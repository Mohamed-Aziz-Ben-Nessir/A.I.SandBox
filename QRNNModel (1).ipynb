{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4Z8amXvFFi2",
        "outputId": "a10d1219-2c95-4536-d231-3c8481a8618f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.19.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-40rd7lvQNV",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65829743-60a2-4e0c-eca6-7429bbf70694"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.88.17.234:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.88.17.234:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.88.17.234:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.88.17.234:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, TFAutoModel, AutoConfig\n",
        "import re\n",
        "import io\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score, accuracy_score,precision_score,recall_score\n",
        "from zipfile import ZipFile\n",
        "from IPython.display import FileLink \n",
        "import tensorflow as tf\n",
        "# import tensorflow_addons as tfa\n",
        "# from focal_loss import SparseCategoricalFocalLoss\n",
        "\n",
        "np.random.seed(45)\n",
        "tf.random.set_seed(45)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tf.distribute.cluster_resolver.TPUClusterResolver.connect())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYyts0EqvQNW"
      },
      "outputs": [],
      "source": [
        "train_data=pd.read_csv(\"/content/nf-hs-aug-train.csv\")\n",
        "valid_data=pd.read_csv(\"/content/valid.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=train_data.append(valid_data)"
      ],
      "metadata": {
        "id": "LyQMvZlZgFbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=train_data.sample(frac=1).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "RtV6Bguzh7V3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuP2kPYQvQNW"
      },
      "outputs": [],
      "source": [
        "def encode_labels(data):\n",
        "    encoded_OFF=tf.convert_to_tensor(data[\"OFF_label\"].astype(\"int32\"))\n",
        "    #encoded_HS=tf.keras.utils.to_categorical(data[\"HS_label\"],num_classes=7)\n",
        "    encoded_HS=tf.convert_to_tensor(data[\"HS_label\"].astype(\"int32\"))\n",
        "    text=list(data[\"tweet_text\"].astype(\"str\"))\n",
        "    return text,encoded_OFF,encoded_HS\n",
        "\n",
        "train_text,train_OFF,train_HS=encode_labels(train_data)\n",
        "valid_text,valid_OFF,valid_HS=encode_labels(valid_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "416Gqk7NvQNX"
      },
      "outputs": [],
      "source": [
        "def OFF_not_HS_feature_gen(encoded_OFF,encoded_HS):\n",
        "    OFF_not_HS=[]\n",
        "    for x,y in zip(encoded_OFF,encoded_HS):\n",
        "        OFF_not_HS.append(int(x==1 and y==0))\n",
        "    return tf.convert_to_tensor(OFF_not_HS)\n",
        "\n",
        "def Binary_HS_feature_gen(encoded_HS):\n",
        "    HS_bn=[]\n",
        "    for x in encoded_HS:\n",
        "        HS_bn.append(x!=0)\n",
        "    return tf.convert_to_tensor(HS_bn)\n",
        "\n",
        "train_OFF_not_HS=OFF_not_HS_feature_gen(train_OFF,train_data[\"HS_label\"])\n",
        "train_HS_bn=Binary_HS_feature_gen(train_data[\"HS_label\"])\n",
        "valid_OFF_not_HS=OFF_not_HS_feature_gen(valid_OFF,valid_data[\"HS_label\"])\n",
        "valid_HS_bn=Binary_HS_feature_gen(valid_data[\"HS_label\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbwcCliovQNX"
      },
      "outputs": [],
      "source": [
        "def tokenize(sentences):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"UBC-NLP/MARBERTv2\")\n",
        "    input_ids, input_masks = [],[]\n",
        "    for sentence in sentences:\n",
        "        inputs = tokenizer.encode_plus(sentence, add_special_tokens=True,max_length=256,truncation=True, padding='max_length',return_attention_mask=True, return_token_type_ids=True)\n",
        "        input_ids.append(inputs['input_ids'])\n",
        "        input_masks.append(inputs['attention_mask'])\n",
        "    return np.asarray(input_ids, dtype='int32'),np.asarray(input_masks, dtype='int32')\n",
        "\n",
        "train_input_ids,train_input_masks=tokenize(train_text)\n",
        "valid_input_ids,valid_input_masks=tokenize(valid_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xcWQK0kvQNX"
      },
      "outputs": [],
      "source": [
        "def report_gen(predictions,labels):\n",
        "    report={\n",
        "    \"F1_macro\":f1_score(predictions,labels,average=\"macro\"),\n",
        "    \"Accuracy\":accuracy_score(predictions,labels),\n",
        "    \"Precision_macro\":precision_score(predictions,labels,average=\"macro\"),\n",
        "    \"Recall_macro\":recall_score(predictions,labels,average=\"macro\")\n",
        "    }\n",
        "    return report\n",
        "\n",
        "def eval_taskA(predictions_OFF,labels_OFF,return_predictions=False):\n",
        "    predictions_OFF=[int(i>0.78) for i in predictions_OFF]\n",
        "    return predictions_OFF if return_predictions else report_gen(predictions_OFF,labels_OFF)\n",
        "\n",
        "def eval_taskB(predictions_HS,labels_HS_bn,return_predictions=False):\n",
        "    predictions_HS_bn=[]\n",
        "    for pred in predictions_HS:\n",
        "        pred=list(pred)\n",
        "        max_value = max(pred)\n",
        "        max_index = pred.index(max_value)\n",
        "        predictions_HS_bn.append(int(max_index!=0))\n",
        "    return predictions_HS_bn if return_predictions else report_gen(predictions_HS_bn,labels_HS_bn)\n",
        "\n",
        "\n",
        "def eval_taskC(predictions_HS,labels_HS,return_predictions=False):\n",
        "    predictions_HS=tf.argmax(predictions_HS,axis=1)\n",
        "    predictions_HS=[int(i) for i in predictions_HS]\n",
        "    return predictions_HS if return_predictions else report_gen(predictions_HS,labels_HS)\n",
        "\n",
        "def eval_taskD(predictions_OFF_not_HS,labels_OFF_not_HS):\n",
        "    predictions_OFF_not_HS=[int(i>0.8) for i in predictions_OFF_not_HS]\n",
        "    return report_gen(predictions_OFF_not_HS,labels_OFF_not_HS)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-rv_jFccOdb"
      },
      "outputs": [],
      "source": [
        "#this was taken from https://github.com/DingKe/nn_playground/blob/master/qrnn/qrnn.py\n",
        "from keras import backend as K\n",
        "from keras import activations, initializers, regularizers, constraints\n",
        "from keras.layers import Layer, InputSpec\n",
        "from keras.utils.conv_utils import conv_output_length\n",
        "\n",
        "def _dropout(x, level, noise_shape=None, seed=None):\n",
        "    x = K.dropout(x, level, noise_shape, seed)\n",
        "    x *= (1. - level) # compensate for the scaling by the dropout\n",
        "    return x\n",
        "\n",
        "\n",
        "class QRNN(Layer):\n",
        "    '''Quasi RNN\n",
        "    # Arguments\n",
        "        units: dimension of the internal projections and the final output.\n",
        "    # References\n",
        "        - [Quasi-recurrent Neural Networks](http://arxiv.org/abs/1611.01576)\n",
        "    '''\n",
        "    def __init__(self, units, window_size=2, stride=1,\n",
        "                 return_sequences=False, go_backwards=False, \n",
        "                 stateful=False, unroll=False, activation='tanh',\n",
        "                 kernel_initializer='uniform', bias_initializer='zero',\n",
        "                 kernel_regularizer=None, bias_regularizer=None,\n",
        "                 activity_regularizer=None,\n",
        "                 kernel_constraint=None, bias_constraint=None, \n",
        "                 dropout=0, use_bias=True, input_dim=None, input_length=None,\n",
        "                 **kwargs):\n",
        "        self.return_sequences = return_sequences\n",
        "        self.go_backwards = go_backwards\n",
        "        self.stateful = stateful\n",
        "        self.unroll = unroll\n",
        "\n",
        "        self.units = units \n",
        "        self.window_size = window_size\n",
        "        self.strides = (stride, 1)\n",
        "\n",
        "        self.use_bias = use_bias\n",
        "        self.activation = activations.get(activation)\n",
        "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
        "        self.bias_initializer = initializers.get(bias_initializer)\n",
        "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
        "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
        "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
        "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
        "        self.bias_constraint = constraints.get(bias_constraint)\n",
        "\n",
        "        self.dropout = dropout\n",
        "        self.supports_masking = True\n",
        "        self.input_spec = [InputSpec(ndim=3)]\n",
        "        self.input_dim = input_dim\n",
        "        self.input_length = input_length\n",
        "        if self.input_dim:\n",
        "            kwargs['input_shape'] = (self.input_length, self.input_dim)\n",
        "        super(QRNN, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        if isinstance(input_shape, list):\n",
        "            input_shape = input_shape[0]\n",
        "\n",
        "        batch_size = input_shape[0] if self.stateful else None\n",
        "        self.input_dim = input_shape[2]\n",
        "        self.input_spec = InputSpec(shape=(batch_size, None, self.input_dim))\n",
        "        self.state_spec = InputSpec(shape=(batch_size, self.units))\n",
        "\n",
        "        self.states = [None]\n",
        "        if self.stateful:\n",
        "            self.reset_states()\n",
        "\n",
        "        kernel_shape = (self.window_size, 1, self.input_dim, self.units * 3)\n",
        "        self.kernel = self.add_weight(name='kernel',\n",
        "                                      shape=kernel_shape,\n",
        "                                      initializer=self.kernel_initializer,\n",
        "                                      regularizer=self.kernel_regularizer,\n",
        "                                      constraint=self.kernel_constraint)\n",
        "        if self.use_bias:\n",
        "            self.bias = self.add_weight(name='bias', \n",
        "                                        shape=(self.units * 3,),\n",
        "                                        initializer=self.bias_initializer,\n",
        "                                        regularizer=self.bias_regularizer,\n",
        "                                        constraint=self.bias_constraint)\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if isinstance(input_shape, list):\n",
        "            input_shape = input_shape[0]\n",
        "\n",
        "        length = input_shape[1]\n",
        "        if length:\n",
        "            length = conv_output_length(length + self.window_size - 1,\n",
        "                                        self.window_size, 'valid',\n",
        "                                        self.strides[0])\n",
        "        if self.return_sequences:\n",
        "            return (input_shape[0], length, self.units)\n",
        "        else:\n",
        "            return (input_shape[0], self.units)\n",
        "\n",
        "    def compute_mask(self, inputs, mask):\n",
        "        if self.return_sequences:\n",
        "            return mask\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def get_initial_states(self, inputs):\n",
        "        # build an all-zero tensor of shape (samples, units)\n",
        "        initial_state = K.zeros_like(inputs)  # (samples, timesteps, input_dim)\n",
        "        initial_state = K.sum(initial_state, axis=(1, 2))  # (samples,)\n",
        "        initial_state = K.expand_dims(initial_state)  # (samples, 1)\n",
        "        initial_state = K.tile(initial_state, [1, self.units])  # (samples, units)\n",
        "        initial_states = [initial_state for _ in range(len(self.states))]\n",
        "        return initial_states\n",
        "\n",
        "    def reset_states(self, states=None):\n",
        "        if not self.stateful:\n",
        "            raise AttributeError('Layer must be stateful.')\n",
        "        if not self.input_spec:\n",
        "            raise RuntimeError('Layer has never been called '\n",
        "                               'and thus has no states.')\n",
        "\n",
        "        batch_size = self.input_spec.shape[0]\n",
        "        if not batch_size:\n",
        "            raise ValueError('If a QRNN is stateful, it needs to know '\n",
        "                             'its batch size. Specify the batch size '\n",
        "                             'of your input tensors: \\n'\n",
        "                             '- If using a Sequential model, '\n",
        "                             'specify the batch size by passing '\n",
        "                             'a `batch_input_shape` '\n",
        "                             'argument to your first layer.\\n'\n",
        "                             '- If using the functional API, specify '\n",
        "                             'the time dimension by passing a '\n",
        "                             '`batch_shape` argument to your Input layer.')\n",
        "\n",
        "        if self.states[0] is None:\n",
        "            self.states = [K.zeros((batch_size, self.units))\n",
        "                           for _ in self.states]\n",
        "        elif states is None:\n",
        "            for state in self.states:\n",
        "                K.set_value(state, np.zeros((batch_size, self.units)))\n",
        "        else:\n",
        "            if not isinstance(states, (list, tuple)):\n",
        "                states = [states]\n",
        "            if len(states) != len(self.states):\n",
        "                raise ValueError('Layer ' + self.name + ' expects ' +\n",
        "                                 str(len(self.states)) + ' states, '\n",
        "                                 'but it received ' + str(len(states)) +\n",
        "                                 'state values. Input received: ' +\n",
        "                                 str(states))\n",
        "            for index, (value, state) in enumerate(zip(states, self.states)):\n",
        "                if value.shape != (batch_size, self.units):\n",
        "                    raise ValueError('State ' + str(index) +\n",
        "                                     ' is incompatible with layer ' +\n",
        "                                     self.name + ': expected shape=' +\n",
        "                                     str((batch_size, self.units)) +\n",
        "                                     ', found shape=' + str(value.shape))\n",
        "                K.set_value(state, value)\n",
        "\n",
        "    def __call__(self, inputs, initial_state=None, **kwargs):\n",
        "        # If `initial_state` is specified,\n",
        "        # and if it a Keras tensor,\n",
        "        # then add it to the inputs and temporarily\n",
        "        # modify the input spec to include the state.\n",
        "        if initial_state is not None:\n",
        "            if hasattr(initial_state, '_keras_history'):\n",
        "                # Compute the full input spec, including state\n",
        "                input_spec = self.input_spec\n",
        "                state_spec = self.state_spec\n",
        "                if not isinstance(state_spec, list):\n",
        "                    state_spec = [state_spec]\n",
        "                self.input_spec = [input_spec] + state_spec\n",
        "\n",
        "                # Compute the full inputs, including state\n",
        "                if not isinstance(initial_state, (list, tuple)):\n",
        "                    initial_state = [initial_state]\n",
        "                inputs = [inputs] + list(initial_state)\n",
        "\n",
        "                # Perform the call\n",
        "                output = super(QRNN, self).__call__(inputs, **kwargs)\n",
        "\n",
        "                # Restore original input spec\n",
        "                self.input_spec = input_spec\n",
        "                return output\n",
        "            else:\n",
        "                kwargs['initial_state'] = initial_state\n",
        "        return super(QRNN, self).__call__(inputs, **kwargs)\n",
        "\n",
        "    def call(self, inputs, mask=None, initial_state=None, training=None):\n",
        "        # input shape: `(samples, time (padded with zeros), input_dim)`\n",
        "        # note that the .build() method of subclasses MUST define\n",
        "        # self.input_spec and self.state_spec with complete input shapes.\n",
        "        if isinstance(inputs, list):\n",
        "            initial_states = inputs[1:]\n",
        "            inputs = inputs[0]\n",
        "        elif initial_state is not None:\n",
        "            pass\n",
        "        elif self.stateful:\n",
        "            initial_states = self.states\n",
        "        else:\n",
        "            initial_states = self.get_initial_states(inputs)\n",
        "\n",
        "        if len(initial_states) != len(self.states):\n",
        "            raise ValueError('Layer has ' + str(len(self.states)) +\n",
        "                             ' states but was passed ' +\n",
        "                             str(len(initial_states)) +\n",
        "                             ' initial states.')\n",
        "        input_shape = K.int_shape(inputs)\n",
        "        if self.unroll and input_shape[1] is None:\n",
        "            raise ValueError('Cannot unroll a RNN if the '\n",
        "                             'time dimension is undefined. \\n'\n",
        "                             '- If using a Sequential model, '\n",
        "                             'specify the time dimension by passing '\n",
        "                             'an `input_shape` or `batch_input_shape` '\n",
        "                             'argument to your first layer. If your '\n",
        "                             'first layer is an Embedding, you can '\n",
        "                             'also use the `input_length` argument.\\n'\n",
        "                             '- If using the functional API, specify '\n",
        "                             'the time dimension by passing a `shape` '\n",
        "                             'or `batch_shape` argument to your Input layer.')\n",
        "        constants = self.get_constants(inputs, training=None)\n",
        "        preprocessed_input = self.preprocess_input(inputs, training=None)\n",
        "\n",
        "        last_output, outputs, states = K.rnn(self.step, preprocessed_input,\n",
        "                                            initial_states,\n",
        "                                            go_backwards=self.go_backwards,\n",
        "                                            mask=mask,\n",
        "                                            constants=constants,\n",
        "                                            unroll=self.unroll,\n",
        "                                            input_length=input_shape[1])\n",
        "        if self.stateful:\n",
        "            updates = []\n",
        "            for i in range(len(states)):\n",
        "                updates.append((self.states[i], states[i]))\n",
        "            self.add_update(updates, inputs)\n",
        "\n",
        "        # Properly set learning phase\n",
        "        if 0 < self.dropout < 1:\n",
        "            last_output._uses_learning_phase = True\n",
        "            outputs._uses_learning_phase = True\n",
        "\n",
        "        if self.return_sequences:\n",
        "            return outputs\n",
        "        else:\n",
        "            return last_output\n",
        "\n",
        "    def preprocess_input(self, inputs, training=None):\n",
        "        if self.window_size > 1:\n",
        "            inputs = K.temporal_padding(inputs, (self.window_size-1, 0))\n",
        "        inputs = K.expand_dims(inputs, 2)  # add a dummy dimension\n",
        "\n",
        "        output = K.conv2d(inputs, self.kernel, strides=self.strides,\n",
        "                          padding='valid',\n",
        "                          data_format='channels_last')\n",
        "        output = K.squeeze(output, 2)  # remove the dummy dimension\n",
        "        if self.use_bias:\n",
        "            output = K.bias_add(output, self.bias, data_format='channels_last')\n",
        "\n",
        "        if self.dropout is not None and 0. < self.dropout < 1.:\n",
        "            z = output[:, :, :self.units]\n",
        "            f = output[:, :, self.units:2 * self.units]\n",
        "            o = output[:, :, 2 * self.units:]\n",
        "            f = K.in_train_phase(1 - _dropout(1 - f, self.dropout), f, training=training)\n",
        "            return K.concatenate([z, f, o], -1)\n",
        "        else:\n",
        "            return output\n",
        "\n",
        "    def step(self, inputs, states):\n",
        "        prev_output = states[0]\n",
        "\n",
        "        z = inputs[:, :self.units]\n",
        "        f = inputs[:, self.units:2 * self.units]\n",
        "        o = inputs[:, 2 * self.units:]\n",
        "\n",
        "        z = self.activation(z)\n",
        "        f = f if self.dropout is not None and 0. < self.dropout < 1. else K.sigmoid(f)\n",
        "        o = K.sigmoid(o)\n",
        "\n",
        "        output = f * prev_output + (1 - f) * z\n",
        "        output = o * output\n",
        "\n",
        "        return output, [output]\n",
        "\n",
        "    def get_constants(self, inputs, training=None):\n",
        "        return []\n",
        " \n",
        "    def get_config(self):\n",
        "        config = {'units': self.units,\n",
        "                  'window_size': self.window_size,\n",
        "                  'stride': self.strides[0],\n",
        "                  'return_sequences': self.return_sequences,\n",
        "                  'go_backwards': self.go_backwards,\n",
        "                  'stateful': self.stateful,\n",
        "                  'unroll': self.unroll,\n",
        "                  'use_bias': self.use_bias,\n",
        "                  'dropout': self.dropout,\n",
        "                  'activation': activations.serialize(self.activation),\n",
        "                  'kernel_initializer': initializers.serialize(self.kernel_initializer),\n",
        "                  'bias_initializer': initializers.serialize(self.bias_initializer),\n",
        "                  'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n",
        "                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n",
        "                  'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n",
        "                  'kernel_constraint': constraints.serialize(self.kernel_constraint),\n",
        "                  'bias_constraint': constraints.serialize(self.bias_constraint),\n",
        "                  'input_dim': self.input_dim,\n",
        "                  'input_length': self.input_length}\n",
        "        base_config = super(QRNN, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UjHrG4sVrCu"
      },
      "outputs": [],
      "source": [
        "def create_model(transformer,conv_units=128,qrnn_units=256,dense_units=64):\n",
        "    input_ids= tf.keras.layers.Input(shape=(256,), dtype='int32')\n",
        "    input_masks = tf.keras.layers.Input(shape=(256,), dtype='int32')\n",
        "    embedding_layer=transformer(input_ids, attention_mask=input_masks)[0]\n",
        "\n",
        "\n",
        "    OFF = tf.keras.layers.Conv1D(conv_units, kernel_size = 3, padding = \"valid\", kernel_initializer = \"glorot_uniform\")(embedding_layer)\n",
        "    OFF =tf.keras.layers.Dropout(0.3,seed=45)(OFF)\n",
        "    OFF_f = QRNN(qrnn_units)(OFF)  \n",
        "    OFF_b = QRNN(qrnn_units, go_backwards=True)(OFF)\n",
        "    OFF = tf.keras.layers.concatenate([OFF_f, OFF_b])\n",
        "    OFF =tf.keras.layers.Dropout(0.2,seed=52)(OFF)\n",
        "    OFF=tf.keras.layers.Dense(dense_units,activation=\"relu\")(OFF)    \n",
        "    output_OFF=tf.keras.layers.Dense(1, activation=\"sigmoid\",name=\"output_OFF\")(OFF)\n",
        "    \n",
        "\n",
        "    HS = tf.keras.layers.Conv1D(conv_units, kernel_size = 3, padding = \"valid\", kernel_initializer = \"glorot_uniform\")(embedding_layer)\n",
        "    HS =tf.keras.layers.Dropout(0.2,seed=55)(HS)\n",
        "    HS_f= QRNN(qrnn_units)(HS) \n",
        "    HS_b = QRNN(qrnn_units, go_backwards=True)(HS)\n",
        "    HS = tf.keras.layers.concatenate([HS_f, HS_b])\n",
        "    HS =tf.keras.layers.Dropout(0.1,seed=45)(HS)\n",
        "    HS=tf.keras.layers.Dense(dense_units,activation=\"relu\")(HS)    \n",
        "    output_HS=tf.keras.layers.Dense(7, activation=\"softmax\",name=\"output_HS\")(HS)\n",
        "\n",
        "\n",
        "    OFF_not_HS=tf.keras.layers.Conv1D(conv_units, kernel_size = 3, padding = \"valid\", kernel_initializer = \"glorot_uniform\")(embedding_layer)\n",
        "    OFF_not_HS =tf.keras.layers.Dropout(0.2,seed=45)(OFF_not_HS)\n",
        "    OFF_not_HS_f = QRNN(qrnn_units)(OFF_not_HS)  \n",
        "    OFF_not_HS_b = QRNN(qrnn_units, go_backwards=True)(OFF_not_HS)\n",
        "    OFF_not_HS = tf.keras.layers.concatenate([OFF_not_HS_f, OFF_not_HS_b])\n",
        "    OFF_not_HS =tf.keras.layers.Dropout(0.1,seed=52)(OFF_not_HS)\n",
        "    OFF_not_HS=tf.keras.layers.Dense(dense_units,activation=\"relu\")(OFF_not_HS)    \n",
        "    output_OFF_not_HS=tf.keras.layers.Dense(1, activation=\"sigmoid\",name=\"output_OFF_not_HS\")(HS)\n",
        "\n",
        "    model = tf.keras.Model(inputs=[input_ids, input_masks], outputs = [output_OFF,output_HS,output_OFF_not_HS])\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvnYJPLHvQNb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 923
        },
        "outputId": "e939c165-aab2-4751-9efb-755202c03c9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertModel.\n",
            "\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at UBC-NLP/MARBERTv2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-a3498560f2b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m                     validation_data=([valid_input_ids,valid_input_masks], [valid_OFF,valid_HS,valid_OFF_not_HS]))#, callbacks=[model_checkpoint_callback])\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_input_masks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_OFF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_HS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_OFF_not_HS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-29-a3498560f2b4>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, input_ids, input_masks, label_OFF, label_HS, label_OFF_not_HS, batch_size, epochs_frozen, epochs_unfrozen, verbose)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         model.fit([input_ids, input_masks],[label_OFF,label_HS,label_OFF_not_HS],batch_size=batch_size,epochs=epochs_frozen,verbose=verbose,\n\u001b[0;32m---> 34\u001b[0;31m                    validation_data=([valid_input_ids,valid_input_masks], [valid_OFF,valid_HS,valid_OFF_not_HS]))#, callbacks=[model_checkpoint_callback])\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepochs_unfrozen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 919, in compute_loss\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 184, in __call__\n        self.build(y_pred)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 133, in build\n        self._losses = tf.nest.map_structure(self._get_loss_object, self._losses)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 272, in _get_loss_object\n        loss = losses_mod.get(loss)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 2369, in get\n        return deserialize(identifier)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 2328, in deserialize\n        printable_module_name='loss function')\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py\", line 710, in deserialize_keras_object\n        f'Unknown {printable_module_name}: {object_name}. Please ensure '\n\n    ValueError: Unknown loss function:  . Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n"
          ]
        }
      ],
      "source": [
        "def build_model():\n",
        "    with tpu_strategy.scope():\n",
        "        config =AutoConfig.from_pretrained(\"UBC-NLP/MARBERTv2\",dropout=0.2,seed=3,attention_dropout=0.2,output_hidden_states = True)\n",
        "        transformer= TFAutoModel.from_pretrained(\"UBC-NLP/MARBERTv2\",config=config)\n",
        "        return create_model(transformer)\n",
        "\n",
        "model=build_model()\n",
        "\n",
        "def train_model(model,input_ids,input_masks,label_OFF,label_HS,label_OFF_not_HS,batch_size=250,epochs_frozen=4,epochs_unfrozen=16,verbose=1):\n",
        "   \n",
        "    checkpoint_filepath = '/content'\n",
        "\n",
        "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "        checkpoint_filepath, \n",
        "        monitor='val_loss', \n",
        "        save_weights_only=True, \n",
        "        save_best_only=True, \n",
        "        save_freq='epoch', \n",
        "        options=tf.train.CheckpointOptions(experimental_io_device='/job:localhost'))\n",
        "\n",
        "    if epochs_frozen:\n",
        "        \n",
        "        for layer in model.layers[:3]:\n",
        "            layer.trainable = False\n",
        "\n",
        "        with tpu_strategy.scope():\n",
        "            model.compile(loss={\"output_OFF\":\"binary_crossentropy\",\"output_HS\":\" \",\"output_OFF_not_HS\":\"binary_crossentropy\"},\n",
        "                          optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), \n",
        "                          metrics={\"output_OFF\":\"accuracy\",\"output_HS\":\"sparse_categorical_accuracy\",\"output_OFF_not_HS\":\"accuracy\"},\n",
        "                          #loss_weights={\"output_OFF\":1,\"output_HS\":1.5}\n",
        "                         )\n",
        "\n",
        "        model.fit([input_ids, input_masks],[label_OFF,label_HS,label_OFF_not_HS],batch_size=batch_size,epochs=epochs_frozen,verbose=verbose,\n",
        "                   validation_data=([valid_input_ids,valid_input_masks], [valid_OFF,valid_HS,valid_OFF_not_HS]))#, callbacks=[model_checkpoint_callback])\n",
        "        \n",
        "    if epochs_unfrozen:\n",
        "      for layer in model.layers[:3]:\n",
        "        layer.trainable = True\n",
        "\n",
        "      with tpu_strategy.scope():\n",
        "            model.compile(loss={\"output_OFF\":\"binary_crossentropy\",\"output_HS\":\"sparse_categorical_crossentropy\",\"output_OFF_not_HS\":\"binary_crossentropy\"},\n",
        "                          optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), \n",
        "                          metrics={\"output_OFF\":\"accuracy\",\"output_HS\":\"sparse_categorical_accuracy\",\"output_OFF_not_HS\":\"accuracy\"},\n",
        "                          #loss_weights={\"output_OFF\":1,\"output_HS\":1.5}\n",
        "                         )\n",
        "\n",
        "      model.fit([input_ids, input_masks],[label_OFF,label_HS,label_OFF_not_HS],batch_size=batch_size,epochs=epochs_unfrozen,verbose=verbose,\n",
        "                    validation_data=([valid_input_ids,valid_input_masks], [valid_OFF,valid_HS,valid_OFF_not_HS]))#, callbacks=[model_checkpoint_callback])\n",
        "\n",
        "train_model(model,train_input_ids,train_input_masks,train_OFF,train_HS,train_OFF_not_HS)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def evaluate_model(model,input_ids,input_masks,labels_OFF,labels_HS,labels_OFF_not_HS,labels_HS_bn):\n",
        "#     predictions_OFF,predictions_HS,predictions_OFF_not_HS=model.predict([input_ids,input_masks])\n",
        "#     print(f\"TaskA:{eval_taskA(predictions_OFF,labels_OFF)}\")\n",
        "#     print(f\"TaskB:{eval_taskB(predictions_HS,labels_HS_bn)}\")\n",
        "#     print(f\"TaskC:{eval_taskC(predictions_HS,labels_HS)}\")\n",
        "#     print(f\"TaskD:{eval_taskD(predictions_OFF_not_HS,labels_OFF_not_HS)}\")\n",
        "# #evaluate_model(model,valid_input_ids,valid_input_masks,valid_OFF,valid_HS,valid_OFF_not_HS,valid_HS_bn)\n",
        "# #0.8542194571109625"
      ],
      "metadata": {
        "id": "CE1LxgE45Ita"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cr79rZrWIkm4"
      },
      "outputs": [],
      "source": [
        "#evaluate_model(model,train_input_ids,train_input_masks,train_OFF,train_HS,train_OFF_not_HS,train_HS_bn)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(sentences):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"UBC-NLP/MARBERTv2\")\n",
        "    input_ids, input_masks = [],[]\n",
        "    for sentence in sentences:\n",
        "        inputs = tokenizer.encode_plus(sentence, add_special_tokens=True,max_length=256,truncation=True, padding='max_length',return_attention_mask=True, return_token_type_ids=True)\n",
        "        input_ids.append(inputs['input_ids'])\n",
        "        input_masks.append(inputs['attention_mask'])\n",
        "    return np.asarray(input_ids, dtype='int32'),np.asarray(input_masks, dtype='int32')\n",
        "\n",
        "test_text=pd.read_csv(\"/content/ntest.csv\")[\"tweet_text\"]\n",
        "test_input_ids,test_input_masks=tokenize(test_text)"
      ],
      "metadata": {
        "id": "xh0omZtUmWmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUidRB8UvQNc",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def zip_file(task):\n",
        "    with ZipFile(task+\".zip\", 'w') as myzip:\n",
        "        myzip.write(task+\".txt\")\n",
        "    myzip.close()\n",
        "    \n",
        "def submission_gen_taskA(predictions):\n",
        "    sub=[]\n",
        "    for i in predictions:\n",
        "        if i==1:\n",
        "            sub.append(\"OFF\")\n",
        "        else :\n",
        "            sub.append(\"NOT_OFF\")\n",
        "    pd.DataFrame(sub).to_csv(\"/content/TaskA.txt\",index=False,header=False)\n",
        "\n",
        "def submission_gen_taskB(predictions):\n",
        "    sub=[]\n",
        "    for i in predictions:\n",
        "        if i==1:\n",
        "            sub.append(\"HS\")\n",
        "        else :\n",
        "            sub.append(\"NOT_HS\")\n",
        "    pd.DataFrame(sub).to_csv(\"/content/TaskB.txt\",index=False,header=False)\n",
        "\n",
        "def submission_gen_taskC(predictions):\n",
        "    sub=[]\n",
        "    for i in predictions:\n",
        "        if i==0:\n",
        "            sub.append(\"NOT_HS\")\n",
        "        else:\n",
        "            sub.append(\"HS\"+str(i))\n",
        "    pd.DataFrame(sub).to_csv(\"/content/TaskC.txt\",index=False,header=False)\n",
        "    \n",
        "def submission_gen():\n",
        "    predictions_OFF,predictions_HS,predictions_OFF_not_HS=model.predict([test_input_ids,test_input_masks])\n",
        "    submission_gen_taskA(eval_taskA(predictions_OFF,valid_OFF,return_predictions=True))\n",
        "    submission_gen_taskB(eval_taskB(predictions_HS,valid_HS_bn,return_predictions=True))\n",
        "    submission_gen_taskC(eval_taskC(predictions_HS,valid_HS,return_predictions=True))\n",
        "\n",
        "submission_gen()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5rYbx4DkpcXw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}