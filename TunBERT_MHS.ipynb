{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xricQGsrC2ZR",
        "outputId": "bcbd1dbb-022f-46ec-e5d6-f74b39971e21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏬ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh...\n",
            "📦 Installing...\n",
            "📌 Adjusting configuration...\n",
            "🩹 Patching environment...\n",
            "⏲ Done in 0:00:32\n",
            "🔁 Restarting kernel...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Mohamed-Aziz-Ben-Nessir/tunbert.git"
      ],
      "metadata": {
        "id": "8LTOZvnnAEM5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2203cf1d-e73e-4e01-c145-81e9d74e8a5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tunbert'...\n",
            "remote: Enumerating objects: 94, done.\u001b[K\n",
            "remote: Counting objects: 100% (94/94), done.\u001b[K\n",
            "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
            "remote: Total 94 (delta 30), reused 81 (delta 21), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (94/94), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/tunbert-opensource-datasets/PyTorch_model/PretrainingBERTFromText--end.ckpt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ttdbuy1y9K4y",
        "outputId": "c83c94c3-112e-4791-baf8-7919a286a065"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-15 07:56:34--  https://storage.googleapis.com/tunbert-opensource-datasets/PyTorch_model/PretrainingBERTFromText--end.ckpt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.196.128, 64.233.191.128, 173.194.74.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.196.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1323771795 (1.2G) [application/octet-stream]\n",
            "Saving to: ‘PretrainingBERTFromText--end.ckpt’\n",
            "\n",
            "PretrainingBERTFrom 100%[===================>]   1.23G   122MB/s    in 14s     \n",
            "\n",
            "2022-07-15 07:56:50 (88.4 MB/s) - ‘PretrainingBERTFromText--end.ckpt’ saved [1323771795/1323771795]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "data=pd.read_csv(\"/content/aug_dataset.csv\")\n",
        "data[\"label\"]=data[\"class\"].map({\"normal\":0,\"abusive\":1,\"hate\":2})\n",
        "# data=data.drop(data[data[\"label\"]==0][1000:].index).reset_index()\n",
        "data[\"class\"].value_counts()"
      ],
      "metadata": {
        "id": "SD9RHivE-EgK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeb99b2e-a5d9-4a31-b7db-5f30de5aca14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "normal     2300\n",
              "abusive    2028\n",
              "hate       1724\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def strat_train_test_split(data,target,rate=0.1):\n",
        "    split=StratifiedShuffleSplit(n_splits=1,test_size=rate,random_state=41)\n",
        "    for train_index,test_index in split.split(data,data[target]):\n",
        "        train_set=data.loc[train_index]\n",
        "        test_set=data.loc[test_index]\n",
        "    return train_set,test_set\n",
        "\n",
        "train_set,test_set=strat_train_test_split(data,\"label\",0.2)\n",
        "train_set=train_set.reset_index()\n",
        "train_set,valid_set=strat_train_test_split(train_set,\"label\",0.1)\n",
        "train_set.to_csv(\"train.tsv\",sep=\"\\t\",index=False,header=False)\n",
        "valid_set.to_csv(\"valid.tsv\",sep=\"\\t\",index=False,header=False)\n",
        "test_set.to_csv(\"test.tsv\",sep=\"\\t\",index=False,header=False)"
      ],
      "metadata": {
        "id": "DNR-GYkjGbu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd tunbert && conda env update -n base -f environment_torch.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_6UfrhGFC7R",
        "outputId": "8a776857-0a74-435d-8d41-c6786765ae59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ WARNING conda.core.solve:_add_specs(611): pinned spec cudatoolkit=11.1 conflicts with explicit specs.  Overriding pinned spec.\n",
            "\b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 4.9.2\n",
            "  latest version: 4.13.0\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base conda\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "toml-0.10.2          | 18 KB     | : 100% 1.0/1 [00:00<00:00,  7.50it/s]               \n",
            "numpy-1.19.1         | 5.2 MB    | : 100% 1.0/1 [00:01<00:00,  1.17s/it]\n",
            "olefile-0.46         | 32 KB     | : 100% 1.0/1 [00:00<00:00, 21.00it/s]\n",
            "pycodestyle-2.6.0    | 38 KB     | : 100% 1.0/1 [00:00<00:00, 21.84it/s]\n",
            "pytorch-1.7.1        | 39.7 MB   | : 100% 1.0/1 [00:07<00:00,  7.72s/it]\n",
            "torchvision-0.8.2    | 6.6 MB    | : 100% 1.0/1 [00:01<00:00,  1.41s/it]               \n",
            "jpeg-9d              | 264 KB    | : 100% 1.0/1 [00:00<00:00,  9.14it/s]\n",
            "click-8.1.3          | 145 KB    | : 100% 1.0/1 [00:00<00:00, 14.25it/s]\n",
            "libpng-1.6.37        | 306 KB    | : 100% 1.0/1 [00:00<00:00, 10.37it/s]\n",
            "python_abi-3.7       | 4 KB      | : 100% 1.0/1 [00:00<00:00, 31.95it/s]\n",
            "torchtext-0.8.1      | 8.0 MB    | : 100% 1.0/1 [00:01<00:00,  1.90s/it]\n",
            "freetype-2.10.4      | 890 KB    | : 100% 1.0/1 [00:00<00:00,  5.26it/s]\n",
            "libtiff-4.2.0        | 639 KB    | : 100% 1.0/1 [00:00<00:00,  7.04it/s]\n",
            "zipp-3.8.0           | 12 KB     | : 100% 1.0/1 [00:00<00:00, 28.55it/s]\n",
            "certifi-2022.6.15    | 155 KB    | : 100% 1.0/1 [00:00<00:00, 17.84it/s]\n",
            "pillow-8.2.0         | 684 KB    | : 100% 1.0/1 [00:00<00:00,  5.58it/s]\n",
            "future-0.18.2        | 713 KB    | : 100% 1.0/1 [00:00<00:00,  4.64it/s]\n",
            "black-19.3b0         | 76 KB     | : 100% 1.0/1 [00:00<00:00, 19.41it/s]\n",
            "libblas-3.9.0        | 12 KB     | : 100% 1.0/1 [00:00<00:00, 15.81it/s]\n",
            "openssl-1.1.1k       | 2.1 MB    | : 100% 1.0/1 [00:00<00:00,  2.91it/s]\n",
            "openjpeg-2.4.0       | 444 KB    | : 100% 1.0/1 [00:00<00:00,  8.72it/s]\n",
            "lcms2-2.12           | 443 KB    | : 100% 1.0/1 [00:00<00:00, 10.28it/s]\n",
            "flake8-3.8.4         | 89 KB     | : 100% 1.0/1 [00:00<00:00, 12.13it/s]\n",
            "isort-5.6.4          | 76 KB     | : 100% 1.0/1 [00:00<00:00, 19.20it/s]\n",
            "appdirs-1.4.4        | 13 KB     | : 100% 1.0/1 [00:00<00:00, 26.10it/s]\n",
            "pyflakes-2.2.0       | 55 KB     | : 100% 1.0/1 [00:00<00:00, 21.12it/s]\n",
            "liblapack-3.9.0      | 11 KB     | : 100% 1.0/1 [00:00<00:00, 13.38it/s]\n",
            "importlib-metadata-4 | 33 KB     | : 100% 1.0/1 [00:00<00:00, 23.48it/s]\n",
            "mccabe-0.6.1         | 8 KB      | : 100% 1.0/1 [00:00<00:00, 28.21it/s]\n",
            "typing_extensions-4. | 28 KB     | : 100% 1.0/1 [00:00<00:00, 14.75it/s]\n",
            "libcblas-3.9.0       | 11 KB     | : 100% 1.0/1 [00:00<00:00, 17.30it/s]\n",
            "_openmp_mutex-4.5    | 6 KB      | : 100% 1.0/1 [00:00<00:00, 16.65it/s]\n",
            "libwebp-base-1.2.0   | 815 KB    | : 100% 1.0/1 [00:00<00:00,  5.77it/s]\n",
            "pip-20.2.2           | 1.1 MB    | : 100% 1.0/1 [00:00<00:00,  2.32it/s]\n",
            "cudatoolkit-11.0.3   | 951.9 MB  | : 100% 1.0/1 [02:05<00:00, 125.98s/it]              \n",
            "ninja-1.10.2         | 2.4 MB    | : 100% 1.0/1 [00:00<00:00,  2.15it/s]\n",
            "mkl-2020.4           | 215.6 MB  | : 100% 1.0/1 [00:38<00:00, 38.55s/it]               \n",
            "attrs-21.4.0         | 49 KB     | : 100% 1.0/1 [00:00<00:00, 16.53it/s]\n",
            "ca-certificates-2022 | 149 KB    | : 100% 1.0/1 [00:00<00:00,  4.61it/s]               \n",
            "llvm-openmp-12.0.1   | 2.8 MB    | : 100% 1.0/1 [00:00<00:00,  2.02it/s]\n",
            "Preparing transaction: | \b\b/ \b\b- \b\bdone\n",
            "Verifying transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Executing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n",
            "\n",
            "\b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Installing pip dependencies: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ Ran pip subprocess with arguments:\n",
            "['/usr/local/bin/python', '-m', 'pip', 'install', '-U', '-r', '/content/tunbert/condaenv.7z5jk73f.requirements.txt']\n",
            "Pip subprocess output:\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nemo_toolkit[all]==1.0.0b1\n",
            "  Downloading nemo_toolkit-1.0.0b1-py3-none-any.whl (407 kB)\n",
            "Collecting pytorch-lightning==0.9.0\n",
            "  Downloading pytorch_lightning-0.9.0-py3-none-any.whl (408 kB)\n",
            "Collecting pre-commit==2.7.1\n",
            "  Downloading pre_commit-2.7.1-py2.py3-none-any.whl (171 kB)\n",
            "Collecting omegaconf==2.0.1rc12\n",
            "  Downloading omegaconf-2.0.1rc12-py3-none-any.whl (35 kB)\n",
            "Collecting hydra-core==1.0.0rc4\n",
            "  Downloading hydra_core-1.0.0rc4-py3-none-any.whl (117 kB)\n",
            "Collecting transformers==3.1.0\n",
            "  Downloading transformers-3.1.0-py3-none-any.whl (884 kB)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.18.2 in /usr/local/lib/python3.7/site-packages (from nemo_toolkit[all]==1.0.0b1->-r /content/tunbert/condaenv.7z5jk73f.requirements.txt (line 1)) (1.19.1)\n",
            "Collecting onnx>=1.7.0\n",
            "  Downloading onnx-1.12.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "Collecting wrapt\n",
            "  Downloading wrapt-1.14.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (75 kB)\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n",
            "Requirement already satisfied, skipping upgrade: torch in /usr/local/lib/python3.7/site-packages (from nemo_toolkit[all]==1.0.0b1->-r /content/tunbert/condaenv.7z5jk73f.requirements.txt (line 1)) (1.7.1.post2)\n",
            "Collecting python-dateutil\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "Collecting ruamel.yaml\n",
            "  Downloading ruamel.yaml-0.17.21-py3-none-any.whl (109 kB)\n",
            "Requirement already satisfied, skipping upgrade: torchtext; extra == \"all\" in /usr/local/lib/python3.7/site-packages (from nemo_toolkit[all]==1.0.0b1->-r /content/tunbert/condaenv.7z5jk73f.requirements.txt (line 1)) (0.8.0a0+0f911ec)\n",
            "Collecting sox; extra == \"all\"\n",
            "  Downloading sox-1.4.1-py2.py3-none-any.whl (39 kB)\n",
            "Collecting megatron-lm>=1.1.4; extra == \"all\"\n",
            "  Downloading megatron_lm-2.2.0-py3-none-any.whl (171 kB)\n",
            "Collecting editdistance; extra == \"all\"\n",
            "  Downloading editdistance-0.6.0-cp37-cp37m-manylinux2010_x86_64.whl (285 kB)\n",
            "Collecting gdown; extra == \"all\"\n",
            "  Downloading gdown-4.5.1.tar.gz (14 kB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "    Preparing wheel metadata: started\n",
            "    Preparing wheel metadata: finished with status 'done'\n",
            "Collecting attrdict; extra == \"all\"\n",
            "  Downloading attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
            "Collecting pytest; extra == \"all\"\n",
            "  Downloading pytest-7.1.2-py3-none-any.whl (297 kB)\n",
            "Collecting pytest-runner; extra == \"all\"\n",
            "  Downloading pytest_runner-6.0.0-py3-none-any.whl (7.2 kB)\n",
            "Collecting youtokentome; extra == \"all\"\n",
            "  Downloading youtokentome-1.0.6-cp37-cp37m-manylinux2010_x86_64.whl (1.7 MB)\n",
            "Collecting wandb; extra == \"all\"\n",
            "  Downloading wandb-0.12.21-py2.py3-none-any.whl (1.8 MB)\n",
            "Collecting parameterized; extra == \"all\"\n",
            "  Downloading parameterized-0.8.1-py2.py3-none-any.whl (26 kB)\n",
            "Collecting packaging; extra == \"all\"\n",
            "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
            "Requirement already satisfied, skipping upgrade: tqdm>=4.41.0; extra == \"all\" in /usr/local/lib/python3.7/site-packages (from nemo_toolkit[all]==1.0.0b1->-r /content/tunbert/condaenv.7z5jk73f.requirements.txt (line 1)) (4.59.0)\n",
            "Collecting rapidfuzz; extra == \"all\"\n",
            "  Downloading rapidfuzz-2.1.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "Collecting soundfile; extra == \"all\"\n",
            "  Downloading SoundFile-0.10.3.post1-py2.py3-none-any.whl (21 kB)\n",
            "Collecting pandas; extra == \"all\"\n",
            "  Downloading pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "Collecting sphinxcontrib-bibtex; extra == \"all\"\n",
            "  Downloading sphinxcontrib_bibtex-2.4.2-py3-none-any.whl (39 kB)\n",
            "Collecting pypinyin; extra == \"all\"\n",
            "  Downloading pypinyin-0.46.0-py2.py3-none-any.whl (1.3 MB)\n",
            "Collecting webdataset; extra == \"all\"\n",
            "  Downloading webdataset-0.2.5-py3-none-any.whl (46 kB)\n",
            "Collecting matplotlib; extra == \"all\"\n",
            "  Downloading matplotlib-3.5.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "Collecting kaldi-io; extra == \"all\"\n",
            "  Downloading kaldi_io-0.9.4-py3-none-any.whl (14 kB)\n",
            "Collecting black==19.10b0; extra == \"all\"\n",
            "  Downloading black-19.10b0-py36-none-any.whl (97 kB)\n",
            "Collecting boto3; extra == \"all\"\n",
            "  Downloading boto3-1.24.30-py3-none-any.whl (132 kB)\n",
            "Collecting sphinx; extra == \"all\"\n",
            "  Downloading Sphinx-5.0.2-py3-none-any.whl (3.1 MB)\n",
            "Requirement already satisfied, skipping upgrade: pillow; extra == \"all\" in /usr/local/lib/python3.7/site-packages (from nemo_toolkit[all]==1.0.0b1->-r /content/tunbert/condaenv.7z5jk73f.requirements.txt (line 1)) (8.2.0)\n",
            "Collecting librosa; extra == \"all\"\n",
            "  Downloading librosa-0.9.2-py3-none-any.whl (214 kB)\n",
            "Collecting num2words; extra == \"all\"\n",
            "  Downloading num2words-0.5.10-py3-none-any.whl (101 kB)\n",
            "Collecting marshmallow; extra == \"all\"\n",
            "  Downloading marshmallow-3.17.0-py3-none-any.whl (48 kB)\n",
            "Collecting braceexpand; extra == \"all\"\n",
            "  Downloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
            "Collecting frozendict; extra == \"all\"\n",
            "  Downloading frozendict-2.3.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (99 kB)\n",
            "Collecting scipy; extra == \"all\"\n",
            "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "Collecting unidecode; extra == \"all\"\n",
            "  Downloading Unidecode-1.3.4-py3-none-any.whl (235 kB)\n",
            "Collecting kaldi-python-io; extra == \"all\"\n",
            "  Downloading kaldi-python-io-1.2.2.tar.gz (8.8 kB)\n",
            "Collecting inflect; extra == \"all\"\n",
            "  Downloading inflect-5.6.1-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied, skipping upgrade: torchvision; extra == \"all\" in /usr/local/lib/python3.7/site-packages (from nemo_toolkit[all]==1.0.0b1->-r /content/tunbert/condaenv.7z5jk73f.requirements.txt (line 1)) (0.8.0a0)\n",
            "Collecting sentencepiece; extra == \"all\"\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "Collecting torch-stft; extra == \"all\"\n",
            "  Downloading torch_stft-0.1.4-py3-none-any.whl (6.2 kB)\n",
            "Collecting h5py; extra == \"all\"\n",
            "  Downloading h5py-3.7.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.1 MB)\n",
            "Collecting isort[requirements]<5; extra == \"all\"\n",
            "  Downloading isort-4.3.21-py2.py3-none-any.whl (42 kB)\n",
            "Collecting PyYAML>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "Requirement already satisfied, skipping upgrade: future>=0.17.1 in /usr/local/lib/python3.7/site-packages (from pytorch-lightning==0.9.0->-r /content/tunbert/condaenv.7z5jk73f.requirements.txt (line 2)) (0.18.2)\n",
            "Collecting tensorboard==2.2.0\n",
            "  Downloading tensorboard-2.2.0-py3-none-any.whl (2.8 MB)\n",
            "Collecting cfgv>=2.0.0\n",
            "  Downloading cfgv-3.3.1-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting nodeenv>=0.11.1\n",
            "  Downloading nodeenv-1.7.0-py2.py3-none-any.whl (21 kB)\n",
            "Collecting virtualenv>=20.0.8\n",
            "  Downloading virtualenv-20.15.1-py2.py3-none-any.whl (10.1 MB)\n",
            "Requirement already satisfied, skipping upgrade: toml in /usr/local/lib/python3.7/site-packages (from pre-commit==2.7.1->-r /content/tunbert/condaenv.7z5jk73f.requirements.txt (line 3)) (0.10.2)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/site-packages (from pre-commit==2.7.1->-r /content/tunbert/condaenv.7z5jk73f.requirements.txt (line 3)) (4.11.4)\n",
            "Collecting identify>=1.0.0\n",
            "  Downloading identify-2.5.1-py2.py3-none-any.whl (98 kB)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/site-packages (from omegaconf==2.0.1rc12->-r /content/tunbert/condaenv.7z5jk73f.requirements.txt (line 4)) (4.3.0)\n",
            "Collecting importlib-resources; python_version < \"3.9\"\n",
            "  Downloading importlib_resources-5.8.0-py3-none-any.whl (28 kB)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "Collecting filelock\n",
            "  Downloading filelock-3.7.1-py3-none-any.whl (10 kB)\n",
            "Collecting regex!=2019.12.17\n",
            "  Downloading regex-2022.7.9-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/site-packages (from transformers==3.1.0->-r /content/tunbert/condaenv.7z5jk73f.requirements.txt (line 6)) (2.25.1)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "  Downloading tokenizers-0.8.1rc2-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n",
            "Collecting protobuf<=3.20.1,>=3.12.2\n",
            "  Downloading protobuf-3.20.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting joblib>=0.11\n",
            "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil->nemo_toolkit[all]==1.0.0b1->-r /content/tunbert/condaenv.7z5jk73f.requirements.txt (line 1)) (1.15.0)\n",
            "Collecting ruamel.yaml.clib>=0.2.6; platform_python_implementation == \"CPython\" and python_version < \"3.11\"\n",
            "  Downloading ruamel.yaml.clib-0.2.6-cp37-cp37m-manylinux1_x86_64.whl (546 kB)\n",
            "Collecting pybind11\n",
            "  Downloading pybind11-2.9.2-py2.py3-none-any.whl (213 kB)\n",
            "Collecting beautifulsoup4\n",
            "  Downloading beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n",
            "Collecting iniconfig\n",
            "  Downloading iniconfig-1.1.1-py2.py3-none-any.whl (5.0 kB)\n",
            "Requirement already satisfied, skipping upgrade: attrs>=19.2.0 in /usr/local/lib/python3.7/site-packages (from pytest; extra == \"all\"->nemo_toolkit[all]==1.0.0b1->-r /content/tunbert/condaenv.7z5jk73f.requirements.txt (line 1)) (21.4.0)\n",
            "Collecting pluggy<2.0,>=0.12\n",
            "  Downloading pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting tomli>=1.0.0\n",
            "  Downloading tomli-2.0.1-py3-none-any.whl (12 kB)\n",
            "Collecting py>=1.8.2\n",
            "  Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
            "Requirement already satisfied, skipping upgrade: Click>=7.0 in /usr/local/lib/python3.7/site-packages (from youtokentome; extra == \"all\"->nemo_toolkit[all]==1.0.0b1->-r /content/tunbert/condaenv.7z5jk73f.requirements.txt (line 1)) (8.1.3)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.7.1-py2.py3-none-any.whl (146 kB)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/site-packages (from wandb; extra == \"all\"->nemo_toolkit[all]==1.0.0b1->-r /content/tunbert/condaenv.7z5jk73f.requirements.txt (line 1)) (49.6.0.post20210108)\n",
            "Collecting promise<3,>=2.0\n",
            "  Downloading promise-2.3.tar.gz (19 kB)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.2.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
            "Collecting psutil>=5.0.0\n",
            "  Downloading psutil-5.9.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
            "Collecting pyparsing!=3.0.5,>=2.0.2\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "Collecting jarowinkler<2.0.0,>=1.1.0\n",
            "  Downloading jarowinkler-1.1.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (104 kB)\n",
            "Requirement already satisfied, skipping upgrade: cffi>=1.0 in /usr/local/lib/python3.7/site-packages (from soundfile; extra == \"all\"->nemo_toolkit[all]==1.0.0b1->-r /content/tunbert/condaenv.7z5jk73f.requirements.txt (line 1)) (1.14.5)\n",
            "Collecting pytz>=2017.3\n",
            "  Downloading pytz-2022.1-py2.py3-none-any.whl (503 kB)\n",
            "Collecting docutils>=0.8\n",
            "  Downloading docutils-0.19-py3-none-any.whl (570 kB)\n",
            "Collecting pybtex-docutils>=1.0.0\n",
            "  Downloading pybtex_docutils-1.0.2-py3-none-any.whl (6.3 kB)\n",
            "Collecting pybtex>=0.24\n",
            "  Downloading pybtex-0.24.0-py2.py3-none-any.whl (561 kB)\n",
            "Collecting cycler>=0.10\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.34.4-py3-none-any.whl (944 kB)\n",
            "Collecting kiwisolver>=1.0.1\n",
            "  Downloading kiwisolver-1.4.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1 MB)\n",
            "Requirement already satisfied, skipping upgrade: appdirs in /usr/local/lib/python3.7/site-packages (from black==19.10b0; extra == \"all\"->nemo_toolkit[all]==1.0.0b1->-r /content/tunbert/condaenv.7z5jk73f.requirements.txt (line 1)) (1.4.4)\n",
            "Collecting typed-ast>=1.4.0\n",
            "  Downloading typed_ast-1.5.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (843 kB)\n",
            "Collecting pathspec<1,>=0.6\n",
            "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting botocore<1.28.0,>=1.27.30\n",
            "  Downloading botocore-1.27.30-py3-none-any.whl (9.0 MB)\n",
            "Collecting sphinxcontrib-applehelp\n",
            "  Downloading sphinxcontrib_applehelp-1.0.2-py2.py3-none-any.whl (121 kB)\n",
            "Collecting sphinxcontrib-devhelp\n",
            "  Downloading sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl (84 kB)\n",
            "Collecting babel>=1.3\n",
            "  Downloading Babel-2.10.3-py3-none-any.whl (9.5 MB)\n",
            "Collecting sphinxcontrib-serializinghtml>=1.1.5\n",
            "  Downloading sphinxcontrib_serializinghtml-1.1.5-py2.py3-none-any.whl (94 kB)\n",
            "Collecting imagesize\n",
            "  Downloading imagesize-1.4.1-py2.py3-none-any.whl (8.8 kB)\n",
            "Collecting sphinxcontrib-htmlhelp>=2.0.0\n",
            "  Downloading sphinxcontrib_htmlhelp-2.0.0-py2.py3-none-any.whl (100 kB)\n",
            "Collecting Pygments>=2.0\n",
            "  Downloading Pygments-2.12.0-py3-none-any.whl (1.1 MB)\n",
            "Collecting sphinxcontrib-qthelp\n",
            "  Downloading sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl (90 kB)\n",
            "Collecting alabaster<0.8,>=0.7\n",
            "  Downloading alabaster-0.7.12-py2.py3-none-any.whl (14 kB)\n",
            "Collecting Jinja2>=2.3\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "Collecting snowballstemmer>=1.1\n",
            "  Downloading snowballstemmer-2.2.0-py2.py3-none-any.whl (93 kB)\n",
            "Collecting sphinxcontrib-jsmath\n",
            "  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\n",
            "Collecting audioread>=2.1.9\n",
            "  Downloading audioread-2.1.9.tar.gz (377 kB)\n",
            "Collecting pooch>=1.0\n",
            "  Downloading pooch-1.6.0-py3-none-any.whl (56 kB)\n",
            "Collecting decorator>=4.0.10\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting numba>=0.45.1\n",
            "  Downloading numba-0.55.2-cp37-cp37m-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.3 MB)\n",
            "Collecting resampy>=0.2.2\n",
            "  Downloading resampy-0.3.1-py3-none-any.whl (3.1 MB)\n",
            "Collecting docopt>=0.6.2\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "Collecting pipreqs; extra == \"requirements\"\n",
            "  Downloading pipreqs-0.4.11-py2.py3-none-any.whl (32 kB)\n",
            "Collecting pip-api; extra == \"requirements\"\n",
            "  Downloading pip_api-0.0.29-py3-none-any.whl (111 kB)\n",
            "Collecting absl-py>=0.4\n",
            "  Downloading absl_py-1.1.0-py3-none-any.whl (123 kB)\n",
            "Collecting grpcio>=1.24.3\n",
            "  Downloading grpcio-1.47.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "Collecting werkzeug>=0.11.15\n",
            "  Downloading Werkzeug-2.1.2-py3-none-any.whl (224 kB)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Collecting tensorboard-plugin-wit>=1.6.0\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "Collecting google-auth<2,>=1.6.3\n",
            "  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
            "Collecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/site-packages (from tensorboard==2.2.0->pytorch-lightning==0.9.0->-r /content/tunbert/condaenv.7z5jk73f.requirements.txt (line 2)) (0.36.2)\n",
            "Collecting distlib<1,>=0.3.1\n",
            "  Downloading distlib-0.3.5-py2.py3-none-any.whl (466 kB)\n",
            "Collecting platformdirs<3,>=2\n",
            "  Downloading platformdirs-2.5.2-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->pre-commit==2.7.1->-r /content/tunbert/condaenv.7z5jk73f.requirements.txt (line 3)) (3.8.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests->transformers==3.1.0->-r /content/tunbert/condaenv.7z5jk73f.requirements.txt (line 6)) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests->transformers==3.1.0->-r /content/tunbert/condaenv.7z5jk73f.requirements.txt (line 6)) (2022.6.15)\n",
            "Requirement already satisfied, skipping upgrade: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/site-packages (from requests->transformers==3.1.0->-r /content/tunbert/condaenv.7z5jk73f.requirements.txt (line 6)) (4.0.0)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests->transformers==3.1.0->-r /content/tunbert/condaenv.7z5jk73f.requirements.txt (line 6)) (1.26.3)\n",
            "Collecting soupsieve>1.2\n",
            "  Downloading soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "Requirement already satisfied, skipping upgrade: pycparser in /usr/local/lib/python3.7/site-packages (from cffi>=1.0->soundfile; extra == \"all\"->nemo_toolkit[all]==1.0.0b1->-r /content/tunbert/condaenv.7z5jk73f.requirements.txt (line 1)) (2.20)\n",
            "Collecting latexcodec>=1.0.4\n",
            "  Downloading latexcodec-2.0.1-py2.py3-none-any.whl (18 kB)\n",
            "Collecting MarkupSafe>=2.0\n",
            "  Downloading MarkupSafe-2.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting llvmlite<0.39,>=0.38.0rc1\n",
            "  Downloading llvmlite-0.38.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "Collecting yarg\n",
            "  Downloading yarg-0.1.9-py2.py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied, skipping upgrade: pip in /usr/local/lib/python3.7/site-packages (from pip-api; extra == \"requirements\"->isort[requirements]<5; extra == \"all\"->nemo_toolkit[all]==1.0.0b1->-r /content/tunbert/condaenv.7z5jk73f.requirements.txt (line 1)) (20.2.2)\n",
            "Collecting requests-oauthlib>=0.7.0\n",
            "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
            "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
            "  Downloading rsa-4.8-py3-none-any.whl (39 kB)\n",
            "Collecting cachetools<5.0,>=2.0.0\n",
            "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
            "Collecting pyasn1-modules>=0.2.1\n",
            "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Collecting oauthlib>=3.0.0\n",
            "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
            "Collecting pyasn1>=0.1.3\n",
            "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
            "Building wheels for collected packages: wget, gdown, kaldi-python-io, antlr4-python3-runtime, sacremoses, pathtools, promise, audioread, docopt\n",
            "  Building wheel for wget (setup.py): started\n",
            "  Building wheel for wget (setup.py): finished with status 'done'\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9680 sha256=af97528457d1ba821f5220b4a9f62efc2ee6b86901787da12b36c349dc76d834\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "  Building wheel for gdown (PEP 517): started\n",
            "  Building wheel for gdown (PEP 517): finished with status 'done'\n",
            "  Created wheel for gdown: filename=gdown-4.5.1-py3-none-any.whl size=14933 sha256=d50365d8b4a7d192ef1af532eeeac5e25d50a4ee842a0fa6498d7911ab06fbbf\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/ec/b0/a96d1d126183f98570a785e6bf8789fca559853a9260e928e1\n",
            "  Building wheel for kaldi-python-io (setup.py): started\n",
            "  Building wheel for kaldi-python-io (setup.py): finished with status 'done'\n",
            "  Created wheel for kaldi-python-io: filename=kaldi_python_io-1.2.2-py3-none-any.whl size=8969 sha256=aa373cead3e285ecec23ea3b7a9f2ab0034d4a3c034a380fda2ba6cbfe5ed8bb\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/26/38/7678d1ff6cd1bbcbfc0d80b0a29d94d917dfa9ad790b4a85a9\n",
            "  Building wheel for antlr4-python3-runtime (setup.py): started\n",
            "  Building wheel for antlr4-python3-runtime (setup.py): finished with status 'done'\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=cf127d7e73b674cff60c9698222dbc8fc8db01b2c9839aca27ff74676a72ac41\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
            "  Building wheel for sacremoses (setup.py): started\n",
            "  Building wheel for sacremoses (setup.py): finished with status 'done'\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895254 sha256=9ed6e47e6f5eee6ba60edd1ea9c67c2369d4a87e8d3b8b6c81c0b03879ef5f52\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "  Building wheel for pathtools (setup.py): started\n",
            "  Building wheel for pathtools (setup.py): finished with status 'done'\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8784 sha256=290fb0a7b9a58850a341494d63bcfc664a7de74ad9488c7bbba450565e495d37\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "  Building wheel for promise (setup.py): started\n",
            "  Building wheel for promise (setup.py): finished with status 'done'\n",
            "  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21494 sha256=b33499a44a60d33c09f9dce6391856f3759f17259efc35e5abb2a7f7434b47a6\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/93/c6/762e359f8cb6a5b69c72235d798804cae523bbe41c2aa8333d\n",
            "  Building wheel for audioread (setup.py): started\n",
            "  Building wheel for audioread (setup.py): finished with status 'done'\n",
            "  Created wheel for audioread: filename=audioread-2.1.9-py3-none-any.whl size=23141 sha256=531f9e1788f8cc2e22df1b8174e6fd9c71af7229365d41d28c14bc22ceddd07f\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/7b/eb/213741ccc0678f63e346ab8dff10495995ca3f426af87b8d88\n",
            "  Building wheel for docopt (setup.py): started\n",
            "  Building wheel for docopt (setup.py): finished with status 'done'\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13705 sha256=39bd8684d71b665dfcca0d505b74b34e44c03f42b958d773a47f797250229eac\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/b0/3f/1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9\n",
            "Successfully built wget gdown kaldi-python-io antlr4-python3-runtime sacremoses pathtools promise audioread docopt\n",
            "Installing collected packages: protobuf, onnx, PyYAML, omegaconf, wrapt, importlib-resources, antlr4-python3-runtime, hydra-core, filelock, regex, pyparsing, packaging, joblib, sacremoses, tokenizers, sentencepiece, transformers, wget, threadpoolctl, scipy, scikit-learn, python-dateutil, absl-py, grpcio, werkzeug, pyasn1, rsa, cachetools, pyasn1-modules, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, tensorboard-plugin-wit, markdown, tensorboard, pytorch-lightning, ruamel.yaml.clib, ruamel.yaml, sox, pybind11, megatron-lm, editdistance, soupsieve, beautifulsoup4, gdown, attrdict, iniconfig, pluggy, tomli, py, pytest, pytest-runner, youtokentome, smmap, gitdb, GitPython, docker-pycreds, sentry-sdk, pathtools, promise, shortuuid, setproctitle, psutil, wandb, parameterized, jarowinkler, rapidfuzz, soundfile, pytz, pandas, docutils, latexcodec, pybtex, pybtex-docutils, sphinxcontrib-applehelp, sphinxcontrib-devhelp, babel, sphinxcontrib-serializinghtml, imagesize, sphinxcontrib-htmlhelp, Pygments, sphinxcontrib-qthelp, alabaster, MarkupSafe, Jinja2, snowballstemmer, sphinxcontrib-jsmath, sphinx, sphinxcontrib-bibtex, pypinyin, braceexpand, webdataset, cycler, fonttools, kiwisolver, matplotlib, kaldi-io, typed-ast, pathspec, black, jmespath, botocore, s3transfer, boto3, audioread, pooch, decorator, llvmlite, numba, resampy, librosa, docopt, num2words, marshmallow, frozendict, unidecode, kaldi-python-io, inflect, torch-stft, h5py, yarg, pipreqs, pip-api, isort, nemo-toolkit, cfgv, nodeenv, distlib, platformdirs, virtualenv, identify, pre-commit\n",
            "  Attempting uninstall: black\n",
            "    Found existing installation: black 19.3b0\n",
            "    Uninstalling black-19.3b0:\n",
            "      Successfully uninstalled black-19.3b0\n",
            "  Attempting uninstall: isort\n",
            "    Found existing installation: isort 5.6.4\n",
            "    Uninstalling isort-5.6.4:\n",
            "      Successfully uninstalled isort-5.6.4\n",
            "Successfully installed GitPython-3.1.27 Jinja2-3.1.2 MarkupSafe-2.1.1 PyYAML-6.0 Pygments-2.12.0 absl-py-1.1.0 alabaster-0.7.12 antlr4-python3-runtime-4.8 attrdict-2.0.1 audioread-2.1.9 babel-2.10.3 beautifulsoup4-4.11.1 black-19.10b0 boto3-1.24.30 botocore-1.27.30 braceexpand-0.1.7 cachetools-4.2.4 cfgv-3.3.1 cycler-0.11.0 decorator-5.1.1 distlib-0.3.5 docker-pycreds-0.4.0 docopt-0.6.2 docutils-0.19 editdistance-0.6.0 filelock-3.7.1 fonttools-4.34.4 frozendict-2.3.2 gdown-4.5.1 gitdb-4.0.9 google-auth-1.35.0 google-auth-oauthlib-0.4.6 grpcio-1.47.0 h5py-3.7.0 hydra-core-1.0.0rc4 identify-2.5.1 imagesize-1.4.1 importlib-resources-5.8.0 inflect-5.6.1 iniconfig-1.1.1 isort-4.3.21 jarowinkler-1.1.2 jmespath-1.0.1 joblib-1.1.0 kaldi-io-0.9.4 kaldi-python-io-1.2.2 kiwisolver-1.4.3 latexcodec-2.0.1 librosa-0.9.2 llvmlite-0.38.1 markdown-3.3.7 marshmallow-3.17.0 matplotlib-3.5.2 megatron-lm-2.2.0 nemo-toolkit-1.0.0b1 nodeenv-1.7.0 num2words-0.5.10 numba-0.55.2 oauthlib-3.2.0 omegaconf-2.0.1rc12 onnx-1.12.0 packaging-21.3 pandas-1.3.5 parameterized-0.8.1 pathspec-0.9.0 pathtools-0.1.2 pip-api-0.0.29 pipreqs-0.4.11 platformdirs-2.5.2 pluggy-1.0.0 pooch-1.6.0 pre-commit-2.7.1 promise-2.3 protobuf-3.20.1 psutil-5.9.1 py-1.11.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 pybind11-2.9.2 pybtex-0.24.0 pybtex-docutils-1.0.2 pyparsing-3.0.9 pypinyin-0.46.0 pytest-7.1.2 pytest-runner-6.0.0 python-dateutil-2.8.2 pytorch-lightning-0.9.0 pytz-2022.1 rapidfuzz-2.1.3 regex-2022.7.9 requests-oauthlib-1.3.1 resampy-0.3.1 rsa-4.8 ruamel.yaml-0.17.21 ruamel.yaml.clib-0.2.6 s3transfer-0.6.0 sacremoses-0.0.53 scikit-learn-1.0.2 scipy-1.7.3 sentencepiece-0.1.96 sentry-sdk-1.7.1 setproctitle-1.2.3 shortuuid-1.0.9 smmap-5.0.0 snowballstemmer-2.2.0 soundfile-0.10.3.post1 soupsieve-2.3.2.post1 sox-1.4.1 sphinx-5.0.2 sphinxcontrib-applehelp-1.0.2 sphinxcontrib-bibtex-2.4.2 sphinxcontrib-devhelp-1.0.2 sphinxcontrib-htmlhelp-2.0.0 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.3 sphinxcontrib-serializinghtml-1.1.5 tensorboard-2.2.0 tensorboard-plugin-wit-1.8.1 threadpoolctl-3.1.0 tokenizers-0.8.1rc2 tomli-2.0.1 torch-stft-0.1.4 transformers-3.1.0 typed-ast-1.5.4 unidecode-1.3.4 virtualenv-20.15.1 wandb-0.12.21 webdataset-0.2.5 werkzeug-2.1.2 wget-3.2 wrapt-1.14.1 yarg-0.1.9 youtokentome-1.0.6\n",
            "\n",
            "\b\b| \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate base\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pre-commit"
      ],
      "metadata": {
        "id": "gzJryZ21tByI",
        "outputId": "dac29b32-e835-4bde-ba71-ce26b450797c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pre-commit\n",
            "  Downloading pre_commit-2.20.0-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: virtualenv>=20.0.8 in /usr/local/lib/python3.7/site-packages (from pre-commit) (20.15.1)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/site-packages (from pre-commit) (4.11.4)\n",
            "Requirement already satisfied, skipping upgrade: identify>=1.0.0 in /usr/local/lib/python3.7/site-packages (from pre-commit) (2.5.1)\n",
            "Requirement already satisfied, skipping upgrade: nodeenv>=0.11.1 in /usr/local/lib/python3.7/site-packages (from pre-commit) (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml>=5.1 in /usr/local/lib/python3.7/site-packages (from pre-commit) (6.0)\n",
            "Requirement already satisfied, skipping upgrade: cfgv>=2.0.0 in /usr/local/lib/python3.7/site-packages (from pre-commit) (3.3.1)\n",
            "Requirement already satisfied, skipping upgrade: toml in /usr/local/lib/python3.7/site-packages (from pre-commit) (0.10.2)\n",
            "Requirement already satisfied, skipping upgrade: distlib<1,>=0.3.1 in /usr/local/lib/python3.7/site-packages (from virtualenv>=20.0.8->pre-commit) (0.3.5)\n",
            "Requirement already satisfied, skipping upgrade: six<2,>=1.9.0 in /usr/local/lib/python3.7/site-packages (from virtualenv>=20.0.8->pre-commit) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: filelock<4,>=3.2 in /usr/local/lib/python3.7/site-packages (from virtualenv>=20.0.8->pre-commit) (3.7.1)\n",
            "Requirement already satisfied, skipping upgrade: platformdirs<3,>=2 in /usr/local/lib/python3.7/site-packages (from virtualenv>=20.0.8->pre-commit) (2.5.2)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->pre-commit) (4.3.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->pre-commit) (3.8.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/site-packages (from nodeenv>=0.11.1->pre-commit) (49.6.0.post20210108)\n",
            "Installing collected packages: pre-commit\n",
            "  Attempting uninstall: pre-commit\n",
            "    Found existing installation: pre-commit 2.7.1\n",
            "    Uninstalling pre-commit-2.7.1:\n",
            "      Successfully uninstalled pre-commit-2.7.1\n",
            "Successfully installed pre-commit-2.20.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.7\n",
        "!pip install torchtext==0.8\n",
        "!pip install pytorch-lightning==0.9.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5Jww2VqEfgM",
        "outputId": "2539f805-ccf7-4668-d47d-42bdf36302ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.7\n",
            "  Downloading torch-1.7.0-cp37-cp37m-manylinux1_x86_64.whl (776.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 776.7 MB 4.4 kB/s \n",
            "\u001b[?25hCollecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/site-packages (from torch==1.7) (4.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/site-packages (from torch==1.7) (0.18.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (from torch==1.7) (1.19.1)\n",
            "Installing collected packages: dataclasses, torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.7.1.post2\n",
            "    Uninstalling torch-1.7.1.post2:\n",
            "      Successfully uninstalled torch-1.7.1.post2\n",
            "Successfully installed dataclasses-0.6 torch-1.7.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.8\n",
            "  Downloading torchtext-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.9 MB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/site-packages (from torchtext==0.8) (2.25.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/site-packages (from torchtext==0.8) (4.59.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/site-packages (from torchtext==0.8) (1.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (from torchtext==0.8) (1.19.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests->torchtext==0.8) (2022.6.15)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests->torchtext==0.8) (1.26.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests->torchtext==0.8) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/site-packages (from requests->torchtext==0.8) (4.0.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/site-packages (from torch->torchtext==0.8) (0.18.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/site-packages (from torch->torchtext==0.8) (4.3.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/site-packages (from torch->torchtext==0.8) (0.6)\n",
            "Installing collected packages: torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.8.0a0+0f911ec\n",
            "    Uninstalling torchtext-0.8.0a0+0f911ec:\n",
            "      Successfully uninstalled torchtext-0.8.0a0+0f911ec\n",
            "Successfully installed torchtext-0.8.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytorch-lightning==0.9.0 in /usr/local/lib/python3.7/site-packages (0.9.0)\n",
            "Requirement already satisfied: tensorboard==2.2.0 in /usr/local/lib/python3.7/site-packages (from pytorch-lightning==0.9.0) (2.2.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/site-packages (from pytorch-lightning==0.9.0) (4.59.0)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.7/site-packages (from pytorch-lightning==0.9.0) (1.19.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/site-packages (from pytorch-lightning==0.9.0) (21.3)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.7/site-packages (from pytorch-lightning==0.9.0) (1.7.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.7/site-packages (from pytorch-lightning==0.9.0) (6.0)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.7/site-packages (from pytorch-lightning==0.9.0) (0.18.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/site-packages (from tensorboard==2.2.0->pytorch-lightning==0.9.0) (2.1.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/site-packages (from tensorboard==2.2.0->pytorch-lightning==0.9.0) (1.1.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/site-packages (from tensorboard==2.2.0->pytorch-lightning==0.9.0) (1.35.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/site-packages (from tensorboard==2.2.0->pytorch-lightning==0.9.0) (49.6.0.post20210108)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/site-packages (from tensorboard==2.2.0->pytorch-lightning==0.9.0) (1.15.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/site-packages (from tensorboard==2.2.0->pytorch-lightning==0.9.0) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/site-packages (from tensorboard==2.2.0->pytorch-lightning==0.9.0) (3.3.7)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/site-packages (from tensorboard==2.2.0->pytorch-lightning==0.9.0) (0.4.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/site-packages (from tensorboard==2.2.0->pytorch-lightning==0.9.0) (1.47.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/site-packages (from tensorboard==2.2.0->pytorch-lightning==0.9.0) (3.20.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/site-packages (from tensorboard==2.2.0->pytorch-lightning==0.9.0) (0.36.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/site-packages (from tensorboard==2.2.0->pytorch-lightning==0.9.0) (2.25.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/site-packages (from packaging->pytorch-lightning==0.9.0) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/site-packages (from torch>=1.3->pytorch-lightning==0.9.0) (4.3.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/site-packages (from torch>=1.3->pytorch-lightning==0.9.0) (0.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard==2.2.0->pytorch-lightning==0.9.0) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard==2.2.0->pytorch-lightning==0.9.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard==2.2.0->pytorch-lightning==0.9.0) (4.8)\n",
            "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /usr/local/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard==2.2.0->pytorch-lightning==0.9.0) (4.11.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.2.0->pytorch-lightning==0.9.0) (1.3.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard==2.2.0->pytorch-lightning==0.9.0) (2022.6.15)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard==2.2.0->pytorch-lightning==0.9.0) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard==2.2.0->pytorch-lightning==0.9.0) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard==2.2.0->pytorch-lightning==0.9.0) (1.26.3)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard==2.2.0->pytorch-lightning==0.9.0) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard==2.2.0->pytorch-lightning==0.9.0) (3.8.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.2.0->pytorch-lightning==0.9.0) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd tunbert && pre-commit install && pre-commit run --all-files"
      ],
      "metadata": {
        "id": "SpLAAa0QrcIZ",
        "outputId": "06402673-a941-4641-81d5-64a7e8af7ddd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pre-commit installed at .git/hooks/pre-commit\n",
            "seed isort known_third_party.............................................\u001b[42mPassed\u001b[m\n",
            "isort....................................................................\u001b[42mPassed\u001b[m\n",
            "black....................................................................\u001b[42mPassed\u001b[m\n",
            "flake8...................................................................\u001b[42mPassed\u001b[m\n",
            "Check for merge conflicts................................................\u001b[42mPassed\u001b[m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/tunbert/models/bert-nvidia/bert_finetuning_SA_DC.py --config-name \"sentiment_analysis_config\" model.language_model.lm_checkpoint=\"/content/PretrainingBERTFromText--end.ckpt\" model.train_ds.file_path=\"/content/train.tsv\" model.validation_ds.file_path=\"/content/valid.tsv\" model.test_ds.file_path=\"/content/test.tsv\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9R0VSN19BuS",
        "outputId": "9f85d864-9984-4e4d-8ccd-62f22c30f179"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n",
            "[NeMo W 2022-07-15 08:09:15 experimental:28] Module <class 'nemo.collections.nlp.modules.common.huggingface.auto.AutoModelEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
            "[NeMo W 2022-07-15 08:09:16 experimental:28] Module <class 'nemo.collections.nlp.modules.common.megatron.megatron_bert.MegatronBertEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
            "[NeMo W 2022-07-15 08:09:17 nemo_logging:349] /usr/local/lib/python3.7/site-packages/omegaconf/basecontainer.py:231: UserWarning: \n",
            "                pretty() is deprecated and will be removed in a future version.\n",
            "                Use OmegaConf.to_yaml. Please note that the default value for\n",
            "                resolve has changed to True.\n",
            "                \n",
            "      category=UserWarning,\n",
            "    \n",
            "[NeMo I 2022-07-15 08:09:17 bert_finetuning_SA_DC:45] \n",
            "    Config Params:\n",
            "    trainer:\n",
            "      gpus: 1\n",
            "      num_nodes: 1\n",
            "      max_epochs: 4\n",
            "      max_steps: null\n",
            "      accumulate_grad_batches: 1\n",
            "      gradient_clip_val: 0.0\n",
            "      amp_level: O0\n",
            "      precision: 32\n",
            "      distributed_backend: ddp\n",
            "      row_log_interval: 1\n",
            "      val_check_interval: 1.0\n",
            "      resume_from_checkpoint: null\n",
            "      num_sanity_val_steps: 0\n",
            "      checkpoint_callback: false\n",
            "      logger: false\n",
            "    model:\n",
            "      nemo_path: null\n",
            "      tokenizer:\n",
            "        tokenizer_name: ${model.language_model.pretrained_model_name}\n",
            "        vocab_file: null\n",
            "        tokenizer_model: null\n",
            "        special_tokens: null\n",
            "      language_model:\n",
            "        pretrained_model_name: bert-base-uncased\n",
            "        lm_checkpoint: /content/PretrainingBERTFromText--end.ckpt\n",
            "        config_file: null\n",
            "        config: null\n",
            "      classifier_head:\n",
            "        num_output_layers: 2\n",
            "        fc_dropout: 0.1\n",
            "      dataset:\n",
            "        num_classes: 3\n",
            "        do_lower_case: false\n",
            "        max_seq_length: 128\n",
            "        class_balancing: null\n",
            "        use_cache: false\n",
            "        num_workers: 3\n",
            "        drop_last: false\n",
            "        pin_memory: false\n",
            "      train_ds:\n",
            "        file_path: /content/train.tsv\n",
            "        batch_size: 4\n",
            "        shuffle: true\n",
            "        num_samples: -1\n",
            "        num_workers: ${model.dataset.num_workers}\n",
            "        drop_last: ${model.dataset.drop_last}\n",
            "        pin_memory: ${model.dataset.pin_memory}\n",
            "      validation_ds:\n",
            "        file_path: /content/valid.tsv\n",
            "        batch_size: 4\n",
            "        shuffle: false\n",
            "        num_samples: -1\n",
            "        num_workers: ${model.dataset.num_workers}\n",
            "        drop_last: ${model.dataset.drop_last}\n",
            "        pin_memory: ${model.dataset.pin_memory}\n",
            "      test_ds:\n",
            "        file_path: /content/test.tsv\n",
            "        batch_size: 4\n",
            "        shuffle: false\n",
            "        num_samples: -1\n",
            "        num_workers: ${model.dataset.num_workers}\n",
            "        drop_last: ${model.dataset.drop_last}\n",
            "        pin_memory: ${model.dataset.pin_memory}\n",
            "      optim:\n",
            "        name: adam\n",
            "        lr: 2.0e-05\n",
            "        betas:\n",
            "        - 0.9\n",
            "        - 0.999\n",
            "        weight_decay: 0.01\n",
            "        sched:\n",
            "          name: WarmupAnnealing\n",
            "          warmup_steps: null\n",
            "          warmup_ratio: 0.1\n",
            "          last_epoch: -1\n",
            "          monitor: val_loss\n",
            "          reduce_on_plateau: false\n",
            "    exp_manager:\n",
            "      exp_dir: null\n",
            "      name: SentimentAnalysis\n",
            "      create_tensorboard_logger: true\n",
            "      create_checkpoint_callback: true\n",
            "    \n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "CUDA_VISIBLE_DEVICES: [0]\n",
            "[NeMo I 2022-07-15 08:09:17 exp_manager:169] Experiments will be logged at /content/nemo_experiments/SentimentAnalysis/2022-07-15_08-09-17\n",
            "[NeMo I 2022-07-15 08:09:17 exp_manager:503] TensorboardLogger has been set up\n",
            "[NeMo W 2022-07-15 08:09:17 exp_manager:537] trainer had a weights_save_path of cwd(). This was ignored.\n",
            "Downloading: 100% 433/433 [00:00<00:00, 324kB/s]\n",
            "Downloading: 100% 232k/232k [00:00<00:00, 2.83MB/s]\n",
            "Using bos_token, but it is not set yet.\n",
            "Using eos_token, but it is not set yet.\n",
            "[NeMo I 2022-07-15 08:09:18 text_classification_dataset:119] Read 4356 examples from /content/train.tsv.\n",
            "[NeMo I 2022-07-15 08:09:18 text_classification_dataset:232] *** Example ***\n",
            "[NeMo I 2022-07-15 08:09:18 text_classification_dataset:233] example 0: ['5915', '8644', 'انت', 'ماتعرفش', 'مصر', 'و', 'قانونها', 'و', 'ماتعرفش', 'الخليج', 'و', 'قانونهم', 'مصر', 'سايبه', 'توصل', 'لمرا', 'تنتقم', 'بايدها', 'تقتل', 'بدم', 'بااارد', 'و', 'إعدام', 'و', 'الصغار', 'يتيتموا', 'مصر', 'بلاد', 'صغارهم', 'في', 'الشوارع', 'متشردين', 'تحب', 'كيما', 'مصر', 'الخليج', 'المرا', 'تقسم', 'شهريه', 'راجلها', 'و', 'تسكن', 'في', 'الفيلا', 'فرقو', 'مع', 'صغارو', 'و', 'تجيب', 'راجل', 'جديد', 'حتى', 'زواج', 'متعه', 'و', 'هو', 'يصرف', 'على', 'صغاره', 'في', 'احسن', 'المدارس', 'مثلا', 'قطر', 'حقوق', 'المرأه', 'توا', 'كيما', 'سويسرا', 'مخك', 'يحبس', 'المرا', 'راقده', 'بالخدام', 'و', 'الشوفور', 'و', 'الجاردينيي', 'و', 'هي', 'من', 'صالون', 'لصالون', 'و', 'توصل', 'تصوحب', 'و', 'تحوس', 'خارج', 'الخليج', 'و', 'تعمل', 'عمليات', 'تجميل', 'عام', 'عن', 'عام', 'ماتعقلهاااش', 'جمله', 'لا', 'نقاب', 'فقط', 'حجاب', 'عادي', 'و', 'قصه', 'لبره', 'ماتحكيش', 'على', 'بلدان', 'ماتعرفهمش', 'انا', 'الخليج', 'عايشه', 'فيه', 'و', 'الجنسيات', 'الكل', 'اللطف', 'المرا', 'سايبه', 'و', 'الراجل', 'سايب', 'الا', 'من', 'رحم', 'ربي', 'بفلوسهم', 'يبدلوا', 'اما', 'يتلدغو', 'بالقانون', 'و', 'ماعادش', 'قادرين', 'يعرس', 'بترتيبه', 'تعيش', 'و', 'تجيه', 'اقل', 'تكلفه', 'و', 'لاباس', 'متهني', 'برشه', 'عرسو', 'بتوانسه', 'و', 'فرحااانين', 'ثقافه', 'و', 'مقديه', 'و', 'زينه', 'من', 'لخر', 'اللي', 'يحب', 'يهني', 'على', 'روحه', 'يهني', 'و', 'اللي', 'مايحبش', 'يقول', 'مانجمتش', 'و', 'يستعرف', 'باغلاطه', 'موش', 'كان', 'المرا', 'السبب', 'المراه', 'حبيسه', 'في', 'داره', 'لا', 'تحكم', 'لا', 'تدري', 'تعطي', 'الثيقه', 'و', 'مبعد', 'تولي', 'مشاكل', 'و', 'الله', 'نحكيلك', 'باللي', 'شفته', 'في', 'الغربه', 'التونسيات', 'من', 'احسن', 'الناس', 'تعرس', 'تشد', 'بلاصتها', 'hate']\n",
            "[NeMo I 2022-07-15 08:09:18 text_classification_dataset:234] subtokens: [CLS] 59 ##15 86 ##44 ا ##ن ##ت م ##ا ##ت ##ع ##ر ##ف ##ش م ##ص ##ر و ق ##ان ##و ##ن ##ه ##ا و م ##ا ##ت ##ع ##ر ##ف ##ش ا ##ل ##خ ##ل ##ي ##ج و ق ##ان ##و ##ن ##ه ##م م ##ص ##ر س ##ا ##ي ##ب ##ه ت ##و ##ص ##ل ل ##م ##ر ##ا ت ##ن ##ت ##ق ##م ب ##ا ##ي ##د ##ه ##ا ت ##ق ##ت ##ل ب ##د ##م ب ##ا ##ا ##ا ##ر ##د و ا ##ع ##د ##ا ##م و ا ##ل ##ص ##غ ##ا ##ر ي ##ت ##ي ##ت ##م ##و ##ا م ##ص ##ر ب ##ل ##ا ##د ص ##غ ##ا ##ر ##ه ##م ف ##ي ا ##ل ##ش ##و ##ا ##ر ##ع [SEP]\n",
            "[NeMo I 2022-07-15 08:09:18 text_classification_dataset:235] input_ids: 101 5354 16068 6564 22932 1270 15915 29817 1295 25573 29817 29830 17149 29833 29825 1295 29826 17149 1298 1292 18511 29836 15915 14157 25573 1298 1295 25573 29817 29830 17149 29833 29825 1270 23673 29821 23673 14498 29819 1298 1292 18511 29836 15915 14157 22192 1295 29826 17149 1282 25573 14498 29816 14157 1273 29836 29826 23673 1294 22192 17149 25573 1273 15915 29817 29834 22192 1271 25573 14498 15394 14157 25573 1273 29834 29817 23673 1271 15394 22192 1271 25573 25573 25573 17149 15394 1298 1270 29830 15394 25573 22192 1298 1270 23673 29826 29831 25573 17149 1300 29817 14498 29817 22192 29836 25573 1295 29826 17149 1271 23673 25573 15394 1284 29831 25573 17149 14157 22192 1291 14498 1270 23673 29825 29836 25573 17149 29830 102\n",
            "[NeMo I 2022-07-15 08:09:18 text_classification_dataset:236] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "[NeMo I 2022-07-15 08:09:18 text_classification_dataset:237] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "[NeMo I 2022-07-15 08:09:18 text_classification_dataset:238] label: 2\n",
            "[NeMo I 2022-07-15 08:09:18 text_classification_dataset:232] *** Example ***\n",
            "[NeMo I 2022-07-15 08:09:18 text_classification_dataset:233] example 1: ['640', '640', 'ربي', 'يطيرك', 'لافغانستان', 'امين', 'normal']\n",
            "[NeMo I 2022-07-15 08:09:18 text_classification_dataset:234] subtokens: [CLS] 640 640 ر ##ب ##ي ي ##ط ##ي ##ر ##ك ل ##ا ##ف ##غ ##ان ##س ##ت ##ان ا ##م ##ي ##ن normal [SEP]\n",
            "[NeMo I 2022-07-15 08:09:18 text_classification_dataset:235] input_ids: 101 19714 19714 1280 29816 14498 1300 29828 14498 17149 29835 1294 25573 29833 29831 18511 29824 29817 18511 1270 22192 14498 15915 3671 102\n",
            "[NeMo I 2022-07-15 08:09:18 text_classification_dataset:236] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "[NeMo I 2022-07-15 08:09:18 text_classification_dataset:237] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "[NeMo I 2022-07-15 08:09:18 text_classification_dataset:238] label: 0\n",
            "[NeMo W 2022-07-15 08:09:24 text_classification_dataset:245] Found 549 out of 4356 sentences with more than 128 subtokens. Truncated long sentences from the end.\n",
            "[NeMo I 2022-07-15 08:09:24 data_preprocessing:295] Some stats of the lengths of the sequences:\n",
            "[NeMo I 2022-07-15 08:09:24 data_preprocessing:301] Min: 8 |                  Max: 129 |                  Mean: 58.55211202938476 |                  Median: 46.0\n",
            "[NeMo I 2022-07-15 08:09:24 data_preprocessing:303] 75 percentile: 83.00\n",
            "[NeMo I 2022-07-15 08:09:24 data_preprocessing:304] 99 percentile: 129.00\n",
            "[NeMo I 2022-07-15 08:09:24 text_classification_dataset:119] Read 485 examples from /content/valid.tsv.\n",
            "[NeMo I 2022-07-15 08:09:24 text_classification_dataset:232] *** Example ***\n",
            "[NeMo I 2022-07-15 08:09:24 text_classification_dataset:233] example 0: ['1331', '1331', 'يعطيها', 'الصحة', 'المقدمة', 'normal']\n",
            "[NeMo I 2022-07-15 08:09:24 text_classification_dataset:234] subtokens: [CLS] 133 ##1 133 ##1 ي ##ع ##ط ##ي ##ه ##ا ا ##ل ##ص ##ح ##ة ا ##ل ##م ##ق ##د ##م ##ة normal [SEP]\n",
            "[NeMo I 2022-07-15 08:09:24 text_classification_dataset:235] input_ids: 101 14506 2487 14506 2487 1300 29830 29828 14498 14157 25573 1270 23673 29826 29820 19433 1270 23673 22192 29834 15394 22192 19433 3671 102\n",
            "[NeMo I 2022-07-15 08:09:24 text_classification_dataset:236] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "[NeMo I 2022-07-15 08:09:24 text_classification_dataset:237] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "[NeMo I 2022-07-15 08:09:24 text_classification_dataset:238] label: 0\n",
            "[NeMo I 2022-07-15 08:09:24 text_classification_dataset:232] *** Example ***\n",
            "[NeMo I 2022-07-15 08:09:24 text_classification_dataset:233] example 1: ['1015', '1015', 'يولى', 'مثلكم', 'normal']\n",
            "[NeMo I 2022-07-15 08:09:24 text_classification_dataset:234] subtokens: [CLS] 101 ##5 101 ##5 ي ##و ##ل ##ى م ##ث ##ل ##ك ##م normal [SEP]\n",
            "[NeMo I 2022-07-15 08:09:24 text_classification_dataset:235] input_ids: 101 7886 2629 7886 2629 1300 29836 23673 29837 1295 29818 23673 29835 22192 3671 102\n",
            "[NeMo I 2022-07-15 08:09:24 text_classification_dataset:236] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "[NeMo I 2022-07-15 08:09:24 text_classification_dataset:237] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "[NeMo I 2022-07-15 08:09:24 text_classification_dataset:238] label: 0\n",
            "[NeMo W 2022-07-15 08:09:24 text_classification_dataset:245] Found 54 out of 485 sentences with more than 128 subtokens. Truncated long sentences from the end.\n",
            "[NeMo I 2022-07-15 08:09:24 data_preprocessing:295] Some stats of the lengths of the sequences:\n",
            "[NeMo I 2022-07-15 08:09:24 data_preprocessing:301] Min: 9 |                  Max: 129 |                  Mean: 56.04123711340206 |                  Median: 42.0\n",
            "[NeMo I 2022-07-15 08:09:24 data_preprocessing:303] 75 percentile: 77.00\n",
            "[NeMo I 2022-07-15 08:09:24 data_preprocessing:304] 99 percentile: 129.00\n",
            "[NeMo I 2022-07-15 08:09:25 text_classification_dataset:119] Read 1211 examples from /content/test.tsv.\n",
            "[NeMo I 2022-07-15 08:09:25 text_classification_dataset:232] *** Example ***\n",
            "[NeMo I 2022-07-15 08:09:25 text_classification_dataset:233] example 0: ['937', 'سلام', 'بالله', 'نشكركم', 'الخدمة', 'تقدموا', 'فيها', 'الله', 'يرحم', 'ول', 'ديكم', 'مكمش', 'مقصرين', 'بالاخص', 'نشكركم', 'الأوفر', 'الجديد', 'عملتوه', 'تلقا', 'حاجة', 'تصرلي', 'لحكية', 'بالله', 'عليكم', 'لواحد', 'يجيب', 'فيهم', 'زبلة', 'الفلوس', 'يزيو', 'احشموا', 'روحكم', 'نكلمكم', 'نشوف', 'الحكاية', 'يقولولي', 'وقتلي', 'قولتولي', 'الحكاية', 'بعثتولي', 'نحيه', 'نحيتوا', 'باقي', 'لحكاية', 'عندي', 'نعمل', 'نهار', 'الحكاية', 'يزيوا', 'احشموا', 'احشموا', 'normal']\n",
            "[NeMo I 2022-07-15 08:09:25 text_classification_dataset:234] subtokens: [CLS] 93 ##7 س ##ل ##ا ##م ب ##ا ##ل ##ل ##ه ن ##ش ##ك ##ر ##ك ##م ا ##ل ##خ ##د ##م ##ة ت ##ق ##د ##م ##و ##ا ف ##ي ##ه ##ا ا ##ل ##ل ##ه ي ##ر ##ح ##م و ##ل د ##ي ##ك ##م م ##ك ##م ##ش م ##ق ##ص ##ر ##ي ##ن ب ##ا ##ل ##ا ##خ ##ص ن ##ش ##ك ##ر ##ك ##م ا ##ل ##ا ##و ##ف ##ر ا ##ل ##ج ##د ##ي ##د ع ##م ##ل ##ت ##و ##ه ت ##ل ##ق ##ا ح ##ا ##ج ##ة ت ##ص ##ر ##ل ##ي ل ##ح ##ك ##ي ##ة ب ##ا ##ل ##ل ##ه ع ##ل ##ي ##ك ##م ل ##و ##ا ##ح ##د ي ##ج ##ي ##ب ف ##ي ##ه [SEP]\n",
            "[NeMo I 2022-07-15 08:09:25 text_classification_dataset:235] input_ids: 101 6109 2581 1282 23673 25573 22192 1271 25573 23673 23673 14157 1296 29825 29835 17149 29835 22192 1270 23673 29821 15394 22192 19433 1273 29834 15394 22192 29836 25573 1291 14498 14157 25573 1270 23673 23673 14157 1300 17149 29820 22192 1298 23673 1278 14498 29835 22192 1295 29835 22192 29825 1295 29834 29826 17149 14498 15915 1271 25573 23673 25573 29821 29826 1296 29825 29835 17149 29835 22192 1270 23673 25573 29836 29833 17149 1270 23673 29819 15394 14498 15394 1288 22192 23673 29817 29836 14157 1273 23673 29834 25573 1276 25573 29819 19433 1273 29826 17149 23673 14498 1294 29820 29835 14498 19433 1271 25573 23673 23673 14157 1288 23673 14498 29835 22192 1294 29836 25573 29820 15394 1300 29819 14498 29816 1291 14498 14157 102\n",
            "[NeMo I 2022-07-15 08:09:25 text_classification_dataset:236] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "[NeMo I 2022-07-15 08:09:25 text_classification_dataset:237] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "[NeMo I 2022-07-15 08:09:25 text_classification_dataset:238] label: 0\n",
            "[NeMo I 2022-07-15 08:09:25 text_classification_dataset:232] *** Example ***\n",
            "[NeMo I 2022-07-15 08:09:25 text_classification_dataset:233] example 1: ['3712', 'حرية', 'الإسلام', 'انتهى', 'hate']\n",
            "[NeMo I 2022-07-15 08:09:25 text_classification_dataset:234] subtokens: [CLS] 37 ##12 ح ##ر ##ي ##ة ا ##ل ##ا ##س ##ل ##ا ##م ا ##ن ##ت ##ه ##ى hate [SEP]\n",
            "[NeMo I 2022-07-15 08:09:25 text_classification_dataset:235] input_ids: 101 4261 12521 1276 17149 14498 19433 1270 23673 25573 29824 23673 25573 22192 1270 15915 29817 14157 29837 5223 102\n",
            "[NeMo I 2022-07-15 08:09:25 text_classification_dataset:236] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "[NeMo I 2022-07-15 08:09:25 text_classification_dataset:237] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "[NeMo I 2022-07-15 08:09:25 text_classification_dataset:238] label: 2\n",
            "[NeMo W 2022-07-15 08:09:26 text_classification_dataset:245] Found 135 out of 1211 sentences with more than 128 subtokens. Truncated long sentences from the end.\n",
            "[NeMo I 2022-07-15 08:09:26 data_preprocessing:295] Some stats of the lengths of the sequences:\n",
            "[NeMo I 2022-07-15 08:09:26 data_preprocessing:301] Min: 6 |                  Max: 129 |                  Mean: 54.92402972749794 |                  Median: 42.0\n",
            "[NeMo I 2022-07-15 08:09:26 data_preprocessing:303] 75 percentile: 77.00\n",
            "[NeMo I 2022-07-15 08:09:26 data_preprocessing:304] 99 percentile: 129.00\n",
            "Downloading: 100% 440M/440M [00:06<00:00, 63.8MB/s]\n",
            "[NeMo I 2022-07-15 08:09:39 bert_module:54] Restoring weights from /content/PretrainingBERTFromText--end.ckpt\n",
            "[NeMo I 2022-07-15 08:09:48 bert_module:82] Weights for BertEncoder restored from /content/PretrainingBERTFromText--end.ckpt\n",
            "[NeMo I 2022-07-15 08:09:48 bert_finetuning_SA_DC:54] ===========================================================================================\n",
            "[NeMo I 2022-07-15 08:09:48 bert_finetuning_SA_DC:56] Starting training...\n",
            "[NeMo W 2022-07-15 08:09:48 nemo_logging:349] /usr/local/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: WORLD_SIZE environment variable (2) is not equal to the computed world size (1). Ignored.\n",
            "      warnings.warn(*args, **kwargs)\n",
            "    \n",
            "initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "distributed_backend=ddp\n",
            "All DDP processes registered. Starting ddp with 1 processes\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[NeMo I 2022-07-15 08:09:48 modelPT:572] Optimizer config = Adam (\n",
            "    Parameter Group 0\n",
            "        amsgrad: False\n",
            "        betas: [0.9, 0.999]\n",
            "        eps: 1e-08\n",
            "        lr: 2e-05\n",
            "        weight_decay: 0.01\n",
            "    )\n",
            "[NeMo I 2022-07-15 08:09:48 lr_scheduler:545] Scheduler \"<nemo.core.optim.lr_scheduler.WarmupAnnealing object at 0x7fc72fba3f90>\" \n",
            "    will be used during training (effective maximum steps = 4356) - \n",
            "    Parameters : \n",
            "    (warmup_steps: null\n",
            "    warmup_ratio: 0.1\n",
            "    last_epoch: -1\n",
            "    max_steps: 4356\n",
            "    )\n",
            "[NeMo W 2022-07-15 08:09:49 nemo_logging:349] /usr/local/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: Could not log computational graph since the `model.example_input_array` attribute is not set or `input_array` was not given\n",
            "      warnings.warn(*args, **kwargs)\n",
            "    \n",
            "\n",
            "  | Name                  | Type                 | Params\n",
            "---------------------------------------------------------------\n",
            "0 | bert_model            | BertEncoder          | 109 M \n",
            "1 | classifier            | SequenceClassifier   | 592 K \n",
            "2 | loss                  | CrossEntropyLoss     | 0     \n",
            "3 | classification_report | ClassificationReport | 0     \n",
            "Epoch 0:  90% 1089/1211 [02:26<00:16,  7.45it/s, loss=0.498, v_num=9-17]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 0:  90% 1091/1211 [02:26<00:16,  7.45it/s, loss=0.498, v_num=9-17]\n",
            "Epoch 0:  91% 1096/1211 [02:26<00:15,  7.48it/s, loss=0.498, v_num=9-17]\n",
            "Validating:   7% 9/122 [00:00<00:04, 25.77it/s]\u001b[A\n",
            "Epoch 0:  91% 1101/1211 [02:26<00:14,  7.51it/s, loss=0.498, v_num=9-17]\n",
            "Epoch 0:  91% 1106/1211 [02:26<00:13,  7.53it/s, loss=0.498, v_num=9-17]\n",
            "Epoch 0:  92% 1111/1211 [02:26<00:13,  7.56it/s, loss=0.498, v_num=9-17]\n",
            "Epoch 0:  92% 1116/1211 [02:27<00:12,  7.59it/s, loss=0.498, v_num=9-17]\n",
            "Validating:  23% 28/122 [00:00<00:02, 32.97it/s]\u001b[A\n",
            "Epoch 0:  93% 1121/1211 [02:27<00:11,  7.61it/s, loss=0.498, v_num=9-17]\n",
            "Epoch 0:  93% 1126/1211 [02:27<00:11,  7.64it/s, loss=0.498, v_num=9-17]\n",
            "Epoch 0:  93% 1131/1211 [02:27<00:10,  7.66it/s, loss=0.498, v_num=9-17]\n",
            "Epoch 0:  94% 1136/1211 [02:27<00:09,  7.69it/s, loss=0.498, v_num=9-17]\n",
            "Validating:  39% 48/122 [00:01<00:02, 32.92it/s]\u001b[A\n",
            "Epoch 0:  94% 1141/1211 [02:27<00:09,  7.72it/s, loss=0.498, v_num=9-17]\n",
            "Epoch 0:  95% 1146/1211 [02:28<00:08,  7.74it/s, loss=0.498, v_num=9-17]\n",
            "Epoch 0:  95% 1151/1211 [02:28<00:07,  7.77it/s, loss=0.498, v_num=9-17]\n",
            "Epoch 0:  95% 1156/1211 [02:28<00:07,  7.79it/s, loss=0.498, v_num=9-17]\n",
            "Epoch 0:  96% 1161/1211 [02:28<00:06,  7.82it/s, loss=0.498, v_num=9-17]\n",
            "Validating:  60% 73/122 [00:02<00:01, 32.82it/s]\u001b[A\n",
            "Epoch 0:  96% 1166/1211 [02:28<00:05,  7.84it/s, loss=0.498, v_num=9-17]\n",
            "Epoch 0:  97% 1171/1211 [02:28<00:05,  7.87it/s, loss=0.498, v_num=9-17]\n",
            "Epoch 0:  97% 1176/1211 [02:28<00:04,  7.89it/s, loss=0.498, v_num=9-17]\n",
            "Epoch 0:  98% 1181/1211 [02:29<00:03,  7.92it/s, loss=0.498, v_num=9-17]\n",
            "Validating:  76% 93/122 [00:02<00:00, 31.82it/s]\u001b[A\n",
            "Epoch 0:  98% 1186/1211 [02:29<00:03,  7.95it/s, loss=0.498, v_num=9-17]\n",
            "Epoch 0:  98% 1191/1211 [02:29<00:02,  7.97it/s, loss=0.498, v_num=9-17]\n",
            "Epoch 0:  99% 1196/1211 [02:29<00:01,  8.00it/s, loss=0.498, v_num=9-17]\n",
            "Epoch 0:  99% 1201/1211 [02:29<00:01,  8.02it/s, loss=0.498, v_num=9-17]\n",
            "Validating:  93% 113/122 [00:03<00:00, 33.91it/s]\u001b[A\n",
            "Epoch 0: 100% 1206/1211 [02:29<00:00,  8.05it/s, loss=0.498, v_num=9-17]\n",
            "Epoch 0: 100% 1211/1211 [02:30<00:00,  8.07it/s, loss=0.498, v_num=9-17][NeMo I 2022-07-15 08:12:19 classification_report:142] \n",
            "    label                                                precision    recall       f1           support   \n",
            "    label_id: 0                                             85.50      92.93      89.06        184\n",
            "    label_id: 1                                             79.33      87.12      83.04        163\n",
            "    label_id: 2                                             92.45      71.01      80.33        138\n",
            "    -------------------\n",
            "    micro avg                                               84.74      84.74      84.74        485\n",
            "    macro avg                                               85.76      83.69      84.14        485\n",
            "    weighted avg                                            85.40      84.74      84.55        485\n",
            "    \n",
            "Epoch 0: 100% 1211/1211 [02:30<00:00,  8.07it/s, loss=0.498, v_num=9-17]\n",
            "                                                 \u001b[Atcmalloc: large alloc 1094385664 bytes == 0x564b7c40e000 @  0x7fc7c5e9e615 0x564a61e2867c 0x564a61efc98b 0x564a61e291a2 0x564a61e0cc9d 0x7fc7c3030484 0x7fc7c3032534 0x7fc7c3001eb0 0x7fc7b394c435 0x7fc7b394899a 0x7fc7b394d5d9 0x7fc7c300fdab 0x7fc7c2c8e02a 0x564a61e9a427 0x564a61e9a5b6 0x564a61e9bb59 0x564a61ec674a 0x564a61e09af2 0x564a61e38030 0x564a61e9b9c8 0x564a61ec24ac 0x564a61e09af2 0x564a61e38030 0x564a61e9b9c8 0x564a61ec674a 0x564a61e37e94 0x564a61e9b9c8 0x564a61ec24ac 0x564a61e09af2 0x564a61e38030 0x564a61e9b9c8\n",
            "tcmalloc: large alloc 1367982080 bytes == 0x564b1d324000 @  0x7fc7c5e9e615 0x564a61e2867c 0x564a61efc98b 0x564a61e291a2 0x564a61e0cc9d 0x7fc7c3030484 0x7fc7c3032534 0x7fc7c3001eb0 0x7fc7b394c435 0x7fc7b394899a 0x7fc7b394d5d9 0x7fc7c300fdab 0x7fc7c2c8e02a 0x564a61e9a427 0x564a61e9a5b6 0x564a61e9bb59 0x564a61ec674a 0x564a61e09af2 0x564a61e38030 0x564a61e9b9c8 0x564a61ec24ac 0x564a61e09af2 0x564a61e38030 0x564a61e9b9c8 0x564a61ec674a 0x564a61e37e94 0x564a61e9b9c8 0x564a61ec24ac 0x564a61e09af2 0x564a61e38030 0x564a61e9b9c8\n",
            "tcmalloc: large alloc 1709981696 bytes == 0x564bbec26000 @  0x7fc7c5e9e615 0x564a61e2867c 0x564a61efc98b 0x564a61e291a2 0x564a61e0cc9d 0x7fc7c3030484 0x7fc7c3032534 0x7fc7c3001eb0 0x7fc7b394c435 0x7fc7b394899a 0x7fc7b394d5d9 0x7fc7c300fdab 0x7fc7c2c8e02a 0x564a61e9a427 0x564a61e9a5b6 0x564a61e9bb59 0x564a61ec674a 0x564a61e09af2 0x564a61e38030 0x564a61e9b9c8 0x564a61ec24ac 0x564a61e09af2 0x564a61e38030 0x564a61e9b9c8 0x564a61ec674a 0x564a61e37e94 0x564a61e9b9c8 0x564a61ec24ac 0x564a61e09af2 0x564a61e38030 0x564a61e9b9c8\n",
            "tcmalloc: large alloc 1709981696 bytes == 0x564bbec26000 @  0x7fc7c5e9e615 0x564a61e2867c 0x564a61efc98b 0x564a61e291a2 0x564a61e0cc9d 0x7fc7c3030484 0x7fc7c3032534 0x7fc7c3001eb0 0x7fc7b394c435 0x7fc7b394899a 0x7fc7b394d5d9 0x7fc7c300fdab 0x7fc7c2c8e02a 0x564a61e9a427 0x564a61e9a5b6 0x564a61e9bb59 0x564a61ec674a 0x564a61e09af2 0x564a61e38030 0x564a61e9b9c8 0x564a61ec24ac 0x564a61e09af2 0x564a61e38030 0x564a61e9b9c8 0x564a61ec674a 0x564a61e37e94 0x564a61e9b9c8 0x564a61ec24ac 0x564a61e09af2 0x564a61e38030 0x564a61e9b9c8\n",
            "Epoch 1:  90% 1089/1211 [02:29<00:16,  7.27it/s, loss=0.258, v_num=9-17]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 1:  90% 1091/1211 [02:30<00:16,  7.27it/s, loss=0.258, v_num=9-17]\n",
            "Epoch 1:  90% 1095/1211 [02:30<00:15,  7.29it/s, loss=0.258, v_num=9-17]\n",
            "Epoch 1:  91% 1099/1211 [02:30<00:15,  7.31it/s, loss=0.258, v_num=9-17]\n",
            "Epoch 1:  91% 1103/1211 [02:30<00:14,  7.33it/s, loss=0.258, v_num=9-17]\n",
            "Epoch 1:  91% 1107/1211 [02:30<00:14,  7.35it/s, loss=0.258, v_num=9-17]\n",
            "Epoch 1:  92% 1111/1211 [02:30<00:13,  7.37it/s, loss=0.258, v_num=9-17]\n",
            "Epoch 1:  92% 1115/1211 [02:30<00:12,  7.40it/s, loss=0.258, v_num=9-17]\n",
            "Epoch 1:  92% 1119/1211 [02:30<00:12,  7.42it/s, loss=0.258, v_num=9-17]\n",
            "Epoch 1:  93% 1123/1211 [02:31<00:11,  7.44it/s, loss=0.258, v_num=9-17]\n",
            "Epoch 1:  93% 1127/1211 [02:31<00:11,  7.46it/s, loss=0.258, v_num=9-17]\n",
            "Epoch 1:  93% 1131/1211 [02:31<00:10,  7.48it/s, loss=0.258, v_num=9-17]\n",
            "Epoch 1:  94% 1135/1211 [02:31<00:10,  7.50it/s, loss=0.258, v_num=9-17]\n",
            "Epoch 1:  94% 1139/1211 [02:31<00:09,  7.52it/s, loss=0.258, v_num=9-17]\n",
            "Epoch 1:  94% 1143/1211 [02:31<00:09,  7.54it/s, loss=0.258, v_num=9-17]\n",
            "Epoch 1:  95% 1147/1211 [02:31<00:08,  7.56it/s, loss=0.258, v_num=9-17]\n",
            "Epoch 1:  95% 1151/1211 [02:31<00:07,  7.58it/s, loss=0.258, v_num=9-17]\n",
            "Epoch 1:  95% 1155/1211 [02:31<00:07,  7.60it/s, loss=0.258, v_num=9-17]\n",
            "Epoch 1:  96% 1159/1211 [02:32<00:06,  7.62it/s, loss=0.258, v_num=9-17]\n",
            "Epoch 1:  96% 1163/1211 [02:32<00:06,  7.64it/s, loss=0.258, v_num=9-17]\n",
            "Epoch 1:  96% 1167/1211 [02:32<00:05,  7.66it/s, loss=0.258, v_num=9-17]\n",
            "Epoch 1:  97% 1171/1211 [02:32<00:05,  7.68it/s, loss=0.258, v_num=9-17]\n",
            "Epoch 1:  97% 1175/1211 [02:32<00:04,  7.70it/s, loss=0.258, v_num=9-17]\n",
            "Epoch 1:  97% 1179/1211 [02:32<00:04,  7.72it/s, loss=0.258, v_num=9-17]\n",
            "Epoch 1:  98% 1183/1211 [02:32<00:03,  7.74it/s, loss=0.258, v_num=9-17]\n",
            "Epoch 1:  98% 1187/1211 [02:32<00:03,  7.76it/s, loss=0.258, v_num=9-17]\n",
            "Epoch 1:  98% 1191/1211 [02:33<00:02,  7.78it/s, loss=0.258, v_num=9-17]\n",
            "Epoch 1:  99% 1195/1211 [02:33<00:02,  7.80it/s, loss=0.258, v_num=9-17]\n",
            "Epoch 1:  99% 1199/1211 [02:33<00:01,  7.82it/s, loss=0.258, v_num=9-17]\n",
            "Epoch 1:  99% 1203/1211 [02:33<00:01,  7.84it/s, loss=0.258, v_num=9-17]\n",
            "Epoch 1: 100% 1207/1211 [02:33<00:00,  7.86it/s, loss=0.258, v_num=9-17]\n",
            "Epoch 1: 100% 1211/1211 [02:33<00:00,  7.88it/s, loss=0.258, v_num=9-17][NeMo I 2022-07-15 08:15:14 classification_report:142] \n",
            "    label                                                precision    recall       f1           support   \n",
            "    label_id: 0                                             93.16      96.20      94.65        184\n",
            "    label_id: 1                                             88.95      98.77      93.60        163\n",
            "    label_id: 2                                             98.25      81.16      88.89        138\n",
            "    -------------------\n",
            "    micro avg                                               92.78      92.78      92.78        485\n",
            "    macro avg                                               93.45      92.04      92.38        485\n",
            "    weighted avg                                            93.19      92.78      92.66        485\n",
            "    \n",
            "Epoch 1: 100% 1211/1211 [02:33<00:00,  7.87it/s, loss=0.258, v_num=9-17]\n",
            "Epoch 2:  90% 1089/1211 [02:29<00:16,  7.28it/s, loss=0.165, v_num=9-17]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 2:  90% 1091/1211 [02:29<00:16,  7.28it/s, loss=0.165, v_num=9-17]\n",
            "Epoch 2:  90% 1095/1211 [02:30<00:15,  7.30it/s, loss=0.165, v_num=9-17]\n",
            "Epoch 2:  91% 1099/1211 [02:30<00:15,  7.32it/s, loss=0.165, v_num=9-17]\n",
            "Epoch 2:  91% 1103/1211 [02:30<00:14,  7.34it/s, loss=0.165, v_num=9-17]\n",
            "Epoch 2:  91% 1107/1211 [02:30<00:14,  7.36it/s, loss=0.165, v_num=9-17]\n",
            "Epoch 2:  92% 1111/1211 [02:30<00:13,  7.38it/s, loss=0.165, v_num=9-17]\n",
            "Epoch 2:  92% 1115/1211 [02:30<00:12,  7.40it/s, loss=0.165, v_num=9-17]\n",
            "Epoch 2:  92% 1119/1211 [02:30<00:12,  7.42it/s, loss=0.165, v_num=9-17]\n",
            "Epoch 2:  93% 1123/1211 [02:30<00:11,  7.44it/s, loss=0.165, v_num=9-17]\n",
            "Epoch 2:  93% 1127/1211 [02:31<00:11,  7.46it/s, loss=0.165, v_num=9-17]\n",
            "Epoch 2:  93% 1131/1211 [02:31<00:10,  7.48it/s, loss=0.165, v_num=9-17]\n",
            "Epoch 2:  94% 1135/1211 [02:31<00:10,  7.51it/s, loss=0.165, v_num=9-17]\n",
            "Epoch 2:  94% 1139/1211 [02:31<00:09,  7.53it/s, loss=0.165, v_num=9-17]\n",
            "Epoch 2:  94% 1143/1211 [02:31<00:09,  7.55it/s, loss=0.165, v_num=9-17]\n",
            "Epoch 2:  95% 1147/1211 [02:31<00:08,  7.57it/s, loss=0.165, v_num=9-17]\n",
            "Epoch 2:  95% 1151/1211 [02:31<00:07,  7.59it/s, loss=0.165, v_num=9-17]\n",
            "Epoch 2:  95% 1155/1211 [02:31<00:07,  7.61it/s, loss=0.165, v_num=9-17]\n",
            "Epoch 2:  96% 1159/1211 [02:31<00:06,  7.63it/s, loss=0.165, v_num=9-17]\n",
            "Epoch 2:  96% 1163/1211 [02:32<00:06,  7.65it/s, loss=0.165, v_num=9-17]\n",
            "Epoch 2:  96% 1167/1211 [02:32<00:05,  7.67it/s, loss=0.165, v_num=9-17]\n",
            "Epoch 2:  97% 1171/1211 [02:32<00:05,  7.69it/s, loss=0.165, v_num=9-17]\n",
            "Epoch 2:  97% 1175/1211 [02:32<00:04,  7.71it/s, loss=0.165, v_num=9-17]\n",
            "Epoch 2:  97% 1179/1211 [02:32<00:04,  7.73it/s, loss=0.165, v_num=9-17]\n",
            "Epoch 2:  98% 1183/1211 [02:32<00:03,  7.75it/s, loss=0.165, v_num=9-17]\n",
            "Epoch 2:  98% 1187/1211 [02:32<00:03,  7.77it/s, loss=0.165, v_num=9-17]\n",
            "Epoch 2:  98% 1191/1211 [02:32<00:02,  7.79it/s, loss=0.165, v_num=9-17]\n",
            "Epoch 2:  99% 1195/1211 [02:33<00:02,  7.81it/s, loss=0.165, v_num=9-17]\n",
            "Epoch 2:  99% 1199/1211 [02:33<00:01,  7.83it/s, loss=0.165, v_num=9-17]\n",
            "Epoch 2:  99% 1203/1211 [02:33<00:01,  7.85it/s, loss=0.165, v_num=9-17]\n",
            "Epoch 2: 100% 1207/1211 [02:33<00:00,  7.87it/s, loss=0.165, v_num=9-17]\n",
            "Epoch 2: 100% 1211/1211 [02:33<00:00,  7.89it/s, loss=0.165, v_num=9-17][NeMo I 2022-07-15 08:18:08 classification_report:142] \n",
            "    label                                                precision    recall       f1           support   \n",
            "    label_id: 0                                             94.65      96.20      95.42        184\n",
            "    label_id: 1                                             97.53      96.93      97.23        163\n",
            "    label_id: 2                                             93.38      92.03      92.70        138\n",
            "    -------------------\n",
            "    micro avg                                               95.26      95.26      95.26        485\n",
            "    macro avg                                               95.19      95.05      95.12        485\n",
            "    weighted avg                                            95.26      95.26      95.25        485\n",
            "    \n",
            "Epoch 2: 100% 1211/1211 [02:33<00:00,  7.88it/s, loss=0.165, v_num=9-17]\n",
            "Epoch 3:  90% 1089/1211 [02:29<00:16,  7.27it/s, loss=0.095, v_num=9-17]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 3:  90% 1091/1211 [02:30<00:16,  7.27it/s, loss=0.095, v_num=9-17]\n",
            "Epoch 3:  90% 1095/1211 [02:30<00:15,  7.29it/s, loss=0.095, v_num=9-17]\n",
            "Epoch 3:  91% 1099/1211 [02:30<00:15,  7.31it/s, loss=0.095, v_num=9-17]\n",
            "Epoch 3:  91% 1103/1211 [02:30<00:14,  7.33it/s, loss=0.095, v_num=9-17]\n",
            "Epoch 3:  91% 1107/1211 [02:30<00:14,  7.35it/s, loss=0.095, v_num=9-17]\n",
            "Epoch 3:  92% 1111/1211 [02:30<00:13,  7.37it/s, loss=0.095, v_num=9-17]\n",
            "Epoch 3:  92% 1115/1211 [02:30<00:12,  7.39it/s, loss=0.095, v_num=9-17]\n",
            "Epoch 3:  92% 1119/1211 [02:30<00:12,  7.41it/s, loss=0.095, v_num=9-17]\n",
            "Epoch 3:  93% 1123/1211 [02:31<00:11,  7.43it/s, loss=0.095, v_num=9-17]\n",
            "Epoch 3:  93% 1127/1211 [02:31<00:11,  7.46it/s, loss=0.095, v_num=9-17]\n",
            "Epoch 3:  93% 1131/1211 [02:31<00:10,  7.48it/s, loss=0.095, v_num=9-17]\n",
            "Epoch 3:  94% 1135/1211 [02:31<00:10,  7.50it/s, loss=0.095, v_num=9-17]\n",
            "Epoch 3:  94% 1139/1211 [02:31<00:09,  7.52it/s, loss=0.095, v_num=9-17]\n",
            "Epoch 3:  94% 1143/1211 [02:31<00:09,  7.54it/s, loss=0.095, v_num=9-17]\n",
            "Epoch 3:  95% 1147/1211 [02:31<00:08,  7.56it/s, loss=0.095, v_num=9-17]\n",
            "Epoch 3:  95% 1151/1211 [02:31<00:07,  7.58it/s, loss=0.095, v_num=9-17]\n",
            "Epoch 3:  95% 1155/1211 [02:32<00:07,  7.60it/s, loss=0.095, v_num=9-17]\n",
            "Epoch 3:  96% 1159/1211 [02:32<00:06,  7.62it/s, loss=0.095, v_num=9-17]\n",
            "Epoch 3:  96% 1163/1211 [02:32<00:06,  7.64it/s, loss=0.095, v_num=9-17]\n",
            "Epoch 3:  96% 1167/1211 [02:32<00:05,  7.66it/s, loss=0.095, v_num=9-17]\n",
            "Epoch 3:  97% 1171/1211 [02:32<00:05,  7.68it/s, loss=0.095, v_num=9-17]\n",
            "Epoch 3:  97% 1175/1211 [02:32<00:04,  7.70it/s, loss=0.095, v_num=9-17]\n",
            "Epoch 3:  97% 1179/1211 [02:32<00:04,  7.72it/s, loss=0.095, v_num=9-17]\n",
            "Epoch 3:  98% 1183/1211 [02:32<00:03,  7.74it/s, loss=0.095, v_num=9-17]\n",
            "Epoch 3:  98% 1187/1211 [02:32<00:03,  7.76it/s, loss=0.095, v_num=9-17]\n",
            "Epoch 3:  98% 1191/1211 [02:33<00:02,  7.78it/s, loss=0.095, v_num=9-17]\n",
            "Epoch 3:  99% 1195/1211 [02:33<00:02,  7.80it/s, loss=0.095, v_num=9-17]\n",
            "Epoch 3:  99% 1199/1211 [02:33<00:01,  7.82it/s, loss=0.095, v_num=9-17]\n",
            "Epoch 3:  99% 1203/1211 [02:33<00:01,  7.84it/s, loss=0.095, v_num=9-17]\n",
            "Epoch 3: 100% 1207/1211 [02:33<00:00,  7.86it/s, loss=0.095, v_num=9-17]\n",
            "Epoch 3: 100% 1211/1211 [02:33<00:00,  7.88it/s, loss=0.095, v_num=9-17][NeMo I 2022-07-15 08:21:01 classification_report:142] \n",
            "    label                                                precision    recall       f1           support   \n",
            "    label_id: 0                                             95.63      95.11      95.37        184\n",
            "    label_id: 1                                             95.24      98.16      96.68        163\n",
            "    label_id: 2                                             93.28      90.58      91.91        138\n",
            "    -------------------\n",
            "    micro avg                                               94.85      94.85      94.85        485\n",
            "    macro avg                                               94.72      94.62      94.65        485\n",
            "    weighted avg                                            94.83      94.85      94.82        485\n",
            "    \n",
            "Epoch 3: 100% 1211/1211 [02:33<00:00,  7.87it/s, loss=0.095, v_num=9-17]\n",
            "Epoch 3: 100% 1211/1211 [02:51<00:00,  7.07it/s, loss=0.095, v_num=9-17]Saving latest checkpoint..\n",
            "Epoch 3: 100% 1211/1211 [02:54<00:00,  6.95it/s, loss=0.095, v_num=9-17]\n",
            "[NeMo I 2022-07-15 08:21:31 bert_finetuning_SA_DC:58] Training finished!\n",
            "[NeMo I 2022-07-15 08:21:31 bert_finetuning_SA_DC:60] ===========================================================================================\n",
            "[NeMo I 2022-07-15 08:21:31 bert_finetuning_SA_DC:70] ===========================================================================================\n",
            "[NeMo I 2022-07-15 08:21:31 bert_finetuning_SA_DC:72] Starting the testing of the trained model on test set...\n",
            "initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "distributed_backend=ddp\n",
            "All DDP processes registered. Starting ddp with 1 processes\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[NeMo I 2022-07-15 08:21:32 modelPT:572] Optimizer config = Adam (\n",
            "    Parameter Group 0\n",
            "        amsgrad: False\n",
            "        betas: [0.9, 0.999]\n",
            "        eps: 1e-08\n",
            "        lr: 2e-05\n",
            "        weight_decay: 0.01\n",
            "    )\n",
            "[NeMo I 2022-07-15 08:21:32 lr_scheduler:545] Scheduler \"<nemo.core.optim.lr_scheduler.WarmupAnnealing object at 0x7fc72fb0dc10>\" \n",
            "    will be used during training (effective maximum steps = 4356) - \n",
            "    Parameters : \n",
            "    (warmup_steps: null\n",
            "    warmup_ratio: 0.1\n",
            "    last_epoch: -1\n",
            "    max_steps: 4356\n",
            "    )\n",
            "Testing: 100% 303/303 [00:09<00:00, 35.42it/s][NeMo I 2022-07-15 08:21:42 classification_report:142] \n",
            "    label                                                precision    recall       f1           support   \n",
            "    label_id: 0                                             93.79      95.22      94.50        460\n",
            "    label_id: 1                                             94.60      90.64      92.58        406\n",
            "    label_id: 2                                             89.01      91.59      90.29        345\n",
            "    -------------------\n",
            "    micro avg                                               92.65      92.65      92.65       1211\n",
            "    macro avg                                               92.47      92.48      92.45       1211\n",
            "    weighted avg                                            92.70      92.65      92.65       1211\n",
            "    \n",
            "Testing: 100% 303/303 [00:09<00:00, 31.32it/s]\n",
            "[NeMo I 2022-07-15 08:21:42 bert_finetuning_SA_DC:75] Testing finished!\n",
            "[NeMo I 2022-07-15 08:21:42 bert_finetuning_SA_DC:77] ===========================================================================================\n",
            "[NeMo I 2022-07-15 08:21:42 bert_finetuning_SA_DC:99] ===========================================================================================\n",
            "[NeMo I 2022-07-15 08:21:42 bert_finetuning_SA_DC:102] Starting the evaluating the the last checkpoint on a data file (validation set by default)...\n",
            "Using bos_token, but it is not set yet.\n",
            "Using eos_token, but it is not set yet.\n",
            "[NeMo W 2022-07-15 08:21:43 modelPT:102] Please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    file_path: /content/train.tsv\n",
            "    batch_size: 4\n",
            "    shuffle: true\n",
            "    num_samples: -1\n",
            "    num_workers: 3\n",
            "    drop_last: false\n",
            "    pin_memory: false\n",
            "    \n",
            "[NeMo W 2022-07-15 08:21:43 modelPT:109] Please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    file_path: /content/valid.tsv\n",
            "    batch_size: 4\n",
            "    shuffle: false\n",
            "    num_samples: -1\n",
            "    num_workers: 3\n",
            "    drop_last: false\n",
            "    pin_memory: false\n",
            "    \n",
            "[NeMo W 2022-07-15 08:21:43 modelPT:116] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    file_path: /content/test.tsv\n",
            "    batch_size: 4\n",
            "    shuffle: false\n",
            "    num_samples: -1\n",
            "    num_workers: 3\n",
            "    drop_last: false\n",
            "    pin_memory: false\n",
            "    \n",
            "[NeMo I 2022-07-15 08:21:49 bert_module:54] Restoring weights from /content/PretrainingBERTFromText--end.ckpt\n",
            "[NeMo I 2022-07-15 08:21:55 bert_module:82] Weights for BertEncoder restored from /content/PretrainingBERTFromText--end.ckpt\n",
            "[NeMo I 2022-07-15 08:21:55 text_classification_dataset:119] Read 485 examples from /content/valid.tsv.\n",
            "[NeMo I 2022-07-15 08:21:55 text_classification_dataset:232] *** Example ***\n",
            "[NeMo I 2022-07-15 08:21:55 text_classification_dataset:233] example 0: ['1331', '1331', 'يعطيها', 'الصحة', 'المقدمة', 'normal']\n",
            "[NeMo I 2022-07-15 08:21:55 text_classification_dataset:234] subtokens: [CLS] 133 ##1 133 ##1 ي ##ع ##ط ##ي ##ه ##ا ا ##ل ##ص ##ح ##ة ا ##ل ##م ##ق ##د ##م ##ة normal [SEP]\n",
            "[NeMo I 2022-07-15 08:21:55 text_classification_dataset:235] input_ids: 101 14506 2487 14506 2487 1300 29830 29828 14498 14157 25573 1270 23673 29826 29820 19433 1270 23673 22192 29834 15394 22192 19433 3671 102\n",
            "[NeMo I 2022-07-15 08:21:55 text_classification_dataset:236] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "[NeMo I 2022-07-15 08:21:55 text_classification_dataset:237] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "[NeMo I 2022-07-15 08:21:55 text_classification_dataset:238] label: 0\n",
            "[NeMo I 2022-07-15 08:21:55 text_classification_dataset:232] *** Example ***\n",
            "[NeMo I 2022-07-15 08:21:55 text_classification_dataset:233] example 1: ['1015', '1015', 'يولى', 'مثلكم', 'normal']\n",
            "[NeMo I 2022-07-15 08:21:55 text_classification_dataset:234] subtokens: [CLS] 101 ##5 101 ##5 ي ##و ##ل ##ى م ##ث ##ل ##ك ##م normal [SEP]\n",
            "[NeMo I 2022-07-15 08:21:55 text_classification_dataset:235] input_ids: 101 7886 2629 7886 2629 1300 29836 23673 29837 1295 29818 23673 29835 22192 3671 102\n",
            "[NeMo I 2022-07-15 08:21:55 text_classification_dataset:236] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "[NeMo I 2022-07-15 08:21:55 text_classification_dataset:237] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "[NeMo I 2022-07-15 08:21:55 text_classification_dataset:238] label: 0\n",
            "[NeMo W 2022-07-15 08:21:56 text_classification_dataset:245] Found 54 out of 485 sentences with more than 128 subtokens. Truncated long sentences from the end.\n",
            "[NeMo I 2022-07-15 08:21:56 data_preprocessing:295] Some stats of the lengths of the sequences:\n",
            "[NeMo I 2022-07-15 08:21:56 data_preprocessing:301] Min: 9 |                  Max: 129 |                  Mean: 56.04123711340206 |                  Median: 42.0\n",
            "[NeMo I 2022-07-15 08:21:56 data_preprocessing:303] 75 percentile: 77.00\n",
            "[NeMo I 2022-07-15 08:21:56 data_preprocessing:304] 99 percentile: 129.00\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "Using environment variable NODE_RANK for node rank (0).\n",
            "CUDA_VISIBLE_DEVICES: [0]\n",
            "[NeMo I 2022-07-15 08:21:56 modelPT:572] Optimizer config = Adam (\n",
            "    Parameter Group 0\n",
            "        amsgrad: False\n",
            "        betas: [0.9, 0.999]\n",
            "        eps: 1e-08\n",
            "        lr: 2e-05\n",
            "        weight_decay: 0.01\n",
            "    )\n",
            "[NeMo W 2022-07-15 08:21:56 lr_scheduler:526] Neither `max_steps` nor `iters_per_batch` were provided to `optim.sched`, cannot compute effective `max_steps` !\n",
            "    Scheduler will not be instantiated !\n",
            "Testing: 100% 8/8 [00:04<00:00,  2.25it/s][NeMo I 2022-07-15 08:22:01 classification_report:142] \n",
            "    label                                                precision    recall       f1           support   \n",
            "    label_id: 0                                             95.63      95.11      95.37        184\n",
            "    label_id: 1                                             95.24      98.16      96.68        163\n",
            "    label_id: 2                                             93.28      90.58      91.91        138\n",
            "    -------------------\n",
            "    micro avg                                               94.85      94.85      94.85        485\n",
            "    macro avg                                               94.72      94.62      94.65        485\n",
            "    weighted avg                                            94.83      94.85      94.82        485\n",
            "    \n",
            "Testing: 100% 8/8 [00:04<00:00,  1.87it/s]\n",
            "[NeMo I 2022-07-15 08:22:01 bert_finetuning_SA_DC:137] Evaluation the last checkpoint finished!\n",
            "[NeMo I 2022-07-15 08:22:01 bert_finetuning_SA_DC:139] ===========================================================================================\n",
            "[NeMo I 2022-07-15 08:22:01 bert_finetuning_SA_DC:150] ===========================================================================================\n",
            "[NeMo I 2022-07-15 08:22:01 bert_finetuning_SA_DC:152] Starting the inference on some sample queries...\n",
            "Using bos_token, but it is not set yet.\n",
            "Using eos_token, but it is not set yet.\n",
            "[NeMo W 2022-07-15 08:22:02 modelPT:102] Please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    file_path: /content/train.tsv\n",
            "    batch_size: 4\n",
            "    shuffle: true\n",
            "    num_samples: -1\n",
            "    num_workers: 3\n",
            "    drop_last: false\n",
            "    pin_memory: false\n",
            "    \n",
            "[NeMo W 2022-07-15 08:22:02 modelPT:109] Please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    file_path: /content/valid.tsv\n",
            "    batch_size: 4\n",
            "    shuffle: false\n",
            "    num_samples: -1\n",
            "    num_workers: 3\n",
            "    drop_last: false\n",
            "    pin_memory: false\n",
            "    \n",
            "[NeMo W 2022-07-15 08:22:02 modelPT:116] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    file_path: /content/test.tsv\n",
            "    batch_size: 4\n",
            "    shuffle: false\n",
            "    num_samples: -1\n",
            "    num_workers: 3\n",
            "    drop_last: false\n",
            "    pin_memory: false\n",
            "    \n",
            "[NeMo I 2022-07-15 08:22:07 bert_module:54] Restoring weights from /content/PretrainingBERTFromText--end.ckpt\n",
            "[NeMo I 2022-07-15 08:22:09 bert_module:82] Weights for BertEncoder restored from /content/PretrainingBERTFromText--end.ckpt\n",
            "[NeMo I 2022-07-15 08:22:10 bert_finetuning_SA_DC:178] The prediction results of some sample queries with the trained model:\n",
            "[NeMo I 2022-07-15 08:22:10 bert_finetuning_SA_DC:181] Query : استفدت برشا نعشق فيديوهاتك و نحب نعرف وقتاه تعلمت هذ الكل\n",
            "[NeMo I 2022-07-15 08:22:10 bert_finetuning_SA_DC:182] Predicted label: 0\n",
            "[NeMo I 2022-07-15 08:22:10 bert_finetuning_SA_DC:181] Query : بصراحة أحسن حاجة كيف رجعتو كريم القنات نورت بيك ربي يوفقك يا خويا كريم يا باهي\n",
            "[NeMo I 2022-07-15 08:22:10 bert_finetuning_SA_DC:182] Predicted label: 0\n",
            "[NeMo I 2022-07-15 08:22:10 bert_finetuning_SA_DC:181] Query : المسلسل هاذا رغم سقاطتو و رغم كلشي فيه اما فيه برشا حاجات مش خايبين\n",
            "[NeMo I 2022-07-15 08:22:10 bert_finetuning_SA_DC:182] Predicted label: 0\n",
            "[NeMo I 2022-07-15 08:22:10 bert_finetuning_SA_DC:181] Query : الله اعز مسلسل تونسي\n",
            "[NeMo I 2022-07-15 08:22:10 bert_finetuning_SA_DC:182] Predicted label: 0\n",
            "[NeMo I 2022-07-15 08:22:10 bert_finetuning_SA_DC:181] Query :  رجعتوا لفساد بطولة و لخماج قفازة  حسبنا الله ونعم الوكيل\n",
            "[NeMo I 2022-07-15 08:22:10 bert_finetuning_SA_DC:182] Predicted label: 0\n",
            "[NeMo I 2022-07-15 08:22:10 bert_finetuning_SA_DC:181] Query : والله لا تحشم.. عيب عليك.. تحب تفدلك على ربي!!!!!! يعني لا دين، لا ملة\n",
            "[NeMo I 2022-07-15 08:22:10 bert_finetuning_SA_DC:182] Predicted label: 0\n",
            "[NeMo I 2022-07-15 08:22:10 bert_finetuning_SA_DC:184] Inference finished!\n",
            "[NeMo I 2022-07-15 08:22:10 bert_finetuning_SA_DC:186] ===========================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9-2iVqXYJg13"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}