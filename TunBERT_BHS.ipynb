{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xricQGsrC2ZR",
        "outputId": "b5e5a4f3-3d81-4028-80d3-440e5a959d1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ¨ðŸ°âœ¨ Everything looks OK!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Mohamed-Aziz-Ben-Nessir/tunbert.git"
      ],
      "metadata": {
        "id": "8LTOZvnnAEM5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed8962d9-bebb-4991-dd21-ce729feae895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tunbert'...\n",
            "remote: Enumerating objects: 94, done.\u001b[K\n",
            "remote: Counting objects: 100% (94/94), done.\u001b[K\n",
            "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
            "remote: Total 94 (delta 30), reused 81 (delta 21), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (94/94), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/tunbert-opensource-datasets/PyTorch_model/PretrainingBERTFromText--end.ckpt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ttdbuy1y9K4y",
        "outputId": "40a71cf8-8e21-4114-e918-bea5b344e524"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-15 10:10:13--  https://storage.googleapis.com/tunbert-opensource-datasets/PyTorch_model/PretrainingBERTFromText--end.ckpt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.202.128, 74.125.20.128, 74.125.197.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.202.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1323771795 (1.2G) [application/octet-stream]\n",
            "Saving to: â€˜PretrainingBERTFromText--end.ckptâ€™\n",
            "\n",
            "PretrainingBERTFrom 100%[===================>]   1.23G   130MB/s    in 14s     \n",
            "\n",
            "2022-07-15 10:10:28 (90.1 MB/s) - â€˜PretrainingBERTFromText--end.ckptâ€™ saved [1323771795/1323771795]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "data=pd.read_csv(\"/content/aug_dataset.csv\")\n",
        "data[\"label\"]=data[\"class\"].map({\"normal\":0,\"abusive\":1,\"hate\":1})\n",
        "# data=data.drop(data[data[\"label\"]==0][1000:].index).reset_index()\n",
        "data[\"class\"].value_counts()"
      ],
      "metadata": {
        "id": "SD9RHivE-EgK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e33ba229-cedb-4242-d184-5d9e1879a629"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "normal     2300\n",
              "abusive    2028\n",
              "hate       1724\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def strat_train_test_split(data,target,rate=0.1):\n",
        "    split=StratifiedShuffleSplit(n_splits=1,test_size=rate,random_state=41)\n",
        "    for train_index,test_index in split.split(data,data[target]):\n",
        "        train_set=data.loc[train_index]\n",
        "        test_set=data.loc[test_index]\n",
        "    return train_set,test_set\n",
        "\n",
        "train_set,test_set=strat_train_test_split(data,\"label\",0.2)\n",
        "train_set=train_set.reset_index()\n",
        "train_set,valid_set=strat_train_test_split(train_set,\"label\",0.1)\n",
        "train_set.to_csv(\"train.tsv\",sep=\"\\t\",index=False,header=False)\n",
        "valid_set.to_csv(\"valid.tsv\",sep=\"\\t\",index=False,header=False)\n",
        "test_set.to_csv(\"test.tsv\",sep=\"\\t\",index=False,header=False)"
      ],
      "metadata": {
        "id": "DNR-GYkjGbu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd tunbert && conda env update -n base -f environment_torch.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_6UfrhGFC7R",
        "outputId": "cdc05687-3cc6-4b8e-cc6c-271aca1cab1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ WARNING conda.core.solve:_add_specs(611): pinned spec cudatoolkit=11.1 conflicts with explicit specs.  Overriding pinned spec.\n",
            "\b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 4.9.2\n",
            "  latest version: 4.13.0\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base conda\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "ninja-1.10.2         | 2.4 MB    | : 100% 1.0/1 [00:00<00:00,  1.97it/s]\n",
            "torchtext-0.8.1      | 8.0 MB    | : 100% 1.0/1 [00:02<00:00,  2.36s/it]             \n",
            "cudatoolkit-11.0.3   | 951.9 MB  | : 100% 1.0/1 [01:55<00:00, 115.22s/it]             \n",
            "openssl-1.1.1k       | 2.1 MB    | : 100% 1.0/1 [00:00<00:00,  1.80it/s]\n",
            "mkl-2020.4           | 215.6 MB  | : 100% 1.0/1 [00:35<00:00, 35.74s/it]               \n",
            "llvm-openmp-12.0.1   | 2.8 MB    | : 100% 1.0/1 [00:00<00:00,  1.43it/s]\n",
            "libblas-3.9.0        | 12 KB     | : 100% 1.0/1 [00:00<00:00, 28.17it/s]\n",
            "attrs-21.4.0         | 49 KB     | : 100% 1.0/1 [00:00<00:00, 20.88it/s]\n",
            "pip-20.2.2           | 1.1 MB    | : 100% 1.0/1 [00:00<00:00,  3.69it/s]\n",
            "_openmp_mutex-4.5    | 6 KB      | : 100% 1.0/1 [00:00<00:00, 26.03it/s]\n",
            "pytorch-1.7.1        | 39.7 MB   | : 100% 1.0/1 [00:07<00:00,  7.59s/it]\n",
            "openjpeg-2.4.0       | 444 KB    | : 100% 1.0/1 [00:00<00:00,  9.94it/s]\n",
            "torchvision-0.8.2    | 6.6 MB    | : 100% 1.0/1 [00:00<00:00,  1.35it/s]\n",
            "lcms2-2.12           | 443 KB    | : 100% 1.0/1 [00:00<00:00,  9.85it/s]\n",
            "libpng-1.6.37        | 306 KB    | : 100% 1.0/1 [00:00<00:00, 11.18it/s]\n",
            "pyflakes-2.2.0       | 55 KB     | : 100% 1.0/1 [00:00<00:00, 21.86it/s]\n",
            "pillow-8.2.0         | 684 KB    | : 100% 1.0/1 [00:00<00:00,  6.40it/s]\n",
            "libtiff-4.2.0        | 639 KB    | : 100% 1.0/1 [00:00<00:00,  7.56it/s]\n",
            "python_abi-3.7       | 4 KB      | : 100% 1.0/1 [00:00<00:00, 27.63it/s]\n",
            "importlib-metadata-4 | 33 KB     | : 100% 1.0/1 [00:00<00:00, 22.30it/s]\n",
            "isort-5.6.4          | 76 KB     | : 100% 1.0/1 [00:00<00:00, 18.14it/s]\n",
            "click-8.1.3          | 145 KB    | : 100% 1.0/1 [00:00<00:00,  8.41it/s]\n",
            "freetype-2.10.4      | 890 KB    | : 100% 1.0/1 [00:00<00:00,  5.68it/s]\n",
            "black-19.3b0         | 76 KB     | : 100% 1.0/1 [00:00<00:00, 16.64it/s]\n",
            "future-0.18.2        | 713 KB    | : 100% 1.0/1 [00:00<00:00,  4.84it/s]\n",
            "typing_extensions-4. | 28 KB     | : 100% 1.0/1 [00:00<00:00, 22.08it/s]\n",
            "ca-certificates-2022 | 149 KB    | : 100% 1.0/1 [00:00<00:00, 17.91it/s]\n",
            "toml-0.10.2          | 18 KB     | : 100% 1.0/1 [00:00<00:00, 29.19it/s]\n",
            "liblapack-3.9.0      | 11 KB     | : 100% 1.0/1 [00:00<00:00, 33.97it/s]\n",
            "certifi-2022.6.15    | 155 KB    | : 100% 1.0/1 [00:00<00:00, 18.67it/s]\n",
            "jpeg-9d              | 264 KB    | : 100% 1.0/1 [00:00<00:00, 13.09it/s]\n",
            "libcblas-3.9.0       | 11 KB     | : 100% 1.0/1 [00:00<00:00, 28.12it/s]\n",
            "olefile-0.46         | 32 KB     | : 100% 1.0/1 [00:00<00:00, 20.71it/s]\n",
            "appdirs-1.4.4        | 13 KB     | : 100% 1.0/1 [00:00<00:00, 28.28it/s]\n",
            "mccabe-0.6.1         | 8 KB      | : 100% 1.0/1 [00:00<00:00, 25.88it/s]\n",
            "zipp-3.8.0           | 12 KB     | : 100% 1.0/1 [00:00<00:00, 17.55it/s]\n",
            "flake8-3.8.4         | 89 KB     | : 100% 1.0/1 [00:00<00:00, 14.00it/s]\n",
            "pycodestyle-2.6.0    | 38 KB     | : 100% 1.0/1 [00:00<00:00, 25.23it/s]\n",
            "libwebp-base-1.2.0   | 815 KB    | : 100% 1.0/1 [00:00<00:00,  5.50it/s]\n",
            "numpy-1.19.1         | 5.2 MB    | : 100% 1.0/1 [00:00<00:00,  1.01it/s]\n",
            "Preparing transaction: / \b\b- \b\b\\ \b\bdone\n",
            "Verifying transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n",
            "\n",
            "\b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Installing pip dependencies: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- Ran pip subprocess with arguments:\n",
            "['/usr/local/bin/python', '-m', 'pip', 'install', '-U', '-r', '/content/tunbert/condaenv.nmxdqdye.requirements.txt']\n",
            "Pip subprocess output:\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nemo_toolkit[all]==1.0.0b1\n",
            "  Downloading nemo_toolkit-1.0.0b1-py3-none-any.whl (407 kB)\n",
            "Collecting pytorch-lightning==0.9.0\n",
            "  Downloading pytorch_lightning-0.9.0-py3-none-any.whl (408 kB)\n",
            "Collecting pre-commit==2.7.1\n",
            "  Downloading pre_commit-2.7.1-py2.py3-none-any.whl (171 kB)\n",
            "Collecting omegaconf==2.0.1rc12\n",
            "  Downloading omegaconf-2.0.1rc12-py3-none-any.whl (35 kB)\n",
            "Collecting hydra-core==1.0.0rc4\n",
            "  Downloading hydra_core-1.0.0rc4-py3-none-any.whl (117 kB)\n",
            "Collecting transformers==3.1.0\n",
            "  Downloading transformers-3.1.0-py3-none-any.whl (884 kB)\n",
            "Collecting wrapt\n",
            "  Downloading wrapt-1.14.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (75 kB)\n",
            "Collecting onnx>=1.7.0\n",
            "  Downloading onnx-1.12.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "Collecting python-dateutil\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "Requirement already satisfied, skipping upgrade: torch in /usr/local/lib/python3.7/site-packages (from nemo_toolkit[all]==1.0.0b1->-r /content/tunbert/condaenv.nmxdqdye.requirements.txt (line 1)) (1.7.1.post2)\n",
            "Collecting ruamel.yaml\n",
            "  Downloading ruamel.yaml-0.17.21-py3-none-any.whl (109 kB)\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.18.2 in /usr/local/lib/python3.7/site-packages (from nemo_toolkit[all]==1.0.0b1->-r /content/tunbert/condaenv.nmxdqdye.requirements.txt (line 1)) (1.19.1)\n",
            "Collecting webdataset; extra == \"all\"\n",
            "  Downloading webdataset-0.2.5-py3-none-any.whl (46 kB)\n",
            "Requirement already satisfied, skipping upgrade: torchvision; extra == \"all\" in /usr/local/lib/python3.7/site-packages (from nemo_toolkit[all]==1.0.0b1->-r /content/tunbert/condaenv.nmxdqdye.requirements.txt (line 1)) (0.8.0a0)\n",
            "Collecting sox; extra == \"all\"\n",
            "  Downloading sox-1.4.1-py2.py3-none-any.whl (39 kB)\n",
            "Collecting editdistance; extra == \"all\"\n",
            "  Downloading editdistance-0.6.0-cp37-cp37m-manylinux2010_x86_64.whl (285 kB)\n",
            "Collecting pytest; extra == \"all\"\n",
            "  Downloading pytest-7.1.2-py3-none-any.whl (297 kB)\n",
            "Collecting sphinx; extra == \"all\"\n",
            "  Downloading Sphinx-5.0.2-py3-none-any.whl (3.1 MB)\n",
            "Collecting inflect; extra == \"all\"\n",
            "  Downloading inflect-5.6.1-py3-none-any.whl (33 kB)\n",
            "Collecting wandb; extra == \"all\"\n",
            "  Downloading wandb-0.12.21-py2.py3-none-any.whl (1.8 MB)\n",
            "Collecting youtokentome; extra == \"all\"\n",
            "  Downloading youtokentome-1.0.6-cp37-cp37m-manylinux2010_x86_64.whl (1.7 MB)\n",
            "Collecting pytest-runner; extra == \"all\"\n",
            "  Downloading pytest_runner-6.0.0-py3-none-any.whl (7.2 kB)\n",
            "Collecting rapidfuzz; extra == \"all\"\n",
            "  Downloading rapidfuzz-2.1.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "Collecting pandas; extra == \"all\"\n",
            "  Downloading pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "Collecting scipy; extra == \"all\"\n",
            "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "Collecting kaldi-io; extra == \"all\"\n",
            "  Downloading kaldi_io-0.9.4-py3-none-any.whl (14 kB)\n",
            "Collecting packaging; extra == \"all\"\n",
            "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
            "Collecting gdown; extra == \"all\"\n",
            "  Downloading gdown-4.5.1.tar.gz (14 kB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "    Preparing wheel metadata: started\n",
            "    Preparing wheel metadata: finished with status 'done'\n",
            "Collecting sentencepiece; extra == \"all\"\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "Collecting kaldi-python-io; extra == \"all\"\n",
            "  Downloading kaldi-python-io-1.2.2.tar.gz (8.8 kB)\n",
            "Collecting h5py; extra == \"all\"\n",
            "  Downloading h5py-3.7.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.1 MB)\n",
            "Collecting black==19.10b0; extra == \"all\"\n",
            "  Downloading black-19.10b0-py36-none-any.whl (97 kB)\n",
            "Requirement already satisfied, skipping upgrade: torchtext; extra == \"all\" in /usr/local/lib/python3.7/site-packages (from nemo_toolkit[all]==1.0.0b1->-r /content/tunbert/condaenv.nmxdqdye.requirements.txt (line 1)) (0.8.0a0+0f911ec)\n",
            "Collecting braceexpand; extra == \"all\"\n",
            "  Downloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
            "Collecting marshmallow; extra == \"all\"\n",
            "  Downloading marshmallow-3.17.0-py3-none-any.whl (48 kB)\n",
            "Requirement already satisfied, skipping upgrade: tqdm>=4.41.0; extra == \"all\" in /usr/local/lib/python3.7/site-packages (from nemo_toolkit[all]==1.0.0b1->-r /content/tunbert/condaenv.nmxdqdye.requirements.txt (line 1)) (4.59.0)\n",
            "Collecting num2words; extra == \"all\"\n",
            "  Downloading num2words-0.5.10-py3-none-any.whl (101 kB)\n",
            "Collecting parameterized; extra == \"all\"\n",
            "  Downloading parameterized-0.8.1-py2.py3-none-any.whl (26 kB)\n",
            "Collecting attrdict; extra == \"all\"\n",
            "  Downloading attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
            "Collecting unidecode; extra == \"all\"\n",
            "  Downloading Unidecode-1.3.4-py3-none-any.whl (235 kB)\n",
            "Collecting frozendict; extra == \"all\"\n",
            "  Downloading frozendict-2.3.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (99 kB)\n",
            "Collecting librosa; extra == \"all\"\n",
            "  Downloading librosa-0.9.2-py3-none-any.whl (214 kB)\n",
            "Collecting torch-stft; extra == \"all\"\n",
            "  Downloading torch_stft-0.1.4-py3-none-any.whl (6.2 kB)\n",
            "Collecting soundfile; extra == \"all\"\n",
            "  Downloading SoundFile-0.10.3.post1-py2.py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied, skipping upgrade: pillow; extra == \"all\" in /usr/local/lib/python3.7/site-packages (from nemo_toolkit[all]==1.0.0b1->-r /content/tunbert/condaenv.nmxdqdye.requirements.txt (line 1)) (8.2.0)\n",
            "Collecting pypinyin; extra == \"all\"\n",
            "  Downloading pypinyin-0.46.0-py2.py3-none-any.whl (1.3 MB)\n",
            "Collecting matplotlib; extra == \"all\"\n",
            "  Downloading matplotlib-3.5.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "Collecting megatron-lm>=1.1.4; extra == \"all\"\n",
            "  Downloading megatron_lm-2.2.0-py3-none-any.whl (171 kB)\n",
            "Collecting sphinxcontrib-bibtex; extra == \"all\"\n",
            "  Downloading sphinxcontrib_bibtex-2.4.2-py3-none-any.whl (39 kB)\n",
            "Collecting boto3; extra == \"all\"\n",
            "  Downloading boto3-1.24.30-py3-none-any.whl (132 kB)\n",
            "Collecting isort[requirements]<5; extra == \"all\"\n",
            "  Downloading isort-4.3.21-py2.py3-none-any.whl (42 kB)\n",
            "Collecting tensorboard==2.2.0\n",
            "  Downloading tensorboard-2.2.0-py3-none-any.whl (2.8 MB)\n",
            "Requirement already satisfied, skipping upgrade: future>=0.17.1 in /usr/local/lib/python3.7/site-packages (from pytorch-lightning==0.9.0->-r /content/tunbert/condaenv.nmxdqdye.requirements.txt (line 2)) (0.18.2)\n",
            "Collecting PyYAML>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "Collecting cfgv>=2.0.0\n",
            "  Downloading cfgv-3.3.1-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting identify>=1.0.0\n",
            "  Downloading identify-2.5.1-py2.py3-none-any.whl (98 kB)\n",
            "Collecting virtualenv>=20.0.8\n",
            "  Downloading virtualenv-20.15.1-py2.py3-none-any.whl (10.1 MB)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/site-packages (from pre-commit==2.7.1->-r /content/tunbert/condaenv.nmxdqdye.requirements.txt (line 3)) (4.11.4)\n",
            "Requirement already satisfied, skipping upgrade: toml in /usr/local/lib/python3.7/site-packages (from pre-commit==2.7.1->-r /content/tunbert/condaenv.nmxdqdye.requirements.txt (line 3)) (0.10.2)\n",
            "Collecting nodeenv>=0.11.1\n",
            "  Downloading nodeenv-1.7.0-py2.py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/site-packages (from omegaconf==2.0.1rc12->-r /content/tunbert/condaenv.nmxdqdye.requirements.txt (line 4)) (4.3.0)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "Collecting importlib-resources; python_version < \"3.9\"\n",
            "  Downloading importlib_resources-5.8.0-py3-none-any.whl (28 kB)\n",
            "Collecting filelock\n",
            "  Downloading filelock-3.7.1-py3-none-any.whl (10 kB)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "  Downloading tokenizers-0.8.1rc2-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/site-packages (from transformers==3.1.0->-r /content/tunbert/condaenv.nmxdqdye.requirements.txt (line 6)) (2.25.1)\n",
            "Collecting regex!=2019.12.17\n",
            "  Downloading regex-2022.7.9-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n",
            "Collecting protobuf<=3.20.1,>=3.12.2\n",
            "  Downloading protobuf-3.20.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil->nemo_toolkit[all]==1.0.0b1->-r /content/tunbert/condaenv.nmxdqdye.requirements.txt (line 1)) (1.15.0)\n",
            "Collecting ruamel.yaml.clib>=0.2.6; platform_python_implementation == \"CPython\" and python_version < \"3.11\"\n",
            "  Downloading ruamel.yaml.clib-0.2.6-cp37-cp37m-manylinux1_x86_64.whl (546 kB)\n",
            "Collecting joblib>=0.11\n",
            "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied, skipping upgrade: attrs>=19.2.0 in /usr/local/lib/python3.7/site-packages (from pytest; extra == \"all\"->nemo_toolkit[all]==1.0.0b1->-r /content/tunbert/condaenv.nmxdqdye.requirements.txt (line 1)) (21.4.0)\n",
            "Collecting iniconfig\n",
            "  Downloading iniconfig-1.1.1-py2.py3-none-any.whl (5.0 kB)\n",
            "Collecting py>=1.8.2\n",
            "  Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
            "Collecting tomli>=1.0.0\n",
            "  Downloading tomli-2.0.1-py3-none-any.whl (12 kB)\n",
            "Collecting pluggy<2.0,>=0.12\n",
            "  Downloading pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting sphinxcontrib-devhelp\n",
            "  Downloading sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl (84 kB)\n",
            "Collecting docutils<0.19,>=0.14\n",
            "  Downloading docutils-0.18.1-py2.py3-none-any.whl (570 kB)\n",
            "Collecting Jinja2>=2.3\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "Collecting Pygments>=2.0\n",
            "  Downloading Pygments-2.12.0-py3-none-any.whl (1.1 MB)\n",
            "Collecting babel>=1.3\n",
            "  Downloading Babel-2.10.3-py3-none-any.whl (9.5 MB)\n",
            "Collecting sphinxcontrib-htmlhelp>=2.0.0\n",
            "  Downloading sphinxcontrib_htmlhelp-2.0.0-py2.py3-none-any.whl (100 kB)\n",
            "Collecting sphinxcontrib-serializinghtml>=1.1.5\n",
            "  Downloading sphinxcontrib_serializinghtml-1.1.5-py2.py3-none-any.whl (94 kB)\n",
            "Collecting snowballstemmer>=1.1\n",
            "  Downloading snowballstemmer-2.2.0-py2.py3-none-any.whl (93 kB)\n",
            "Collecting sphinxcontrib-qthelp\n",
            "  Downloading sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl (90 kB)\n",
            "Collecting sphinxcontrib-applehelp\n",
            "  Downloading sphinxcontrib_applehelp-1.0.2-py2.py3-none-any.whl (121 kB)\n",
            "Collecting sphinxcontrib-jsmath\n",
            "  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\n",
            "Collecting alabaster<0.8,>=0.7\n",
            "  Downloading alabaster-0.7.12-py2.py3-none-any.whl (14 kB)\n",
            "Collecting imagesize\n",
            "  Downloading imagesize-1.4.1-py2.py3-none-any.whl (8.8 kB)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.7.1-py2.py3-none-any.whl (146 kB)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.2.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
            "Collecting promise<3,>=2.0\n",
            "  Downloading promise-2.3.tar.gz (19 kB)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/site-packages (from wandb; extra == \"all\"->nemo_toolkit[all]==1.0.0b1->-r /content/tunbert/condaenv.nmxdqdye.requirements.txt (line 1)) (49.6.0.post20210108)\n",
            "Collecting psutil>=5.0.0\n",
            "  Downloading psutil-5.9.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
            "Requirement already satisfied, skipping upgrade: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/site-packages (from wandb; extra == \"all\"->nemo_toolkit[all]==1.0.0b1->-r /content/tunbert/condaenv.nmxdqdye.requirements.txt (line 1)) (8.1.3)\n",
            "Collecting jarowinkler<2.0.0,>=1.1.0\n",
            "  Downloading jarowinkler-1.1.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (104 kB)\n",
            "Collecting pytz>=2017.3\n",
            "  Downloading pytz-2022.1-py2.py3-none-any.whl (503 kB)\n",
            "Collecting pyparsing!=3.0.5,>=2.0.2\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "Collecting beautifulsoup4\n",
            "  Downloading beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n",
            "Collecting typed-ast>=1.4.0\n",
            "  Downloading typed_ast-1.5.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (843 kB)\n",
            "Collecting pathspec<1,>=0.6\n",
            "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied, skipping upgrade: appdirs in /usr/local/lib/python3.7/site-packages (from black==19.10b0; extra == \"all\"->nemo_toolkit[all]==1.0.0b1->-r /content/tunbert/condaenv.nmxdqdye.requirements.txt (line 1)) (1.4.4)\n",
            "Collecting docopt>=0.6.2\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "Collecting audioread>=2.1.9\n",
            "  Downloading audioread-2.1.9.tar.gz (377 kB)\n",
            "Collecting numba>=0.45.1\n",
            "  Downloading numba-0.55.2-cp37-cp37m-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.3 MB)\n",
            "Collecting pooch>=1.0\n",
            "  Downloading pooch-1.6.0-py3-none-any.whl (56 kB)\n",
            "Collecting resampy>=0.2.2\n",
            "  Downloading resampy-0.3.1-py3-none-any.whl (3.1 MB)\n",
            "Collecting decorator>=4.0.10\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied, skipping upgrade: cffi>=1.0 in /usr/local/lib/python3.7/site-packages (from soundfile; extra == \"all\"->nemo_toolkit[all]==1.0.0b1->-r /content/tunbert/condaenv.nmxdqdye.requirements.txt (line 1)) (1.14.5)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.34.4-py3-none-any.whl (944 kB)\n",
            "Collecting kiwisolver>=1.0.1\n",
            "  Downloading kiwisolver-1.4.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1 MB)\n",
            "Collecting cycler>=0.10\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Collecting pybind11\n",
            "  Downloading pybind11-2.9.2-py2.py3-none-any.whl (213 kB)\n",
            "Collecting pybtex-docutils>=1.0.0\n",
            "  Downloading pybtex_docutils-1.0.2-py3-none-any.whl (6.3 kB)\n",
            "Collecting pybtex>=0.24\n",
            "  Downloading pybtex-0.24.0-py2.py3-none-any.whl (561 kB)\n",
            "Collecting botocore<1.28.0,>=1.27.30\n",
            "  Downloading botocore-1.27.30-py3-none-any.whl (9.0 MB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting pipreqs; extra == \"requirements\"\n",
            "  Downloading pipreqs-0.4.11-py2.py3-none-any.whl (32 kB)\n",
            "Collecting pip-api; extra == \"requirements\"\n",
            "  Downloading pip_api-0.0.29-py3-none-any.whl (111 kB)\n",
            "Collecting tensorboard-plugin-wit>=1.6.0\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "Collecting absl-py>=0.4\n",
            "  Downloading absl_py-1.1.0-py3-none-any.whl (123 kB)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/site-packages (from tensorboard==2.2.0->pytorch-lightning==0.9.0->-r /content/tunbert/condaenv.nmxdqdye.requirements.txt (line 2)) (0.36.2)\n",
            "Collecting google-auth<2,>=1.6.3\n",
            "  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Collecting grpcio>=1.24.3\n",
            "  Downloading grpcio-1.47.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "Collecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
            "Collecting werkzeug>=0.11.15\n",
            "  Downloading Werkzeug-2.1.2-py3-none-any.whl (224 kB)\n",
            "Collecting distlib<1,>=0.3.1\n",
            "  Downloading distlib-0.3.5-py2.py3-none-any.whl (466 kB)\n",
            "Collecting platformdirs<3,>=2\n",
            "  Downloading platformdirs-2.5.2-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->pre-commit==2.7.1->-r /content/tunbert/condaenv.nmxdqdye.requirements.txt (line 3)) (3.8.0)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests->transformers==3.1.0->-r /content/tunbert/condaenv.nmxdqdye.requirements.txt (line 6)) (2022.6.15)\n",
            "Requirement already satisfied, skipping upgrade: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/site-packages (from requests->transformers==3.1.0->-r /content/tunbert/condaenv.nmxdqdye.requirements.txt (line 6)) (4.0.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests->transformers==3.1.0->-r /content/tunbert/condaenv.nmxdqdye.requirements.txt (line 6)) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests->transformers==3.1.0->-r /content/tunbert/condaenv.nmxdqdye.requirements.txt (line 6)) (1.26.3)\n",
            "Collecting MarkupSafe>=2.0\n",
            "  Downloading MarkupSafe-2.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "Collecting soupsieve>1.2\n",
            "  Downloading soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n",
            "Collecting llvmlite<0.39,>=0.38.0rc1\n",
            "  Downloading llvmlite-0.38.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "Requirement already satisfied, skipping upgrade: pycparser in /usr/local/lib/python3.7/site-packages (from cffi>=1.0->soundfile; extra == \"all\"->nemo_toolkit[all]==1.0.0b1->-r /content/tunbert/condaenv.nmxdqdye.requirements.txt (line 1)) (2.20)\n",
            "Collecting latexcodec>=1.0.4\n",
            "  Downloading latexcodec-2.0.1-py2.py3-none-any.whl (18 kB)\n",
            "Collecting yarg\n",
            "  Downloading yarg-0.1.9-py2.py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied, skipping upgrade: pip in /usr/local/lib/python3.7/site-packages (from pip-api; extra == \"requirements\"->isort[requirements]<5; extra == \"all\"->nemo_toolkit[all]==1.0.0b1->-r /content/tunbert/condaenv.nmxdqdye.requirements.txt (line 1)) (20.2.2)\n",
            "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
            "  Downloading rsa-4.8-py3-none-any.whl (39 kB)\n",
            "Collecting pyasn1-modules>=0.2.1\n",
            "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
            "Collecting cachetools<5.0,>=2.0.0\n",
            "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
            "Collecting requests-oauthlib>=0.7.0\n",
            "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Collecting pyasn1>=0.1.3\n",
            "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
            "Collecting oauthlib>=3.0.0\n",
            "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
            "Building wheels for collected packages: wget, gdown, kaldi-python-io, antlr4-python3-runtime, sacremoses, pathtools, promise, docopt, audioread\n",
            "  Building wheel for wget (setup.py): started\n",
            "  Building wheel for wget (setup.py): finished with status 'done'\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9680 sha256=798d87b5eaa6ef15ec13f84f8b190a40a1b9f360a65baa1ea213f61b0d612d9b\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "  Building wheel for gdown (PEP 517): started\n",
            "  Building wheel for gdown (PEP 517): finished with status 'done'\n",
            "  Created wheel for gdown: filename=gdown-4.5.1-py3-none-any.whl size=14933 sha256=7111327e4087ec00a914a8327886549f0eb69571ea698498be2acd12bafbbbc9\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/ec/b0/a96d1d126183f98570a785e6bf8789fca559853a9260e928e1\n",
            "  Building wheel for kaldi-python-io (setup.py): started\n",
            "  Building wheel for kaldi-python-io (setup.py): finished with status 'done'\n",
            "  Created wheel for kaldi-python-io: filename=kaldi_python_io-1.2.2-py3-none-any.whl size=8969 sha256=96434c1c6c6361bacd98372e5cbc61178dab6abb1bc58d23e7061cae5c4afc24\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/26/38/7678d1ff6cd1bbcbfc0d80b0a29d94d917dfa9ad790b4a85a9\n",
            "  Building wheel for antlr4-python3-runtime (setup.py): started\n",
            "  Building wheel for antlr4-python3-runtime (setup.py): finished with status 'done'\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=7cac86dc9a064cf205ba4ec1ca3557e970ab13ccd0afe26b3b101b7b716751c0\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
            "  Building wheel for sacremoses (setup.py): started\n",
            "  Building wheel for sacremoses (setup.py): finished with status 'done'\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895254 sha256=1d5c10563e14c47fb70b2c2a105f204aec08783f10f4f46996341ef5ee97b776\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "  Building wheel for pathtools (setup.py): started\n",
            "  Building wheel for pathtools (setup.py): finished with status 'done'\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8784 sha256=437e4e3ff37f96d00dee748c00db5c879a81d9658084ea25a27e45242f106780\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "  Building wheel for promise (setup.py): started\n",
            "  Building wheel for promise (setup.py): finished with status 'done'\n",
            "  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21494 sha256=3b1c7613f51ecda7d762f20cd47204ed6ddb8e21571b36e75cb8cd384d98141a\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/93/c6/762e359f8cb6a5b69c72235d798804cae523bbe41c2aa8333d\n",
            "  Building wheel for docopt (setup.py): started\n",
            "  Building wheel for docopt (setup.py): finished with status 'done'\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13705 sha256=9a50a5cbe8f8c9964aea9d802924a0426fb9f8d0f7f5b4d2cd27b07c34121149\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/b0/3f/1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9\n",
            "  Building wheel for audioread (setup.py): started\n",
            "  Building wheel for audioread (setup.py): finished with status 'done'\n",
            "  Created wheel for audioread: filename=audioread-2.1.9-py3-none-any.whl size=23141 sha256=caccde1f0076bd4fd64fb243a97840e2e0745530325d9683b035efbf40c599d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/7b/eb/213741ccc0678f63e346ab8dff10495995ca3f426af87b8d88\n",
            "Successfully built wget gdown kaldi-python-io antlr4-python3-runtime sacremoses pathtools promise docopt audioread\n",
            "Installing collected packages: wrapt, PyYAML, omegaconf, protobuf, onnx, python-dateutil, ruamel.yaml.clib, ruamel.yaml, tensorboard-plugin-wit, absl-py, pyasn1, rsa, pyasn1-modules, cachetools, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, grpcio, markdown, werkzeug, tensorboard, pyparsing, packaging, pytorch-lightning, wget, scipy, joblib, threadpoolctl, scikit-learn, antlr4-python3-runtime, importlib-resources, hydra-core, filelock, regex, sacremoses, tokenizers, sentencepiece, transformers, braceexpand, webdataset, sox, editdistance, iniconfig, py, tomli, pluggy, pytest, sphinxcontrib-devhelp, docutils, MarkupSafe, Jinja2, Pygments, pytz, babel, sphinxcontrib-htmlhelp, sphinxcontrib-serializinghtml, snowballstemmer, sphinxcontrib-qthelp, sphinxcontrib-applehelp, sphinxcontrib-jsmath, alabaster, imagesize, sphinx, inflect, shortuuid, docker-pycreds, sentry-sdk, smmap, gitdb, GitPython, pathtools, setproctitle, promise, psutil, wandb, youtokentome, pytest-runner, jarowinkler, rapidfuzz, pandas, kaldi-io, soupsieve, beautifulsoup4, gdown, kaldi-python-io, h5py, typed-ast, pathspec, black, marshmallow, docopt, num2words, parameterized, attrdict, unidecode, frozendict, audioread, llvmlite, numba, pooch, resampy, decorator, soundfile, librosa, torch-stft, pypinyin, fonttools, kiwisolver, cycler, matplotlib, pybind11, megatron-lm, latexcodec, pybtex, pybtex-docutils, sphinxcontrib-bibtex, jmespath, botocore, s3transfer, boto3, yarg, pipreqs, pip-api, isort, nemo-toolkit, cfgv, identify, distlib, platformdirs, virtualenv, nodeenv, pre-commit\n",
            "  Attempting uninstall: black\n",
            "    Found existing installation: black 19.3b0\n",
            "    Uninstalling black-19.3b0:\n",
            "      Successfully uninstalled black-19.3b0\n",
            "  Attempting uninstall: isort\n",
            "    Found existing installation: isort 5.6.4\n",
            "    Uninstalling isort-5.6.4:\n",
            "      Successfully uninstalled isort-5.6.4\n",
            "Successfully installed GitPython-3.1.27 Jinja2-3.1.2 MarkupSafe-2.1.1 PyYAML-6.0 Pygments-2.12.0 absl-py-1.1.0 alabaster-0.7.12 antlr4-python3-runtime-4.8 attrdict-2.0.1 audioread-2.1.9 babel-2.10.3 beautifulsoup4-4.11.1 black-19.10b0 boto3-1.24.30 botocore-1.27.30 braceexpand-0.1.7 cachetools-4.2.4 cfgv-3.3.1 cycler-0.11.0 decorator-5.1.1 distlib-0.3.5 docker-pycreds-0.4.0 docopt-0.6.2 docutils-0.18.1 editdistance-0.6.0 filelock-3.7.1 fonttools-4.34.4 frozendict-2.3.2 gdown-4.5.1 gitdb-4.0.9 google-auth-1.35.0 google-auth-oauthlib-0.4.6 grpcio-1.47.0 h5py-3.7.0 hydra-core-1.0.0rc4 identify-2.5.1 imagesize-1.4.1 importlib-resources-5.8.0 inflect-5.6.1 iniconfig-1.1.1 isort-4.3.21 jarowinkler-1.1.2 jmespath-1.0.1 joblib-1.1.0 kaldi-io-0.9.4 kaldi-python-io-1.2.2 kiwisolver-1.4.3 latexcodec-2.0.1 librosa-0.9.2 llvmlite-0.38.1 markdown-3.3.7 marshmallow-3.17.0 matplotlib-3.5.2 megatron-lm-2.2.0 nemo-toolkit-1.0.0b1 nodeenv-1.7.0 num2words-0.5.10 numba-0.55.2 oauthlib-3.2.0 omegaconf-2.0.1rc12 onnx-1.12.0 packaging-21.3 pandas-1.3.5 parameterized-0.8.1 pathspec-0.9.0 pathtools-0.1.2 pip-api-0.0.29 pipreqs-0.4.11 platformdirs-2.5.2 pluggy-1.0.0 pooch-1.6.0 pre-commit-2.7.1 promise-2.3 protobuf-3.20.1 psutil-5.9.1 py-1.11.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 pybind11-2.9.2 pybtex-0.24.0 pybtex-docutils-1.0.2 pyparsing-3.0.9 pypinyin-0.46.0 pytest-7.1.2 pytest-runner-6.0.0 python-dateutil-2.8.2 pytorch-lightning-0.9.0 pytz-2022.1 rapidfuzz-2.1.3 regex-2022.7.9 requests-oauthlib-1.3.1 resampy-0.3.1 rsa-4.8 ruamel.yaml-0.17.21 ruamel.yaml.clib-0.2.6 s3transfer-0.6.0 sacremoses-0.0.53 scikit-learn-1.0.2 scipy-1.7.3 sentencepiece-0.1.96 sentry-sdk-1.7.1 setproctitle-1.2.3 shortuuid-1.0.9 smmap-5.0.0 snowballstemmer-2.2.0 soundfile-0.10.3.post1 soupsieve-2.3.2.post1 sox-1.4.1 sphinx-5.0.2 sphinxcontrib-applehelp-1.0.2 sphinxcontrib-bibtex-2.4.2 sphinxcontrib-devhelp-1.0.2 sphinxcontrib-htmlhelp-2.0.0 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.3 sphinxcontrib-serializinghtml-1.1.5 tensorboard-2.2.0 tensorboard-plugin-wit-1.8.1 threadpoolctl-3.1.0 tokenizers-0.8.1rc2 tomli-2.0.1 torch-stft-0.1.4 transformers-3.1.0 typed-ast-1.5.4 unidecode-1.3.4 virtualenv-20.15.1 wandb-0.12.21 webdataset-0.2.5 werkzeug-2.1.2 wget-3.2 wrapt-1.14.1 yarg-0.1.9 youtokentome-1.0.6\n",
            "\n",
            "\b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate base\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pre-commit"
      ],
      "metadata": {
        "id": "gzJryZ21tByI",
        "outputId": "cddd2e60-8140-4d11-fd09-4ea436b627ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pre-commit\n",
            "  Downloading pre_commit-2.20.0-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 199 kB 6.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pyyaml>=5.1 in /usr/local/lib/python3.7/site-packages (from pre-commit) (6.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/site-packages (from pre-commit) (4.11.4)\n",
            "Requirement already satisfied, skipping upgrade: cfgv>=2.0.0 in /usr/local/lib/python3.7/site-packages (from pre-commit) (3.3.1)\n",
            "Requirement already satisfied, skipping upgrade: identify>=1.0.0 in /usr/local/lib/python3.7/site-packages (from pre-commit) (2.5.1)\n",
            "Requirement already satisfied, skipping upgrade: virtualenv>=20.0.8 in /usr/local/lib/python3.7/site-packages (from pre-commit) (20.15.1)\n",
            "Requirement already satisfied, skipping upgrade: toml in /usr/local/lib/python3.7/site-packages (from pre-commit) (0.10.2)\n",
            "Requirement already satisfied, skipping upgrade: nodeenv>=0.11.1 in /usr/local/lib/python3.7/site-packages (from pre-commit) (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->pre-commit) (4.3.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->pre-commit) (3.8.0)\n",
            "Requirement already satisfied, skipping upgrade: six<2,>=1.9.0 in /usr/local/lib/python3.7/site-packages (from virtualenv>=20.0.8->pre-commit) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: filelock<4,>=3.2 in /usr/local/lib/python3.7/site-packages (from virtualenv>=20.0.8->pre-commit) (3.7.1)\n",
            "Requirement already satisfied, skipping upgrade: platformdirs<3,>=2 in /usr/local/lib/python3.7/site-packages (from virtualenv>=20.0.8->pre-commit) (2.5.2)\n",
            "Requirement already satisfied, skipping upgrade: distlib<1,>=0.3.1 in /usr/local/lib/python3.7/site-packages (from virtualenv>=20.0.8->pre-commit) (0.3.5)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/site-packages (from nodeenv>=0.11.1->pre-commit) (49.6.0.post20210108)\n",
            "Installing collected packages: pre-commit\n",
            "  Attempting uninstall: pre-commit\n",
            "    Found existing installation: pre-commit 2.7.1\n",
            "    Uninstalling pre-commit-2.7.1:\n",
            "      Successfully uninstalled pre-commit-2.7.1\n",
            "Successfully installed pre-commit-2.20.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.7\n",
        "!pip install torchtext==0.8\n",
        "!pip install pytorch-lightning==0.9.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5Jww2VqEfgM",
        "outputId": "19400069-b860-48ea-e0dd-a92ddf4d086e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.7\n",
            "  Downloading torch-1.7.0-cp37-cp37m-manylinux1_x86_64.whl (776.7 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776.7 MB 4.7 kB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/site-packages (from torch==1.7) (0.18.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (from torch==1.7) (1.19.1)\n",
            "Collecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/site-packages (from torch==1.7) (4.3.0)\n",
            "Installing collected packages: dataclasses, torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.7.1.post2\n",
            "    Uninstalling torch-1.7.1.post2:\n",
            "      Successfully uninstalled torch-1.7.1.post2\n",
            "Successfully installed dataclasses-0.6 torch-1.7.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.8\n",
            "  Downloading torchtext-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.9 MB 7.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/site-packages (from torchtext==0.8) (2.25.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (from torchtext==0.8) (1.19.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/site-packages (from torchtext==0.8) (1.7.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/site-packages (from torchtext==0.8) (4.59.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests->torchtext==0.8) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests->torchtext==0.8) (2022.6.15)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/site-packages (from requests->torchtext==0.8) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests->torchtext==0.8) (1.26.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/site-packages (from torch->torchtext==0.8) (0.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/site-packages (from torch->torchtext==0.8) (4.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/site-packages (from torch->torchtext==0.8) (0.18.2)\n",
            "Installing collected packages: torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.8.0a0+0f911ec\n",
            "    Uninstalling torchtext-0.8.0a0+0f911ec:\n",
            "      Successfully uninstalled torchtext-0.8.0a0+0f911ec\n",
            "Successfully installed torchtext-0.8.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytorch-lightning==0.9.0 in /usr/local/lib/python3.7/site-packages (0.9.0)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.7/site-packages (from pytorch-lightning==0.9.0) (0.18.2)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/site-packages (from pytorch-lightning==0.9.0) (4.59.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.7/site-packages (from pytorch-lightning==0.9.0) (6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/site-packages (from pytorch-lightning==0.9.0) (21.3)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.7/site-packages (from pytorch-lightning==0.9.0) (1.7.0)\n",
            "Requirement already satisfied: tensorboard==2.2.0 in /usr/local/lib/python3.7/site-packages (from pytorch-lightning==0.9.0) (2.2.0)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.7/site-packages (from pytorch-lightning==0.9.0) (1.19.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/site-packages (from packaging->pytorch-lightning==0.9.0) (3.0.9)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/site-packages (from torch>=1.3->pytorch-lightning==0.9.0) (0.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/site-packages (from torch>=1.3->pytorch-lightning==0.9.0) (4.3.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/site-packages (from tensorboard==2.2.0->pytorch-lightning==0.9.0) (49.6.0.post20210108)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/site-packages (from tensorboard==2.2.0->pytorch-lightning==0.9.0) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/site-packages (from tensorboard==2.2.0->pytorch-lightning==0.9.0) (0.36.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/site-packages (from tensorboard==2.2.0->pytorch-lightning==0.9.0) (1.1.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/site-packages (from tensorboard==2.2.0->pytorch-lightning==0.9.0) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/site-packages (from tensorboard==2.2.0->pytorch-lightning==0.9.0) (2.1.2)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/site-packages (from tensorboard==2.2.0->pytorch-lightning==0.9.0) (1.47.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/site-packages (from tensorboard==2.2.0->pytorch-lightning==0.9.0) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/site-packages (from tensorboard==2.2.0->pytorch-lightning==0.9.0) (2.25.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/site-packages (from tensorboard==2.2.0->pytorch-lightning==0.9.0) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/site-packages (from tensorboard==2.2.0->pytorch-lightning==0.9.0) (1.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/site-packages (from tensorboard==2.2.0->pytorch-lightning==0.9.0) (3.20.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.2.0->pytorch-lightning==0.9.0) (1.3.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard==2.2.0->pytorch-lightning==0.9.0) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard==2.2.0->pytorch-lightning==0.9.0) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard==2.2.0->pytorch-lightning==0.9.0) (0.2.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard==2.2.0->pytorch-lightning==0.9.0) (1.26.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard==2.2.0->pytorch-lightning==0.9.0) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard==2.2.0->pytorch-lightning==0.9.0) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard==2.2.0->pytorch-lightning==0.9.0) (2022.6.15)\n",
            "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /usr/local/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard==2.2.0->pytorch-lightning==0.9.0) (4.11.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.2.0->pytorch-lightning==0.9.0) (3.2.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard==2.2.0->pytorch-lightning==0.9.0) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard==2.2.0->pytorch-lightning==0.9.0) (3.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd tunbert && pre-commit install && pre-commit run --all-files"
      ],
      "metadata": {
        "id": "SpLAAa0QrcIZ",
        "outputId": "0f5a8d44-fc6c-4bd4-dc71-55b2bb73d81d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pre-commit installed at .git/hooks/pre-commit\n",
            "seed isort known_third_party.............................................\u001b[42mPassed\u001b[m\n",
            "isort....................................................................\u001b[42mPassed\u001b[m\n",
            "black....................................................................\u001b[42mPassed\u001b[m\n",
            "flake8...................................................................\u001b[42mPassed\u001b[m\n",
            "Check for merge conflicts................................................\u001b[42mPassed\u001b[m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/tunbert/models/bert-nvidia/bert_finetuning_SA_DC.py --config-name \"sentiment_analysis_config\" model.language_model.lm_checkpoint=\"/content/PretrainingBERTFromText--end.ckpt\" model.train_ds.file_path=\"/content/train.tsv\" model.validation_ds.file_path=\"/content/valid.tsv\" model.test_ds.file_path=\"/content/test.tsv\" model.dataset.num_classes=2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9R0VSN19BuS",
        "outputId": "5ffb1edd-15a4-4abe-eafd-e056b637f762"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n",
            "[NeMo W 2022-07-15 10:25:27 experimental:28] Module <class 'nemo.collections.nlp.modules.common.huggingface.auto.AutoModelEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
            "[NeMo W 2022-07-15 10:25:27 experimental:28] Module <class 'nemo.collections.nlp.modules.common.megatron.megatron_bert.MegatronBertEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
            "[NeMo W 2022-07-15 10:25:29 nemo_logging:349] /usr/local/lib/python3.7/site-packages/omegaconf/basecontainer.py:231: UserWarning: \n",
            "                pretty() is deprecated and will be removed in a future version.\n",
            "                Use OmegaConf.to_yaml. Please note that the default value for\n",
            "                resolve has changed to True.\n",
            "                \n",
            "      category=UserWarning,\n",
            "    \n",
            "[NeMo I 2022-07-15 10:25:29 bert_finetuning_SA_DC:45] \n",
            "    Config Params:\n",
            "    trainer:\n",
            "      gpus: 1\n",
            "      num_nodes: 1\n",
            "      max_epochs: 4\n",
            "      max_steps: null\n",
            "      accumulate_grad_batches: 1\n",
            "      gradient_clip_val: 0.0\n",
            "      amp_level: O0\n",
            "      precision: 32\n",
            "      distributed_backend: ddp\n",
            "      row_log_interval: 1\n",
            "      val_check_interval: 1.0\n",
            "      resume_from_checkpoint: null\n",
            "      num_sanity_val_steps: 0\n",
            "      checkpoint_callback: false\n",
            "      logger: false\n",
            "    model:\n",
            "      nemo_path: null\n",
            "      tokenizer:\n",
            "        tokenizer_name: ${model.language_model.pretrained_model_name}\n",
            "        vocab_file: null\n",
            "        tokenizer_model: null\n",
            "        special_tokens: null\n",
            "      language_model:\n",
            "        pretrained_model_name: bert-base-uncased\n",
            "        lm_checkpoint: /content/PretrainingBERTFromText--end.ckpt\n",
            "        config_file: null\n",
            "        config: null\n",
            "      classifier_head:\n",
            "        num_output_layers: 2\n",
            "        fc_dropout: 0.1\n",
            "      dataset:\n",
            "        num_classes: 2\n",
            "        do_lower_case: false\n",
            "        max_seq_length: 128\n",
            "        class_balancing: null\n",
            "        use_cache: false\n",
            "        num_workers: 3\n",
            "        drop_last: false\n",
            "        pin_memory: false\n",
            "      train_ds:\n",
            "        file_path: /content/train.tsv\n",
            "        batch_size: 4\n",
            "        shuffle: true\n",
            "        num_samples: -1\n",
            "        num_workers: ${model.dataset.num_workers}\n",
            "        drop_last: ${model.dataset.drop_last}\n",
            "        pin_memory: ${model.dataset.pin_memory}\n",
            "      validation_ds:\n",
            "        file_path: /content/valid.tsv\n",
            "        batch_size: 4\n",
            "        shuffle: false\n",
            "        num_samples: -1\n",
            "        num_workers: ${model.dataset.num_workers}\n",
            "        drop_last: ${model.dataset.drop_last}\n",
            "        pin_memory: ${model.dataset.pin_memory}\n",
            "      test_ds:\n",
            "        file_path: /content/test.tsv\n",
            "        batch_size: 4\n",
            "        shuffle: false\n",
            "        num_samples: -1\n",
            "        num_workers: ${model.dataset.num_workers}\n",
            "        drop_last: ${model.dataset.drop_last}\n",
            "        pin_memory: ${model.dataset.pin_memory}\n",
            "      optim:\n",
            "        name: adam\n",
            "        lr: 2.0e-05\n",
            "        betas:\n",
            "        - 0.9\n",
            "        - 0.999\n",
            "        weight_decay: 0.01\n",
            "        sched:\n",
            "          name: WarmupAnnealing\n",
            "          warmup_steps: null\n",
            "          warmup_ratio: 0.1\n",
            "          last_epoch: -1\n",
            "          monitor: val_loss\n",
            "          reduce_on_plateau: false\n",
            "    exp_manager:\n",
            "      exp_dir: null\n",
            "      name: SentimentAnalysis\n",
            "      create_tensorboard_logger: true\n",
            "      create_checkpoint_callback: true\n",
            "    \n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "CUDA_VISIBLE_DEVICES: [0]\n",
            "[NeMo I 2022-07-15 10:25:29 exp_manager:169] Experiments will be logged at /content/nemo_experiments/SentimentAnalysis/2022-07-15_10-25-29\n",
            "[NeMo I 2022-07-15 10:25:29 exp_manager:503] TensorboardLogger has been set up\n",
            "[NeMo W 2022-07-15 10:25:29 exp_manager:537] trainer had a weights_save_path of cwd(). This was ignored.\n",
            "Downloading: 100% 433/433 [00:00<00:00, 446kB/s]\n",
            "Downloading: 100% 232k/232k [00:00<00:00, 1.23MB/s]\n",
            "Using bos_token, but it is not set yet.\n",
            "Using eos_token, but it is not set yet.\n",
            "[NeMo I 2022-07-15 10:25:30 text_classification_dataset:119] Read 4356 examples from /content/train.tsv.\n",
            "[NeMo I 2022-07-15 10:25:30 text_classification_dataset:232] *** Example ***\n",
            "[NeMo I 2022-07-15 10:25:30 text_classification_dataset:233] example 0: ['5721', '6637', 'Ø§ÙˆÙ„', 'Ø´ÙŠØ¦', 'Ø§Ø¹Ø¬Ø¨', 'ÙÙŠ', 'Ù‡Ø°Ø§', 'Ø§Ù„Ø´Ø§Ø·ÙŠØ¦', 'Ù†Ø§Ø³', 'Ù…ØªØ±Ø¨ÙŠØ©', 'ÙƒÙŠÙ', 'ØªØ¹Ø¬Ø¨', 'Ø¨Ù„ØªØ±Ø¨ÙŠØ©', 'ÙˆØ§Ù†ØªÙŠ', 'Ø¨Ù„Ø¨Ø§Ø³', 'Ø¹Ø§Ø±ÙŠ', 'Ùˆ', 'ÙØ§Ø¶Ø­', 'ÙˆØ§Ù†ØªÙŠ', 'ÙƒØ¨ÙŠØ±Ø©', 'Ø¹Ù„Ù‰', 'Ù‡Ø°Ø§', 'Ø§Ù„Ù„Ø¨Ø§Ø³', 'Ù…Ø¹', 'Ø§Ù†Ùƒ', 'ØªØ±ÙŠÙ†Ù‡Ø§', 'Ø­Ø±ÙŠØ©', 'Ø´Ø®ØµÙŠØ©', 'Ù„Ø§ÙƒÙ†', 'ØªÙ†ØªÙ‡ÙŠ', 'Ø­Ø±ÙŠØªÙƒ', 'Ø¹Ù†Ø¯', 'Ø¨Ø¯Ø¡', 'Ø­Ø±ÙŠØ©', 'Ø§Ù„Ø§Ø®Ø±ÙŠÙ†', 'Ø§Ù„Ø­ÙŠØ§Ø¡', 'Ù„Ù‡', 'Ø·Ø¹Ù…', 'ÙÙŠ', 'Ø­ÙŠØ§Ø©', 'Ø§Ù„Ù…Ø³Ù„Ù…ÙŠÙ†', 'Ø§Ù„Ù„Ù‡', 'ÙŠÙ‡Ø¯ÙŠÙ†Ø§', 'ÙˆÙŠØ³ØªØ±Ù†Ø§', 'ÙˆÙŠØºÙØ±', 'Ù„Ù†Ø§', 'ÙˆÙŠØ­Ø³Ù†', 'Ø®Ø§ØªÙ…ØªÙ†Ø§', 'abusive']\n",
            "[NeMo I 2022-07-15 10:25:30 text_classification_dataset:234] subtokens: [CLS] 57 ##21 66 ##37 Ø§ ##Ùˆ ##Ù„ Ø´ ##ÙŠ ##ÙŠ Ø§ ##Ø¹ ##Ø¬ ##Ø¨ Ù ##ÙŠ Ù‡ ##Ø° ##Ø§ Ø§ ##Ù„ ##Ø´ ##Ø§ ##Ø· ##ÙŠ ##ÙŠ Ù† ##Ø§ ##Ø³ Ù… ##Øª ##Ø± ##Ø¨ ##ÙŠ ##Ø© Ùƒ ##ÙŠ ##Ù Øª ##Ø¹ ##Ø¬ ##Ø¨ Ø¨ ##Ù„ ##Øª ##Ø± ##Ø¨ ##ÙŠ ##Ø© Ùˆ ##Ø§Ù† ##Øª ##ÙŠ Ø¨ ##Ù„ ##Ø¨ ##Ø§ ##Ø³ Ø¹ ##Ø§ ##Ø± ##ÙŠ Ùˆ Ù ##Ø§ ##Ø¶ ##Ø­ Ùˆ ##Ø§Ù† ##Øª ##ÙŠ Ùƒ ##Ø¨ ##ÙŠ ##Ø± ##Ø© Ø¹ ##Ù„ ##Ù‰ Ù‡ ##Ø° ##Ø§ Ø§ ##Ù„ ##Ù„ ##Ø¨ ##Ø§ ##Ø³ Ù… ##Ø¹ Ø§ ##Ù† ##Ùƒ Øª ##Ø± ##ÙŠ ##Ù† ##Ù‡ ##Ø§ Ø­ ##Ø± ##ÙŠ ##Ø© Ø´ ##Ø® ##Øµ ##ÙŠ ##Ø© Ù„ ##Ø§ ##Ùƒ ##Ù† Øª ##Ù† ##Øª ##Ù‡ ##ÙŠ Ø­ ##Ø± ##ÙŠ ##Øª ##Ùƒ Ø¹ ##Ù† ##Ø¯ Ø¨ ##Ø¯ [SEP]\n",
            "[NeMo I 2022-07-15 10:25:30 text_classification_dataset:235] input_ids: 101 5401 17465 5764 24434 1270 29836 23673 1283 14498 14498 1270 29830 29819 29816 1291 14498 1297 29822 25573 1270 23673 29825 25573 29828 14498 14498 1296 25573 29824 1295 29817 17149 29816 14498 19433 1293 14498 29833 1273 29830 29819 29816 1271 23673 29817 17149 29816 14498 19433 1298 18511 29817 14498 1271 23673 29816 25573 29824 1288 25573 17149 14498 1298 1291 25573 29827 29820 1298 18511 29817 14498 1293 29816 14498 17149 19433 1288 23673 29837 1297 29822 25573 1270 23673 23673 29816 25573 29824 1295 29830 1270 15915 29835 1273 17149 14498 15915 14157 25573 1276 17149 14498 19433 1283 29821 29826 14498 19433 1294 25573 29835 15915 1273 15915 29817 14157 14498 1276 17149 14498 29817 29835 1288 15915 15394 1271 15394 102\n",
            "[NeMo I 2022-07-15 10:25:30 text_classification_dataset:236] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "[NeMo I 2022-07-15 10:25:30 text_classification_dataset:237] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "[NeMo I 2022-07-15 10:25:30 text_classification_dataset:238] label: 1\n",
            "[NeMo I 2022-07-15 10:25:30 text_classification_dataset:232] *** Example ***\n",
            "[NeMo I 2022-07-15 10:25:30 text_classification_dataset:233] example 1: ['248', '248', 'ØªÙÙˆÙˆÙˆÙˆÙˆÙˆÙ‡', 'Ø²Ø¨ÙˆØ±', 'Ø§Ù„ÙƒØ±Ø©', 'ØªÙˆÙ†Ø³', 'Ø¬Ø§ÙŠØ¨ÙŠÙ†', 'ÙƒØ§Ø±Ø«Ø©', 'Ø§Ù„Ù…ÙŠØ¨ÙˆÙ†', 'Ø§Ù„Ø¬Ø±ÙŠØ¡', 'Ø±Ø¡ÙŠØ³', 'Ø¬Ø§Ù…Ø¹Ø©', 'abusive']\n",
            "[NeMo I 2022-07-15 10:25:30 text_classification_dataset:234] subtokens: [CLS] 248 248 Øª ##Ù ##Ùˆ ##Ùˆ ##Ùˆ ##Ùˆ ##Ùˆ ##Ùˆ ##Ù‡ Ø² ##Ø¨ ##Ùˆ ##Ø± Ø§ ##Ù„ ##Ùƒ ##Ø± ##Ø© Øª ##Ùˆ ##Ù† ##Ø³ Ø¬ ##Ø§ ##ÙŠ ##Ø¨ ##ÙŠ ##Ù† Ùƒ ##Ø§ ##Ø± ##Ø« ##Ø© Ø§ ##Ù„ ##Ù… ##ÙŠ ##Ø¨ ##Ùˆ ##Ù† Ø§ ##Ù„ ##Ø¬ ##Ø± ##ÙŠ ##Ø¡ Ø± ##Ø¡ ##ÙŠ ##Ø³ Ø¬ ##Ø§ ##Ù… ##Ø¹ ##Ø© abusive [SEP]\n",
            "[NeMo I 2022-07-15 10:25:30 text_classification_dataset:235] input_ids: 101 24568 24568 1273 29833 29836 29836 29836 29836 29836 29836 14157 1281 29816 29836 17149 1270 23673 29835 17149 19433 1273 29836 15915 29824 1275 25573 14498 29816 14498 15915 1293 25573 17149 29818 19433 1270 23673 22192 14498 29816 29836 15915 1270 23673 29819 17149 14498 29815 1280 29815 14498 29824 1275 25573 22192 29830 19433 20676 102\n",
            "[NeMo I 2022-07-15 10:25:30 text_classification_dataset:236] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "[NeMo I 2022-07-15 10:25:30 text_classification_dataset:237] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "[NeMo I 2022-07-15 10:25:30 text_classification_dataset:238] label: 1\n",
            "[NeMo W 2022-07-15 10:25:35 text_classification_dataset:245] Found 538 out of 4356 sentences with more than 128 subtokens. Truncated long sentences from the end.\n",
            "[NeMo I 2022-07-15 10:25:35 data_preprocessing:295] Some stats of the lengths of the sequences:\n",
            "[NeMo I 2022-07-15 10:25:35 data_preprocessing:301] Min: 7 |                  Max: 129 |                  Mean: 58.273415977961434 |                  Median: 45.0\n",
            "[NeMo I 2022-07-15 10:25:35 data_preprocessing:303] 75 percentile: 83.00\n",
            "[NeMo I 2022-07-15 10:25:35 data_preprocessing:304] 99 percentile: 129.00\n",
            "[NeMo I 2022-07-15 10:25:35 text_classification_dataset:119] Read 485 examples from /content/valid.tsv.\n",
            "[NeMo I 2022-07-15 10:25:35 text_classification_dataset:232] *** Example ***\n",
            "[NeMo I 2022-07-15 10:25:35 text_classification_dataset:233] example 0: ['4358', '955', 'Ø¹Ø³Ù„Ø§Ù…Ø©', 'ÙŠÙˆØ³Ù', 'Ù†Ù‚ØªØ±Ø­', 'Ø¹Ù„ÙŠÙƒ', 'ÙŠØ¹Ø·ÙŠÙƒ', 'Ø§Ù†ØªØ±Ù†Øª', 'Ù…Ø­Ø¯ÙˆØ¯Ø©', 'Ø³Ø±Ø¹Ø©', 'Ø¥Ø¨Ø­Ø§Ø±', 'Ù…Ø¶Ù…ÙˆÙ†Ø©', 'ØªØ³ØªØ­Ù‚', 'Ø¥ØªØµØ§Ù„Ø§Øª', 'ØªÙˆÙ†Ø³', 'Ø§Ù„Ø§Ø´ØªØ±Ø§Ùƒ', 'Ø¨', '5', 'Ø¯ÙŠÙ†Ø§Ø±', 'Ø§Ù„Ø´Ù‡Ø±', 'Ù„Ø­ØµÙˆÙ„', 'Ø£ÙƒØ«Ø±', 'Ø§Ù„ØªÙØ§ØµÙŠÙ„', 'Ø¥Ø¶ØºØ·', 'Ø§Ù„Ø±Ø§Ø¨Ø·', 'Ø£Ø­Ù…Ø¯', 'normal']\n",
            "[NeMo I 2022-07-15 10:25:35 text_classification_dataset:234] subtokens: [CLS] 435 ##8 95 ##5 Ø¹ ##Ø³ ##Ù„ ##Ø§ ##Ù… ##Ø© ÙŠ ##Ùˆ ##Ø³ ##Ù Ù† ##Ù‚ ##Øª ##Ø± ##Ø­ Ø¹ ##Ù„ ##ÙŠ ##Ùƒ ÙŠ ##Ø¹ ##Ø· ##ÙŠ ##Ùƒ Ø§ ##Ù† ##Øª ##Ø± ##Ù† ##Øª Ù… ##Ø­ ##Ø¯ ##Ùˆ ##Ø¯ ##Ø© Ø³ ##Ø± ##Ø¹ ##Ø© Ø§ ##Ø¨ ##Ø­ ##Ø§ ##Ø± Ù… ##Ø¶ ##Ù… ##Ùˆ ##Ù† ##Ø© Øª ##Ø³ ##Øª ##Ø­ ##Ù‚ Ø§ ##Øª ##Øµ ##Ø§ ##Ù„ ##Ø§ ##Øª Øª ##Ùˆ ##Ù† ##Ø³ Ø§ ##Ù„ ##Ø§ ##Ø´ ##Øª ##Ø± ##Ø§ ##Ùƒ Ø¨ 5 Ø¯ ##ÙŠ ##Ù† ##Ø§ ##Ø± Ø§ ##Ù„ ##Ø´ ##Ù‡ ##Ø± Ù„ ##Ø­ ##Øµ ##Ùˆ ##Ù„ Ø§ ##Ùƒ ##Ø« ##Ø± Ø§ ##Ù„ ##Øª ##Ù ##Ø§ ##Øµ ##ÙŠ ##Ù„ Ø§ ##Ø¶ ##Øº ##Ø· Ø§ ##Ù„ ##Ø± ##Ø§ ##Ø¨ ##Ø· Ø§ ##Ø­ ##Ù… ##Ø¯ normal [SEP]\n",
            "[NeMo I 2022-07-15 10:25:35 text_classification_dataset:235] input_ids: 101 24125 2620 5345 2629 1288 29824 23673 25573 22192 19433 1300 29836 29824 29833 1296 29834 29817 17149 29820 1288 23673 14498 29835 1300 29830 29828 14498 29835 1270 15915 29817 17149 15915 29817 1295 29820 15394 29836 15394 19433 1282 17149 29830 19433 1270 29816 29820 25573 17149 1295 29827 22192 29836 15915 19433 1273 29824 29817 29820 29834 1270 29817 29826 25573 23673 25573 29817 1273 29836 15915 29824 1270 23673 25573 29825 29817 17149 25573 29835 1271 1019 1278 14498 15915 25573 17149 1270 23673 29825 14157 17149 1294 29820 29826 29836 23673 1270 29835 29818 17149 1270 23673 29817 29833 25573 29826 14498 23673 1270 29827 29831 29828 1270 23673 17149 25573 29816 29828 1270 29820 22192 15394 3671 102\n",
            "[NeMo I 2022-07-15 10:25:35 text_classification_dataset:236] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "[NeMo I 2022-07-15 10:25:35 text_classification_dataset:237] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "[NeMo I 2022-07-15 10:25:35 text_classification_dataset:238] label: 0\n",
            "[NeMo I 2022-07-15 10:25:35 text_classification_dataset:232] *** Example ***\n",
            "[NeMo I 2022-07-15 10:25:35 text_classification_dataset:233] example 1: ['2438', '3347', 'Ø§Ø®ÙˆØ§Ù†ÙŠ', 'Ø§Ù„ØªÙˆØ§Ù†Ø³Ø©', 'Ø¯Ø¹ÙƒÙ…', 'Ø§Ù„ØªØ²Ù„Ù', 'ÙˆØ§Ù„Ø´ÙŠØªØ©', 'Ù„Ù„ØºØ±Ø¨', 'ÙˆØ§Ø³Ø±Ø§Ø¦ÙŠÙ„', 'Ø§Ù„ÙŠÙ‡ÙˆØ¯ÙŠ', 'ÙŠØ¨Ù‚Ù‰', 'Ø¯Ø§Ø¦Ù…Ø§', 'ÙŠÙ‡ÙˆØ¯ÙŠ', 'ÙˆØ§Ø³ØªÙ…Ø¹Ùˆ', 'Ù‚Ø§Ù„Ù‡', 'Ø¹Ø²', 'ÙˆØ¬Ù„', 'ØªØ±Ø¶Ù‰', 'Ø§Ù„ÙŠÙ‡ÙˆØ¯', 'Ø§Ù„Ù†ØµØ§Ø±Ù‰', 'ØªØªØ¨Ø¹', 'Ù…Ù„ØªÙ‡Ù…', 'Ù‚Ù„', 'Ù‡Ø¯Ù‰', 'Ø§Ù„Ù‡Ø¯Ù‰', 'hate']\n",
            "[NeMo I 2022-07-15 10:25:35 text_classification_dataset:234] subtokens: [CLS] 243 ##8 334 ##7 Ø§ ##Ø® ##Ùˆ ##Ø§Ù† ##ÙŠ Ø§ ##Ù„ ##Øª ##Ùˆ ##Ø§Ù† ##Ø³ ##Ø© Ø¯ ##Ø¹ ##Ùƒ ##Ù… Ø§ ##Ù„ ##Øª ##Ø² ##Ù„ ##Ù Ùˆ ##Ø§ ##Ù„ ##Ø´ ##ÙŠ ##Øª ##Ø© Ù„ ##Ù„ ##Øº ##Ø± ##Ø¨ Ùˆ ##Ø§ ##Ø³ ##Ø± ##Ø§ ##ÙŠ ##ÙŠ ##Ù„ Ø§ ##Ù„ ##ÙŠ ##Ù‡ ##Ùˆ ##Ø¯ ##ÙŠ ÙŠ ##Ø¨ ##Ù‚ ##Ù‰ Ø¯ ##Ø§ ##ÙŠ ##Ù… ##Ø§ ÙŠ ##Ù‡ ##Ùˆ ##Ø¯ ##ÙŠ Ùˆ ##Ø§ ##Ø³ ##Øª ##Ù… ##Ø¹ ##Ùˆ Ù‚ ##Ø§ ##Ù„ ##Ù‡ Ø¹ ##Ø² Ùˆ ##Ø¬ ##Ù„ Øª ##Ø± ##Ø¶ ##Ù‰ Ø§ ##Ù„ ##ÙŠ ##Ù‡ ##Ùˆ ##Ø¯ Ø§ ##Ù„ ##Ù† ##Øµ ##Ø§ ##Ø± ##Ù‰ Øª ##Øª ##Ø¨ ##Ø¹ Ù… ##Ù„ ##Øª ##Ù‡ ##Ù… Ù‚ ##Ù„ Ù‡ ##Ø¯ ##Ù‰ Ø§ ##Ù„ ##Ù‡ ##Ø¯ ##Ù‰ hate [SEP]\n",
            "[NeMo I 2022-07-15 10:25:35 text_classification_dataset:235] input_ids: 101 22884 2620 29562 2581 1270 29821 29836 18511 14498 1270 23673 29817 29836 18511 29824 19433 1278 29830 29835 22192 1270 23673 29817 29823 23673 29833 1298 25573 23673 29825 14498 29817 19433 1294 23673 29831 17149 29816 1298 25573 29824 17149 25573 14498 14498 23673 1270 23673 14498 14157 29836 15394 14498 1300 29816 29834 29837 1278 25573 14498 22192 25573 1300 14157 29836 15394 14498 1298 25573 29824 29817 22192 29830 29836 1292 25573 23673 14157 1288 29823 1298 29819 23673 1273 17149 29827 29837 1270 23673 14498 14157 29836 15394 1270 23673 15915 29826 25573 17149 29837 1273 29817 29816 29830 1295 23673 29817 14157 22192 1292 23673 1297 15394 29837 1270 23673 14157 15394 29837 5223 102\n",
            "[NeMo I 2022-07-15 10:25:35 text_classification_dataset:236] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "[NeMo I 2022-07-15 10:25:35 text_classification_dataset:237] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "[NeMo I 2022-07-15 10:25:35 text_classification_dataset:238] label: 1\n",
            "[NeMo W 2022-07-15 10:25:36 text_classification_dataset:245] Found 60 out of 485 sentences with more than 128 subtokens. Truncated long sentences from the end.\n",
            "[NeMo I 2022-07-15 10:25:36 data_preprocessing:295] Some stats of the lengths of the sequences:\n",
            "[NeMo I 2022-07-15 10:25:36 data_preprocessing:301] Min: 11 |                  Max: 129 |                  Mean: 58.47216494845361 |                  Median: 46.0\n",
            "[NeMo I 2022-07-15 10:25:36 data_preprocessing:303] 75 percentile: 81.00\n",
            "[NeMo I 2022-07-15 10:25:36 data_preprocessing:304] 99 percentile: 129.00\n",
            "[NeMo I 2022-07-15 10:25:36 text_classification_dataset:119] Read 1211 examples from /content/test.tsv.\n",
            "[NeMo I 2022-07-15 10:25:36 text_classification_dataset:232] *** Example ***\n",
            "[NeMo I 2022-07-15 10:25:36 text_classification_dataset:233] example 0: ['3', 'Ùˆ', 'Ù…Ù†', 'Ø¯Ø§Ø®Ù„', 'Ù…Ù†', 'Ø¯Ø§Ø®Ù„', 'Ø·Ø­Ø§Ù†', 'abusive']\n",
            "[NeMo I 2022-07-15 10:25:36 text_classification_dataset:234] subtokens: [CLS] 3 Ùˆ Ù… ##Ù† Ø¯ ##Ø§ ##Ø® ##Ù„ Ù… ##Ù† Ø¯ ##Ø§ ##Ø® ##Ù„ Ø· ##Ø­ ##Ø§Ù† abusive [SEP]\n",
            "[NeMo I 2022-07-15 10:25:36 text_classification_dataset:235] input_ids: 101 1017 1298 1295 15915 1278 25573 29821 23673 1295 15915 1278 25573 29821 23673 1286 29820 18511 20676 102\n",
            "[NeMo I 2022-07-15 10:25:36 text_classification_dataset:236] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "[NeMo I 2022-07-15 10:25:36 text_classification_dataset:237] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "[NeMo I 2022-07-15 10:25:36 text_classification_dataset:238] label: 1\n",
            "[NeMo I 2022-07-15 10:25:36 text_classification_dataset:232] *** Example ***\n",
            "[NeMo I 2022-07-15 10:25:36 text_classification_dataset:233] example 1: ['216', 'ØªÙÙˆÙˆÙˆÙˆ', 'ÙƒÙØ§Ø±', 'Ø§Ø´ÙˆÙÙƒ', 'Ø§Ù‚Ø·Ø¹', 'Ø±Ø§Ø³Ùƒ', 'ÙƒÙ„Ø¨', 'hate']\n",
            "[NeMo I 2022-07-15 10:25:36 text_classification_dataset:234] subtokens: [CLS] 216 Øª ##Ù ##Ùˆ ##Ùˆ ##Ùˆ ##Ùˆ Ùƒ ##Ù ##Ø§ ##Ø± Ø§ ##Ø´ ##Ùˆ ##Ù ##Ùƒ Ø§ ##Ù‚ ##Ø· ##Ø¹ Ø± ##Ø§ ##Ø³ ##Ùƒ Ùƒ ##Ù„ ##Ø¨ hate [SEP]\n",
            "[NeMo I 2022-07-15 10:25:36 text_classification_dataset:235] input_ids: 101 20294 1273 29833 29836 29836 29836 29836 1293 29833 25573 17149 1270 29825 29836 29833 29835 1270 29834 29828 29830 1280 25573 29824 29835 1293 23673 29816 5223 102\n",
            "[NeMo I 2022-07-15 10:25:36 text_classification_dataset:236] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "[NeMo I 2022-07-15 10:25:36 text_classification_dataset:237] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "[NeMo I 2022-07-15 10:25:36 text_classification_dataset:238] label: 1\n",
            "[NeMo W 2022-07-15 10:25:37 text_classification_dataset:245] Found 138 out of 1211 sentences with more than 128 subtokens. Truncated long sentences from the end.\n",
            "[NeMo I 2022-07-15 10:25:37 data_preprocessing:295] Some stats of the lengths of the sequences:\n",
            "[NeMo I 2022-07-15 10:25:37 data_preprocessing:301] Min: 7 |                  Max: 129 |                  Mean: 54.97027250206441 |                  Median: 42.0\n",
            "[NeMo I 2022-07-15 10:25:37 data_preprocessing:303] 75 percentile: 76.50\n",
            "[NeMo I 2022-07-15 10:25:37 data_preprocessing:304] 99 percentile: 129.00\n",
            "Downloading: 100% 440M/440M [00:06<00:00, 68.1MB/s]\n",
            "[NeMo I 2022-07-15 10:25:50 bert_module:54] Restoring weights from /content/PretrainingBERTFromText--end.ckpt\n",
            "[NeMo I 2022-07-15 10:25:59 bert_module:82] Weights for BertEncoder restored from /content/PretrainingBERTFromText--end.ckpt\n",
            "[NeMo I 2022-07-15 10:25:59 bert_finetuning_SA_DC:54] ===========================================================================================\n",
            "[NeMo I 2022-07-15 10:25:59 bert_finetuning_SA_DC:56] Starting training...\n",
            "[NeMo W 2022-07-15 10:25:59 nemo_logging:349] /usr/local/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: WORLD_SIZE environment variable (2) is not equal to the computed world size (1). Ignored.\n",
            "      warnings.warn(*args, **kwargs)\n",
            "    \n",
            "initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "distributed_backend=ddp\n",
            "All DDP processes registered. Starting ddp with 1 processes\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[NeMo I 2022-07-15 10:26:00 modelPT:572] Optimizer config = Adam (\n",
            "    Parameter Group 0\n",
            "        amsgrad: False\n",
            "        betas: [0.9, 0.999]\n",
            "        eps: 1e-08\n",
            "        lr: 2e-05\n",
            "        weight_decay: 0.01\n",
            "    )\n",
            "[NeMo I 2022-07-15 10:26:00 lr_scheduler:545] Scheduler \"<nemo.core.optim.lr_scheduler.WarmupAnnealing object at 0x7f9a75474450>\" \n",
            "    will be used during training (effective maximum steps = 4356) - \n",
            "    Parameters : \n",
            "    (warmup_steps: null\n",
            "    warmup_ratio: 0.1\n",
            "    last_epoch: -1\n",
            "    max_steps: 4356\n",
            "    )\n",
            "[NeMo W 2022-07-15 10:26:00 nemo_logging:349] /usr/local/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: Could not log computational graph since the `model.example_input_array` attribute is not set or `input_array` was not given\n",
            "      warnings.warn(*args, **kwargs)\n",
            "    \n",
            "\n",
            "  | Name                  | Type                 | Params\n",
            "---------------------------------------------------------------\n",
            "0 | bert_model            | BertEncoder          | 109 M \n",
            "1 | classifier            | SequenceClassifier   | 592 K \n",
            "2 | loss                  | CrossEntropyLoss     | 0     \n",
            "3 | classification_report | ClassificationReport | 0     \n",
            "Epoch 0:  90% 1089/1211 [02:24<00:16,  7.52it/s, loss=0.226, v_num=5-29]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 0:  90% 1090/1211 [02:24<00:16,  7.52it/s, loss=0.226, v_num=5-29]\n",
            "Epoch 0:  90% 1093/1211 [02:25<00:15,  7.54it/s, loss=0.226, v_num=5-29]\n",
            "Epoch 0:  91% 1097/1211 [02:25<00:15,  7.56it/s, loss=0.226, v_num=5-29]\n",
            "Epoch 0:  91% 1101/1211 [02:25<00:14,  7.58it/s, loss=0.226, v_num=5-29]\n",
            "Epoch 0:  91% 1105/1211 [02:25<00:13,  7.60it/s, loss=0.226, v_num=5-29]\n",
            "Epoch 0:  92% 1109/1211 [02:25<00:13,  7.62it/s, loss=0.226, v_num=5-29]\n",
            "Epoch 0:  92% 1113/1211 [02:25<00:12,  7.64it/s, loss=0.226, v_num=5-29]\n",
            "Epoch 0:  92% 1117/1211 [02:25<00:12,  7.66it/s, loss=0.226, v_num=5-29]\n",
            "Epoch 0:  93% 1122/1211 [02:25<00:11,  7.69it/s, loss=0.226, v_num=5-29]\n",
            "Epoch 0:  93% 1127/1211 [02:26<00:10,  7.71it/s, loss=0.226, v_num=5-29]\n",
            "Validating:  32% 39/122 [00:01<00:02, 35.11it/s]\u001b[A\n",
            "Epoch 0:  93% 1132/1211 [02:26<00:10,  7.74it/s, loss=0.226, v_num=5-29]\n",
            "Epoch 0:  94% 1137/1211 [02:26<00:09,  7.77it/s, loss=0.226, v_num=5-29]\n",
            "Epoch 0:  94% 1142/1211 [02:26<00:08,  7.79it/s, loss=0.226, v_num=5-29]\n",
            "Epoch 0:  95% 1147/1211 [02:26<00:08,  7.82it/s, loss=0.226, v_num=5-29]\n",
            "Validating:  48% 59/122 [00:01<00:01, 33.37it/s]\u001b[A\n",
            "Epoch 0:  95% 1152/1211 [02:26<00:07,  7.84it/s, loss=0.226, v_num=5-29]\n",
            "Epoch 0:  96% 1157/1211 [02:27<00:06,  7.87it/s, loss=0.226, v_num=5-29]\n",
            "Epoch 0:  96% 1162/1211 [02:27<00:06,  7.89it/s, loss=0.226, v_num=5-29]\n",
            "Epoch 0:  96% 1167/1211 [02:27<00:05,  7.92it/s, loss=0.226, v_num=5-29]\n",
            "Validating:  65% 79/122 [00:02<00:01, 32.33it/s]\u001b[A\n",
            "Epoch 0:  97% 1172/1211 [02:27<00:04,  7.95it/s, loss=0.226, v_num=5-29]\n",
            "Epoch 0:  97% 1177/1211 [02:27<00:04,  7.97it/s, loss=0.226, v_num=5-29]\n",
            "Epoch 0:  98% 1182/1211 [02:27<00:03,  8.00it/s, loss=0.226, v_num=5-29]\n",
            "Epoch 0:  98% 1187/1211 [02:27<00:02,  8.02it/s, loss=0.226, v_num=5-29]\n",
            "Validating:  81% 99/122 [00:03<00:00, 29.47it/s]\u001b[A\n",
            "Epoch 0:  98% 1192/1211 [02:28<00:02,  8.04it/s, loss=0.226, v_num=5-29]\n",
            "Epoch 0:  99% 1197/1211 [02:28<00:01,  8.07it/s, loss=0.226, v_num=5-29]\n",
            "Validating:  89% 109/122 [00:03<00:00, 29.20it/s]\u001b[A\n",
            "Epoch 0:  99% 1202/1211 [02:28<00:01,  8.09it/s, loss=0.226, v_num=5-29]\n",
            "Epoch 0: 100% 1207/1211 [02:28<00:00,  8.12it/s, loss=0.226, v_num=5-29]\n",
            "Validating:  98% 120/122 [00:03<00:00, 30.78it/s]\u001b[A[NeMo I 2022-07-15 10:28:29 classification_report:142] \n",
            "    label                                                precision    recall       f1           support   \n",
            "    label_id: 0                                             88.48      91.85      90.13        184\n",
            "    label_id: 1                                             94.90      92.69      93.78        301\n",
            "    -------------------\n",
            "    micro avg                                               92.37      92.37      92.37        485\n",
            "    macro avg                                               91.69      92.27      91.96        485\n",
            "    weighted avg                                            92.46      92.37      92.40        485\n",
            "    \n",
            "Epoch 0: 100% 1211/1211 [02:28<00:00,  8.13it/s, loss=0.226, v_num=5-29]\n",
            "                                                 \u001b[Atcmalloc: large alloc 1156866048 bytes == 0x55e400368000 @  0x7f9afb637615 0x55e2bc0bc67c 0x55e2bc19098b 0x55e2bc0bd1a2 0x55e2bc0a0c9d 0x7f9af87c9484 0x7f9af87cb534 0x7f9af879aeb0 0x7f9ae90e5435 0x7f9ae90e199a 0x7f9ae90e65d9 0x7f9af87a8dab 0x7f9af842702a 0x55e2bc12e427 0x55e2bc12e5b6 0x55e2bc12fb59 0x55e2bc15a74a 0x55e2bc09daf2 0x55e2bc0cc030 0x55e2bc12f9c8 0x55e2bc1564ac 0x55e2bc09daf2 0x55e2bc0cc030 0x55e2bc12f9c8 0x55e2bc15a74a 0x55e2bc0cbe94 0x55e2bc12f9c8 0x55e2bc1564ac 0x55e2bc09daf2 0x55e2bc0cc030 0x55e2bc12f9c8\n",
            "tcmalloc: large alloc 1446084608 bytes == 0x55e391b6c000 @  0x7f9afb637615 0x55e2bc0bc67c 0x55e2bc19098b 0x55e2bc0bd1a2 0x55e2bc0a0c9d 0x7f9af87c9484 0x7f9af87cb534 0x7f9af879aeb0 0x7f9ae90e5435 0x7f9ae90e199a 0x7f9ae90e65d9 0x7f9af87a8dab 0x7f9af842702a 0x55e2bc12e427 0x55e2bc12e5b6 0x55e2bc12fb59 0x55e2bc15a74a 0x55e2bc09daf2 0x55e2bc0cc030 0x55e2bc12f9c8 0x55e2bc1564ac 0x55e2bc09daf2 0x55e2bc0cc030 0x55e2bc12f9c8 0x55e2bc15a74a 0x55e2bc0cbe94 0x55e2bc12f9c8 0x55e2bc1564ac 0x55e2bc09daf2 0x55e2bc0cc030 0x55e2bc12f9c8\n",
            "Epoch 0: 100% 1211/1211 [02:39<00:00,  7.60it/s, loss=0.226, v_num=5-29]tcmalloc: large alloc 1446084608 bytes == 0x55e391b6c000 @  0x7f9afb637615 0x55e2bc0bc67c 0x55e2bc19098b 0x55e2bc0bd1a2 0x55e2bc0a0c9d 0x7f9af87c9484 0x7f9af87cb534 0x7f9af879aeb0 0x7f9ae90e5435 0x7f9ae90e199a 0x7f9ae90e65d9 0x7f9af87a8dab 0x7f9af842702a 0x55e2bc12e427 0x55e2bc12e5b6 0x55e2bc12fb59 0x55e2bc15a74a 0x55e2bc09daf2 0x55e2bc0cc030 0x55e2bc12f9c8 0x55e2bc1564ac 0x55e2bc09daf2 0x55e2bc0cc030 0x55e2bc12f9c8 0x55e2bc15a74a 0x55e2bc0cbe94 0x55e2bc12f9c8 0x55e2bc1564ac 0x55e2bc09daf2 0x55e2bc0cc030 0x55e2bc12f9c8\n",
            "Epoch 1:  90% 1089/1211 [02:30<00:16,  7.24it/s, loss=0.170, v_num=5-29]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 1:  90% 1091/1211 [02:30<00:16,  7.24it/s, loss=0.170, v_num=5-29]\n",
            "Epoch 1:  90% 1095/1211 [02:30<00:15,  7.26it/s, loss=0.170, v_num=5-29]\n",
            "Epoch 1:  91% 1099/1211 [02:31<00:15,  7.28it/s, loss=0.170, v_num=5-29]\n",
            "Validating:   9% 11/122 [00:00<00:05, 21.45it/s]\u001b[A\n",
            "Epoch 1:  91% 1103/1211 [02:31<00:14,  7.29it/s, loss=0.170, v_num=5-29]\n",
            "Epoch 1:  91% 1107/1211 [02:31<00:14,  7.32it/s, loss=0.170, v_num=5-29]\n",
            "Epoch 1:  92% 1111/1211 [02:31<00:13,  7.34it/s, loss=0.170, v_num=5-29]\n",
            "Epoch 1:  92% 1115/1211 [02:31<00:13,  7.36it/s, loss=0.170, v_num=5-29]\n",
            "Epoch 1:  92% 1119/1211 [02:31<00:12,  7.38it/s, loss=0.170, v_num=5-29]\n",
            "Epoch 1:  93% 1123/1211 [02:31<00:11,  7.40it/s, loss=0.170, v_num=5-29]\n",
            "Epoch 1:  93% 1128/1211 [02:31<00:11,  7.42it/s, loss=0.170, v_num=5-29]\n",
            "Epoch 1:  94% 1133/1211 [02:32<00:10,  7.45it/s, loss=0.170, v_num=5-29]\n",
            "Epoch 1:  94% 1138/1211 [02:32<00:09,  7.48it/s, loss=0.170, v_num=5-29]\n",
            "Epoch 1:  94% 1143/1211 [02:32<00:09,  7.50it/s, loss=0.170, v_num=5-29]\n",
            "Validating:  45% 55/122 [00:01<00:02, 32.65it/s]\u001b[A\n",
            "Epoch 1:  95% 1148/1211 [02:32<00:08,  7.53it/s, loss=0.170, v_num=5-29]\n",
            "Epoch 1:  95% 1153/1211 [02:32<00:07,  7.55it/s, loss=0.170, v_num=5-29]\n",
            "Epoch 1:  96% 1158/1211 [02:32<00:06,  7.57it/s, loss=0.170, v_num=5-29]\n",
            "Epoch 1:  96% 1163/1211 [02:33<00:06,  7.60it/s, loss=0.170, v_num=5-29]\n",
            "Validating:  61% 75/122 [00:02<00:01, 31.98it/s]\u001b[A\n",
            "Epoch 1:  96% 1168/1211 [02:33<00:05,  7.62it/s, loss=0.170, v_num=5-29]\n",
            "Epoch 1:  97% 1173/1211 [02:33<00:04,  7.65it/s, loss=0.170, v_num=5-29]\n",
            "Epoch 1:  97% 1178/1211 [02:33<00:04,  7.68it/s, loss=0.170, v_num=5-29]\n",
            "Epoch 1:  98% 1183/1211 [02:33<00:03,  7.70it/s, loss=0.170, v_num=5-29]\n",
            "Validating:  78% 95/122 [00:03<00:00, 31.60it/s]\u001b[A\n",
            "Epoch 1:  98% 1188/1211 [02:33<00:02,  7.72it/s, loss=0.170, v_num=5-29]\n",
            "Epoch 1:  99% 1193/1211 [02:34<00:02,  7.75it/s, loss=0.170, v_num=5-29]\n",
            "Epoch 1:  99% 1198/1211 [02:34<00:01,  7.77it/s, loss=0.170, v_num=5-29]\n",
            "Validating:  90% 110/122 [00:03<00:00, 29.64it/s]\u001b[A\n",
            "Epoch 1:  99% 1203/1211 [02:34<00:01,  7.79it/s, loss=0.170, v_num=5-29]\n",
            "Epoch 1: 100% 1208/1211 [02:34<00:00,  7.82it/s, loss=0.170, v_num=5-29]\n",
            "Validating: 100% 122/122 [00:04<00:00, 31.16it/s]\u001b[A[NeMo I 2022-07-15 10:31:22 classification_report:142] \n",
            "    label                                                precision    recall       f1           support   \n",
            "    label_id: 0                                             90.10      98.91      94.30        184\n",
            "    label_id: 1                                             99.29      93.36      96.23        301\n",
            "    -------------------\n",
            "    micro avg                                               95.46      95.46      95.46        485\n",
            "    macro avg                                               94.70      96.13      95.27        485\n",
            "    weighted avg                                            95.81      95.46      95.50        485\n",
            "    \n",
            "Epoch 1: 100% 1211/1211 [02:34<00:00,  7.83it/s, loss=0.170, v_num=5-29]\n",
            "Epoch 2:  90% 1089/1211 [02:30<00:16,  7.25it/s, loss=0.091, v_num=5-29]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 2:  90% 1091/1211 [02:30<00:16,  7.25it/s, loss=0.091, v_num=5-29]\n",
            "Epoch 2:  90% 1095/1211 [02:30<00:15,  7.27it/s, loss=0.091, v_num=5-29]\n",
            "Epoch 2:  91% 1099/1211 [02:30<00:15,  7.29it/s, loss=0.091, v_num=5-29]\n",
            "Validating:   9% 11/122 [00:00<00:04, 23.80it/s]\u001b[A\n",
            "Epoch 2:  91% 1103/1211 [02:30<00:14,  7.31it/s, loss=0.091, v_num=5-29]\n",
            "Epoch 2:  91% 1107/1211 [02:31<00:14,  7.33it/s, loss=0.091, v_num=5-29]\n",
            "Epoch 2:  92% 1111/1211 [02:31<00:13,  7.35it/s, loss=0.091, v_num=5-29]\n",
            "Epoch 2:  92% 1115/1211 [02:31<00:13,  7.37it/s, loss=0.091, v_num=5-29]\n",
            "Epoch 2:  92% 1119/1211 [02:31<00:12,  7.39it/s, loss=0.091, v_num=5-29]\n",
            "Epoch 2:  93% 1123/1211 [02:31<00:11,  7.41it/s, loss=0.091, v_num=5-29]\n",
            "Epoch 2:  93% 1128/1211 [02:31<00:11,  7.44it/s, loss=0.091, v_num=5-29]\n",
            "Epoch 2:  94% 1133/1211 [02:31<00:10,  7.47it/s, loss=0.091, v_num=5-29]\n",
            "Epoch 2:  94% 1138/1211 [02:31<00:09,  7.49it/s, loss=0.091, v_num=5-29]\n",
            "Epoch 2:  94% 1143/1211 [02:32<00:09,  7.52it/s, loss=0.091, v_num=5-29]\n",
            "Validating:  45% 55/122 [00:01<00:02, 33.49it/s]\u001b[A\n",
            "Epoch 2:  95% 1148/1211 [02:32<00:08,  7.54it/s, loss=0.091, v_num=5-29]\n",
            "Epoch 2:  95% 1153/1211 [02:32<00:07,  7.57it/s, loss=0.091, v_num=5-29]\n",
            "Epoch 2:  96% 1158/1211 [02:32<00:06,  7.59it/s, loss=0.091, v_num=5-29]\n",
            "Epoch 2:  96% 1163/1211 [02:32<00:06,  7.61it/s, loss=0.091, v_num=5-29]\n",
            "Validating:  61% 75/122 [00:02<00:01, 32.04it/s]\u001b[A\n",
            "Epoch 2:  96% 1168/1211 [02:32<00:05,  7.64it/s, loss=0.091, v_num=5-29]\n",
            "Epoch 2:  97% 1173/1211 [02:33<00:04,  7.67it/s, loss=0.091, v_num=5-29]\n",
            "Epoch 2:  97% 1178/1211 [02:33<00:04,  7.69it/s, loss=0.091, v_num=5-29]\n",
            "Epoch 2:  98% 1183/1211 [02:33<00:03,  7.72it/s, loss=0.091, v_num=5-29]\n",
            "Validating:  78% 95/122 [00:03<00:00, 31.92it/s]\u001b[A\n",
            "Epoch 2:  98% 1188/1211 [02:33<00:02,  7.74it/s, loss=0.091, v_num=5-29]\n",
            "Epoch 2:  99% 1193/1211 [02:33<00:02,  7.76it/s, loss=0.091, v_num=5-29]\n",
            "Epoch 2:  99% 1198/1211 [02:33<00:01,  7.79it/s, loss=0.091, v_num=5-29]\n",
            "Epoch 2:  99% 1203/1211 [02:34<00:01,  7.81it/s, loss=0.091, v_num=5-29]\n",
            "Validating:  94% 115/122 [00:03<00:00, 30.64it/s]\u001b[A\n",
            "Epoch 2: 100% 1208/1211 [02:34<00:00,  7.84it/s, loss=0.091, v_num=5-29][NeMo I 2022-07-15 10:34:15 classification_report:142] \n",
            "    label                                                precision    recall       f1           support   \n",
            "    label_id: 0                                             97.22      95.11      96.15        184\n",
            "    label_id: 1                                             97.05      98.34      97.69        301\n",
            "    -------------------\n",
            "    micro avg                                               97.11      97.11      97.11        485\n",
            "    macro avg                                               97.14      96.72      96.92        485\n",
            "    weighted avg                                            97.11      97.11      97.11        485\n",
            "    \n",
            "Epoch 2: 100% 1211/1211 [02:34<00:00,  7.84it/s, loss=0.091, v_num=5-29]\n",
            "Epoch 3:  90% 1089/1211 [02:30<00:16,  7.21it/s, loss=0.028, v_num=5-29]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 3:  90% 1091/1211 [02:31<00:16,  7.22it/s, loss=0.028, v_num=5-29]\n",
            "Epoch 3:  90% 1095/1211 [02:31<00:16,  7.24it/s, loss=0.028, v_num=5-29]\n",
            "Epoch 3:  91% 1099/1211 [02:31<00:15,  7.25it/s, loss=0.028, v_num=5-29]\n",
            "Validating:   9% 11/122 [00:00<00:04, 23.50it/s]\u001b[A\n",
            "Epoch 3:  91% 1103/1211 [02:31<00:14,  7.27it/s, loss=0.028, v_num=5-29]\n",
            "Epoch 3:  91% 1107/1211 [02:31<00:14,  7.30it/s, loss=0.028, v_num=5-29]\n",
            "Epoch 3:  92% 1111/1211 [02:31<00:13,  7.32it/s, loss=0.028, v_num=5-29]\n",
            "Epoch 3:  92% 1115/1211 [02:31<00:13,  7.34it/s, loss=0.028, v_num=5-29]\n",
            "Epoch 3:  92% 1119/1211 [02:32<00:12,  7.36it/s, loss=0.028, v_num=5-29]\n",
            "Epoch 3:  93% 1123/1211 [02:32<00:11,  7.38it/s, loss=0.028, v_num=5-29]\n",
            "Epoch 3:  93% 1128/1211 [02:32<00:11,  7.41it/s, loss=0.028, v_num=5-29]\n",
            "Epoch 3:  94% 1133/1211 [02:32<00:10,  7.43it/s, loss=0.028, v_num=5-29]\n",
            "Epoch 3:  94% 1138/1211 [02:32<00:09,  7.46it/s, loss=0.028, v_num=5-29]\n",
            "Epoch 3:  94% 1143/1211 [02:32<00:09,  7.48it/s, loss=0.028, v_num=5-29]\n",
            "Validating:  45% 55/122 [00:01<00:01, 34.29it/s]\u001b[A\n",
            "Epoch 3:  95% 1148/1211 [02:32<00:08,  7.51it/s, loss=0.028, v_num=5-29]\n",
            "Epoch 3:  95% 1153/1211 [02:33<00:07,  7.53it/s, loss=0.028, v_num=5-29]\n",
            "Epoch 3:  96% 1158/1211 [02:33<00:07,  7.56it/s, loss=0.028, v_num=5-29]\n",
            "Epoch 3:  96% 1163/1211 [02:33<00:06,  7.58it/s, loss=0.028, v_num=5-29]\n",
            "Validating:  61% 75/122 [00:02<00:01, 32.35it/s]\u001b[A\n",
            "Epoch 3:  96% 1168/1211 [02:33<00:05,  7.61it/s, loss=0.028, v_num=5-29]\n",
            "Epoch 3:  97% 1173/1211 [02:33<00:04,  7.63it/s, loss=0.028, v_num=5-29]\n",
            "Epoch 3:  97% 1178/1211 [02:33<00:04,  7.66it/s, loss=0.028, v_num=5-29]\n",
            "Epoch 3:  98% 1183/1211 [02:34<00:03,  7.68it/s, loss=0.028, v_num=5-29]\n",
            "Validating:  78% 95/122 [00:03<00:00, 31.91it/s]\u001b[A\n",
            "Epoch 3:  98% 1188/1211 [02:34<00:02,  7.70it/s, loss=0.028, v_num=5-29]\n",
            "Epoch 3:  99% 1193/1211 [02:34<00:02,  7.73it/s, loss=0.028, v_num=5-29]\n",
            "Epoch 3:  99% 1198/1211 [02:34<00:01,  7.75it/s, loss=0.028, v_num=5-29]\n",
            "Epoch 3:  99% 1203/1211 [02:34<00:01,  7.78it/s, loss=0.028, v_num=5-29]\n",
            "Validating:  94% 115/122 [00:03<00:00, 31.41it/s]\u001b[A\n",
            "Epoch 3: 100% 1208/1211 [02:34<00:00,  7.80it/s, loss=0.028, v_num=5-29][NeMo I 2022-07-15 10:37:08 classification_report:142] \n",
            "    label                                                precision    recall       f1           support   \n",
            "    label_id: 0                                             98.24      90.76      94.35        184\n",
            "    label_id: 1                                             94.60      99.00      96.75        301\n",
            "    -------------------\n",
            "    micro avg                                               95.88      95.88      95.88        485\n",
            "    macro avg                                               96.42      94.88      95.55        485\n",
            "    weighted avg                                            95.98      95.88      95.84        485\n",
            "    \n",
            "Epoch 3: 100% 1211/1211 [02:35<00:00,  7.81it/s, loss=0.028, v_num=5-29]\n",
            "Epoch 3: 100% 1211/1211 [02:46<00:00,  7.25it/s, loss=0.028, v_num=5-29]Saving latest checkpoint..\n",
            "Epoch 3: 100% 1211/1211 [02:53<00:00,  6.99it/s, loss=0.028, v_num=5-29]\n",
            "[NeMo I 2022-07-15 10:37:36 bert_finetuning_SA_DC:58] Training finished!\n",
            "[NeMo I 2022-07-15 10:37:36 bert_finetuning_SA_DC:60] ===========================================================================================\n",
            "[NeMo I 2022-07-15 10:37:36 bert_finetuning_SA_DC:70] ===========================================================================================\n",
            "[NeMo I 2022-07-15 10:37:36 bert_finetuning_SA_DC:72] Starting the testing of the trained model on test set...\n",
            "initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "distributed_backend=ddp\n",
            "All DDP processes registered. Starting ddp with 1 processes\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[NeMo I 2022-07-15 10:37:36 modelPT:572] Optimizer config = Adam (\n",
            "    Parameter Group 0\n",
            "        amsgrad: False\n",
            "        betas: [0.9, 0.999]\n",
            "        eps: 1e-08\n",
            "        lr: 2e-05\n",
            "        weight_decay: 0.01\n",
            "    )\n",
            "[NeMo I 2022-07-15 10:37:36 lr_scheduler:545] Scheduler \"<nemo.core.optim.lr_scheduler.WarmupAnnealing object at 0x7f9a75950250>\" \n",
            "    will be used during training (effective maximum steps = 4356) - \n",
            "    Parameters : \n",
            "    (warmup_steps: null\n",
            "    warmup_ratio: 0.1\n",
            "    last_epoch: -1\n",
            "    max_steps: 4356\n",
            "    )\n",
            "Testing: 100% 303/303 [00:09<00:00, 34.42it/s][NeMo I 2022-07-15 10:37:46 classification_report:142] \n",
            "    label                                                precision    recall       f1           support   \n",
            "    label_id: 0                                             95.19      94.57      94.87        460\n",
            "    label_id: 1                                             96.68      97.07      96.88        751\n",
            "    -------------------\n",
            "    micro avg                                               96.12      96.12      96.12       1211\n",
            "    macro avg                                               95.94      95.82      95.88       1211\n",
            "    weighted avg                                            96.12      96.12      96.12       1211\n",
            "    \n",
            "Testing: 100% 303/303 [00:09<00:00, 31.00it/s]\n",
            "[NeMo I 2022-07-15 10:37:46 bert_finetuning_SA_DC:75] Testing finished!\n",
            "[NeMo I 2022-07-15 10:37:46 bert_finetuning_SA_DC:77] ===========================================================================================\n",
            "[NeMo I 2022-07-15 10:37:46 bert_finetuning_SA_DC:99] ===========================================================================================\n",
            "[NeMo I 2022-07-15 10:37:46 bert_finetuning_SA_DC:102] Starting the evaluating the the last checkpoint on a data file (validation set by default)...\n",
            "Using bos_token, but it is not set yet.\n",
            "Using eos_token, but it is not set yet.\n",
            "[NeMo W 2022-07-15 10:37:47 modelPT:102] Please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    file_path: /content/train.tsv\n",
            "    batch_size: 4\n",
            "    shuffle: true\n",
            "    num_samples: -1\n",
            "    num_workers: 3\n",
            "    drop_last: false\n",
            "    pin_memory: false\n",
            "    \n",
            "[NeMo W 2022-07-15 10:37:47 modelPT:109] Please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    file_path: /content/valid.tsv\n",
            "    batch_size: 4\n",
            "    shuffle: false\n",
            "    num_samples: -1\n",
            "    num_workers: 3\n",
            "    drop_last: false\n",
            "    pin_memory: false\n",
            "    \n",
            "[NeMo W 2022-07-15 10:37:47 modelPT:116] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    file_path: /content/test.tsv\n",
            "    batch_size: 4\n",
            "    shuffle: false\n",
            "    num_samples: -1\n",
            "    num_workers: 3\n",
            "    drop_last: false\n",
            "    pin_memory: false\n",
            "    \n",
            "[NeMo I 2022-07-15 10:37:53 bert_module:54] Restoring weights from /content/PretrainingBERTFromText--end.ckpt\n",
            "[NeMo I 2022-07-15 10:38:00 bert_module:82] Weights for BertEncoder restored from /content/PretrainingBERTFromText--end.ckpt\n",
            "[NeMo I 2022-07-15 10:38:00 text_classification_dataset:119] Read 485 examples from /content/valid.tsv.\n",
            "[NeMo I 2022-07-15 10:38:00 text_classification_dataset:232] *** Example ***\n",
            "[NeMo I 2022-07-15 10:38:00 text_classification_dataset:233] example 0: ['4358', '955', 'Ø¹Ø³Ù„Ø§Ù…Ø©', 'ÙŠÙˆØ³Ù', 'Ù†Ù‚ØªØ±Ø­', 'Ø¹Ù„ÙŠÙƒ', 'ÙŠØ¹Ø·ÙŠÙƒ', 'Ø§Ù†ØªØ±Ù†Øª', 'Ù…Ø­Ø¯ÙˆØ¯Ø©', 'Ø³Ø±Ø¹Ø©', 'Ø¥Ø¨Ø­Ø§Ø±', 'Ù…Ø¶Ù…ÙˆÙ†Ø©', 'ØªØ³ØªØ­Ù‚', 'Ø¥ØªØµØ§Ù„Ø§Øª', 'ØªÙˆÙ†Ø³', 'Ø§Ù„Ø§Ø´ØªØ±Ø§Ùƒ', 'Ø¨', '5', 'Ø¯ÙŠÙ†Ø§Ø±', 'Ø§Ù„Ø´Ù‡Ø±', 'Ù„Ø­ØµÙˆÙ„', 'Ø£ÙƒØ«Ø±', 'Ø§Ù„ØªÙØ§ØµÙŠÙ„', 'Ø¥Ø¶ØºØ·', 'Ø§Ù„Ø±Ø§Ø¨Ø·', 'Ø£Ø­Ù…Ø¯', 'normal']\n",
            "[NeMo I 2022-07-15 10:38:00 text_classification_dataset:234] subtokens: [CLS] 435 ##8 95 ##5 Ø¹ ##Ø³ ##Ù„ ##Ø§ ##Ù… ##Ø© ÙŠ ##Ùˆ ##Ø³ ##Ù Ù† ##Ù‚ ##Øª ##Ø± ##Ø­ Ø¹ ##Ù„ ##ÙŠ ##Ùƒ ÙŠ ##Ø¹ ##Ø· ##ÙŠ ##Ùƒ Ø§ ##Ù† ##Øª ##Ø± ##Ù† ##Øª Ù… ##Ø­ ##Ø¯ ##Ùˆ ##Ø¯ ##Ø© Ø³ ##Ø± ##Ø¹ ##Ø© Ø§ ##Ø¨ ##Ø­ ##Ø§ ##Ø± Ù… ##Ø¶ ##Ù… ##Ùˆ ##Ù† ##Ø© Øª ##Ø³ ##Øª ##Ø­ ##Ù‚ Ø§ ##Øª ##Øµ ##Ø§ ##Ù„ ##Ø§ ##Øª Øª ##Ùˆ ##Ù† ##Ø³ Ø§ ##Ù„ ##Ø§ ##Ø´ ##Øª ##Ø± ##Ø§ ##Ùƒ Ø¨ 5 Ø¯ ##ÙŠ ##Ù† ##Ø§ ##Ø± Ø§ ##Ù„ ##Ø´ ##Ù‡ ##Ø± Ù„ ##Ø­ ##Øµ ##Ùˆ ##Ù„ Ø§ ##Ùƒ ##Ø« ##Ø± Ø§ ##Ù„ ##Øª ##Ù ##Ø§ ##Øµ ##ÙŠ ##Ù„ Ø§ ##Ø¶ ##Øº ##Ø· Ø§ ##Ù„ ##Ø± ##Ø§ ##Ø¨ ##Ø· Ø§ ##Ø­ ##Ù… ##Ø¯ normal [SEP]\n",
            "[NeMo I 2022-07-15 10:38:00 text_classification_dataset:235] input_ids: 101 24125 2620 5345 2629 1288 29824 23673 25573 22192 19433 1300 29836 29824 29833 1296 29834 29817 17149 29820 1288 23673 14498 29835 1300 29830 29828 14498 29835 1270 15915 29817 17149 15915 29817 1295 29820 15394 29836 15394 19433 1282 17149 29830 19433 1270 29816 29820 25573 17149 1295 29827 22192 29836 15915 19433 1273 29824 29817 29820 29834 1270 29817 29826 25573 23673 25573 29817 1273 29836 15915 29824 1270 23673 25573 29825 29817 17149 25573 29835 1271 1019 1278 14498 15915 25573 17149 1270 23673 29825 14157 17149 1294 29820 29826 29836 23673 1270 29835 29818 17149 1270 23673 29817 29833 25573 29826 14498 23673 1270 29827 29831 29828 1270 23673 17149 25573 29816 29828 1270 29820 22192 15394 3671 102\n",
            "[NeMo I 2022-07-15 10:38:00 text_classification_dataset:236] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "[NeMo I 2022-07-15 10:38:00 text_classification_dataset:237] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "[NeMo I 2022-07-15 10:38:00 text_classification_dataset:238] label: 0\n",
            "[NeMo I 2022-07-15 10:38:00 text_classification_dataset:232] *** Example ***\n",
            "[NeMo I 2022-07-15 10:38:00 text_classification_dataset:233] example 1: ['2438', '3347', 'Ø§Ø®ÙˆØ§Ù†ÙŠ', 'Ø§Ù„ØªÙˆØ§Ù†Ø³Ø©', 'Ø¯Ø¹ÙƒÙ…', 'Ø§Ù„ØªØ²Ù„Ù', 'ÙˆØ§Ù„Ø´ÙŠØªØ©', 'Ù„Ù„ØºØ±Ø¨', 'ÙˆØ§Ø³Ø±Ø§Ø¦ÙŠÙ„', 'Ø§Ù„ÙŠÙ‡ÙˆØ¯ÙŠ', 'ÙŠØ¨Ù‚Ù‰', 'Ø¯Ø§Ø¦Ù…Ø§', 'ÙŠÙ‡ÙˆØ¯ÙŠ', 'ÙˆØ§Ø³ØªÙ…Ø¹Ùˆ', 'Ù‚Ø§Ù„Ù‡', 'Ø¹Ø²', 'ÙˆØ¬Ù„', 'ØªØ±Ø¶Ù‰', 'Ø§Ù„ÙŠÙ‡ÙˆØ¯', 'Ø§Ù„Ù†ØµØ§Ø±Ù‰', 'ØªØªØ¨Ø¹', 'Ù…Ù„ØªÙ‡Ù…', 'Ù‚Ù„', 'Ù‡Ø¯Ù‰', 'Ø§Ù„Ù‡Ø¯Ù‰', 'hate']\n",
            "[NeMo I 2022-07-15 10:38:00 text_classification_dataset:234] subtokens: [CLS] 243 ##8 334 ##7 Ø§ ##Ø® ##Ùˆ ##Ø§Ù† ##ÙŠ Ø§ ##Ù„ ##Øª ##Ùˆ ##Ø§Ù† ##Ø³ ##Ø© Ø¯ ##Ø¹ ##Ùƒ ##Ù… Ø§ ##Ù„ ##Øª ##Ø² ##Ù„ ##Ù Ùˆ ##Ø§ ##Ù„ ##Ø´ ##ÙŠ ##Øª ##Ø© Ù„ ##Ù„ ##Øº ##Ø± ##Ø¨ Ùˆ ##Ø§ ##Ø³ ##Ø± ##Ø§ ##ÙŠ ##ÙŠ ##Ù„ Ø§ ##Ù„ ##ÙŠ ##Ù‡ ##Ùˆ ##Ø¯ ##ÙŠ ÙŠ ##Ø¨ ##Ù‚ ##Ù‰ Ø¯ ##Ø§ ##ÙŠ ##Ù… ##Ø§ ÙŠ ##Ù‡ ##Ùˆ ##Ø¯ ##ÙŠ Ùˆ ##Ø§ ##Ø³ ##Øª ##Ù… ##Ø¹ ##Ùˆ Ù‚ ##Ø§ ##Ù„ ##Ù‡ Ø¹ ##Ø² Ùˆ ##Ø¬ ##Ù„ Øª ##Ø± ##Ø¶ ##Ù‰ Ø§ ##Ù„ ##ÙŠ ##Ù‡ ##Ùˆ ##Ø¯ Ø§ ##Ù„ ##Ù† ##Øµ ##Ø§ ##Ø± ##Ù‰ Øª ##Øª ##Ø¨ ##Ø¹ Ù… ##Ù„ ##Øª ##Ù‡ ##Ù… Ù‚ ##Ù„ Ù‡ ##Ø¯ ##Ù‰ Ø§ ##Ù„ ##Ù‡ ##Ø¯ ##Ù‰ hate [SEP]\n",
            "[NeMo I 2022-07-15 10:38:00 text_classification_dataset:235] input_ids: 101 22884 2620 29562 2581 1270 29821 29836 18511 14498 1270 23673 29817 29836 18511 29824 19433 1278 29830 29835 22192 1270 23673 29817 29823 23673 29833 1298 25573 23673 29825 14498 29817 19433 1294 23673 29831 17149 29816 1298 25573 29824 17149 25573 14498 14498 23673 1270 23673 14498 14157 29836 15394 14498 1300 29816 29834 29837 1278 25573 14498 22192 25573 1300 14157 29836 15394 14498 1298 25573 29824 29817 22192 29830 29836 1292 25573 23673 14157 1288 29823 1298 29819 23673 1273 17149 29827 29837 1270 23673 14498 14157 29836 15394 1270 23673 15915 29826 25573 17149 29837 1273 29817 29816 29830 1295 23673 29817 14157 22192 1292 23673 1297 15394 29837 1270 23673 14157 15394 29837 5223 102\n",
            "[NeMo I 2022-07-15 10:38:00 text_classification_dataset:236] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "[NeMo I 2022-07-15 10:38:00 text_classification_dataset:237] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "[NeMo I 2022-07-15 10:38:00 text_classification_dataset:238] label: 1\n",
            "[NeMo W 2022-07-15 10:38:01 text_classification_dataset:245] Found 60 out of 485 sentences with more than 128 subtokens. Truncated long sentences from the end.\n",
            "[NeMo I 2022-07-15 10:38:01 data_preprocessing:295] Some stats of the lengths of the sequences:\n",
            "[NeMo I 2022-07-15 10:38:01 data_preprocessing:301] Min: 11 |                  Max: 129 |                  Mean: 58.47216494845361 |                  Median: 46.0\n",
            "[NeMo I 2022-07-15 10:38:01 data_preprocessing:303] 75 percentile: 81.00\n",
            "[NeMo I 2022-07-15 10:38:01 data_preprocessing:304] 99 percentile: 129.00\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "Using environment variable NODE_RANK for node rank (0).\n",
            "CUDA_VISIBLE_DEVICES: [0]\n",
            "[NeMo I 2022-07-15 10:38:01 modelPT:572] Optimizer config = Adam (\n",
            "    Parameter Group 0\n",
            "        amsgrad: False\n",
            "        betas: [0.9, 0.999]\n",
            "        eps: 1e-08\n",
            "        lr: 2e-05\n",
            "        weight_decay: 0.01\n",
            "    )\n",
            "[NeMo W 2022-07-15 10:38:01 lr_scheduler:526] Neither `max_steps` nor `iters_per_batch` were provided to `optim.sched`, cannot compute effective `max_steps` !\n",
            "    Scheduler will not be instantiated !\n",
            "Testing: 100% 8/8 [00:04<00:00,  2.08it/s][NeMo I 2022-07-15 10:38:06 classification_report:142] \n",
            "    label                                                precision    recall       f1           support   \n",
            "    label_id: 0                                             98.24      90.76      94.35        184\n",
            "    label_id: 1                                             94.60      99.00      96.75        301\n",
            "    -------------------\n",
            "    micro avg                                               95.88      95.88      95.88        485\n",
            "    macro avg                                               96.42      94.88      95.55        485\n",
            "    weighted avg                                            95.98      95.88      95.84        485\n",
            "    \n",
            "Testing: 100% 8/8 [00:04<00:00,  1.77it/s]\n",
            "[NeMo I 2022-07-15 10:38:06 bert_finetuning_SA_DC:137] Evaluation the last checkpoint finished!\n",
            "[NeMo I 2022-07-15 10:38:06 bert_finetuning_SA_DC:139] ===========================================================================================\n",
            "[NeMo I 2022-07-15 10:38:06 bert_finetuning_SA_DC:150] ===========================================================================================\n",
            "[NeMo I 2022-07-15 10:38:06 bert_finetuning_SA_DC:152] Starting the inference on some sample queries...\n",
            "Using bos_token, but it is not set yet.\n",
            "Using eos_token, but it is not set yet.\n",
            "[NeMo W 2022-07-15 10:38:07 modelPT:102] Please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    file_path: /content/train.tsv\n",
            "    batch_size: 4\n",
            "    shuffle: true\n",
            "    num_samples: -1\n",
            "    num_workers: 3\n",
            "    drop_last: false\n",
            "    pin_memory: false\n",
            "    \n",
            "[NeMo W 2022-07-15 10:38:07 modelPT:109] Please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    file_path: /content/valid.tsv\n",
            "    batch_size: 4\n",
            "    shuffle: false\n",
            "    num_samples: -1\n",
            "    num_workers: 3\n",
            "    drop_last: false\n",
            "    pin_memory: false\n",
            "    \n",
            "[NeMo W 2022-07-15 10:38:07 modelPT:116] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    file_path: /content/test.tsv\n",
            "    batch_size: 4\n",
            "    shuffle: false\n",
            "    num_samples: -1\n",
            "    num_workers: 3\n",
            "    drop_last: false\n",
            "    pin_memory: false\n",
            "    \n",
            "[NeMo I 2022-07-15 10:38:13 bert_module:54] Restoring weights from /content/PretrainingBERTFromText--end.ckpt\n",
            "[NeMo I 2022-07-15 10:38:14 bert_module:82] Weights for BertEncoder restored from /content/PretrainingBERTFromText--end.ckpt\n",
            "[NeMo I 2022-07-15 10:38:15 bert_finetuning_SA_DC:178] The prediction results of some sample queries with the trained model:\n",
            "[NeMo I 2022-07-15 10:38:15 bert_finetuning_SA_DC:181] Query : Ø§Ø³ØªÙØ¯Øª Ø¨Ø±Ø´Ø§ Ù†Ø¹Ø´Ù‚ ÙÙŠØ¯ÙŠÙˆÙ‡Ø§ØªÙƒ Ùˆ Ù†Ø­Ø¨ Ù†Ø¹Ø±Ù ÙˆÙ‚ØªØ§Ù‡ ØªØ¹Ù„Ù…Øª Ù‡Ø° Ø§Ù„ÙƒÙ„\n",
            "[NeMo I 2022-07-15 10:38:15 bert_finetuning_SA_DC:182] Predicted label: 0\n",
            "[NeMo I 2022-07-15 10:38:15 bert_finetuning_SA_DC:181] Query : Ø¨ØµØ±Ø§Ø­Ø© Ø£Ø­Ø³Ù† Ø­Ø§Ø¬Ø© ÙƒÙŠÙ Ø±Ø¬Ø¹ØªÙˆ ÙƒØ±ÙŠÙ… Ø§Ù„Ù‚Ù†Ø§Øª Ù†ÙˆØ±Øª Ø¨ÙŠÙƒ Ø±Ø¨ÙŠ ÙŠÙˆÙÙ‚Ùƒ ÙŠØ§ Ø®ÙˆÙŠØ§ ÙƒØ±ÙŠÙ… ÙŠØ§ Ø¨Ø§Ù‡ÙŠ\n",
            "[NeMo I 2022-07-15 10:38:15 bert_finetuning_SA_DC:182] Predicted label: 0\n",
            "[NeMo I 2022-07-15 10:38:15 bert_finetuning_SA_DC:181] Query : Ø§Ù„Ù…Ø³Ù„Ø³Ù„ Ù‡Ø§Ø°Ø§ Ø±ØºÙ… Ø³Ù‚Ø§Ø·ØªÙˆ Ùˆ Ø±ØºÙ… ÙƒÙ„Ø´ÙŠ ÙÙŠÙ‡ Ø§Ù…Ø§ ÙÙŠÙ‡ Ø¨Ø±Ø´Ø§ Ø­Ø§Ø¬Ø§Øª Ù…Ø´ Ø®Ø§ÙŠØ¨ÙŠÙ†\n",
            "[NeMo I 2022-07-15 10:38:15 bert_finetuning_SA_DC:182] Predicted label: 0\n",
            "[NeMo I 2022-07-15 10:38:15 bert_finetuning_SA_DC:181] Query : Ø§Ù„Ù„Ù‡ Ø§Ø¹Ø² Ù…Ø³Ù„Ø³Ù„ ØªÙˆÙ†Ø³ÙŠ\n",
            "[NeMo I 2022-07-15 10:38:15 bert_finetuning_SA_DC:182] Predicted label: 0\n",
            "[NeMo I 2022-07-15 10:38:15 bert_finetuning_SA_DC:181] Query :  Ø±Ø¬Ø¹ØªÙˆØ§ Ù„ÙØ³Ø§Ø¯ Ø¨Ø·ÙˆÙ„Ø© Ùˆ Ù„Ø®Ù…Ø§Ø¬ Ù‚ÙØ§Ø²Ø©  Ø­Ø³Ø¨Ù†Ø§ Ø§Ù„Ù„Ù‡ ÙˆÙ†Ø¹Ù… Ø§Ù„ÙˆÙƒÙŠÙ„\n",
            "[NeMo I 2022-07-15 10:38:15 bert_finetuning_SA_DC:182] Predicted label: 0\n",
            "[NeMo I 2022-07-15 10:38:15 bert_finetuning_SA_DC:181] Query : ÙˆØ§Ù„Ù„Ù‡ Ù„Ø§ ØªØ­Ø´Ù….. Ø¹ÙŠØ¨ Ø¹Ù„ÙŠÙƒ.. ØªØ­Ø¨ ØªÙØ¯Ù„Ùƒ Ø¹Ù„Ù‰ Ø±Ø¨ÙŠ!!!!!! ÙŠØ¹Ù†ÙŠ Ù„Ø§ Ø¯ÙŠÙ†ØŒ Ù„Ø§ Ù…Ù„Ø©\n",
            "[NeMo I 2022-07-15 10:38:15 bert_finetuning_SA_DC:182] Predicted label: 0\n",
            "[NeMo I 2022-07-15 10:38:15 bert_finetuning_SA_DC:184] Inference finished!\n",
            "[NeMo I 2022-07-15 10:38:15 bert_finetuning_SA_DC:186] ===========================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9-2iVqXYJg13"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}